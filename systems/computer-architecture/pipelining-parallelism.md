# 流水线与并行处理 (Pipelining and Parallelism)

> CPU 如何同时做多件事来提升性能

## 🎯 核心概念

**关键思想：不让 CPU 的任何部分闲置**

```
串行执行（慢）:
  指令1: [取指][译码][执行][访存][写回]
  指令2:                              [取指][译码][执行][访存][写回]
  时间: ─────────────────────────────────────────────────────→

流水线执行（快）:
  指令1: [取指][译码][执行][访存][写回]
  指令2:       [取指][译码][执行][访存][写回]
  指令3:             [取指][译码][执行][访存][写回]
  指令4:                   [取指][译码][执行][访存][写回]
  时间: ─────────────────────────────→

类比：汽车组装流水线 vs 一个人组装完整辆车
```

---

## 1️⃣ 指令流水线基础

### 经典五级流水线

```
┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐   ┌──────────┐
│   IF     │→ │   ID     │→ │   EX     │→ │   MEM    │→ │   WB     │
│ 取指     │  │ 译码     │  │ 执行     │  │ 访存     │  │ 写回     │
│ Fetch    │  │ Decode   │  │ Execute  │  │ Memory   │  │WriteBack │
└──────────┘   └──────────┘   └──────────┘   └──────────┘   └──────────┘

1. IF (Instruction Fetch):
   • 从内存取指令
   • PC → 指令地址
   • 指令 → IR

2. ID (Instruction Decode):
   • 解析指令
   • 读取寄存器
   • 准备操作数

3. EX (Execute):
   • ALU 运算
   • 地址计算
   • 分支判断

4. MEM (Memory Access):
   • Load/Store 访问内存
   • 其他指令跳过此阶段

5. WB (Write Back):
   • 将结果写回寄存器
```

### 流水线时空图

```
时钟周期:  1    2    3    4    5    6    7    8    9
         ┌────┬────┬────┬────┬────┬────┬────┬────┬────┐
指令1:   │ IF │ ID │ EX │ MEM│ WB │    │    │    │    │
         ├────┼────┼────┼────┼────┼────┼────┼────┼────┤
指令2:   │    │ IF │ ID │ EX │ MEM│ WB │    │    │    │
         ├────┼────┼────┼────┼────┼────┼────┼────┼────┤
指令3:   │    │    │ IF │ ID │ EX │ MEM│ WB │    │    │
         ├────┼────┼────┼────┼────┼────┼────┼────┼────┤
指令4:   │    │    │    │ IF │ ID │ EX │ MEM│ WB │    │
         ├────┼────┼────┼────┼────┼────┼────┼────┼────┤
指令5:   │    │    │    │    │ IF │ ID │ EX │ MEM│ WB │
         └────┴────┴────┴────┴────┴────┴────┴────┴────┘

理想情况：每个时钟周期完成一条指令（CPI = 1）
```

### 加速比计算

```
假设：
  • 每个流水线阶段 = 1ns
  • 5 级流水线
  • 执行 100 条指令

无流水线:
  时间 = 100 × 5ns = 500ns

有流水线:
  时间 = 5ns (填充流水线) + 99 × 1ns = 104ns

加速比 = 500 / 104 ≈ 4.8 倍

理论最大加速比 = 流水线级数（这里是5）
```

---

## 2️⃣ 流水线冒险 (Hazards)

### 什么是冒险？

**冒险 = 流水线不能在下一个时钟周期执行下一条指令的情况**

### 1. 结构冒险 (Structural Hazard)

**硬件资源冲突 - 两条指令需要同时使用同一个硬件**

```
问题：统一的指令和数据内存

时钟周期:  1    2    3    4    5
         ┌────┬────┬────┬────┬────┐
指令1:   │ IF │ ID │ EX │ MEM│ WB │
         ├────┼────┼────┼────┼────┤
指令4:   │    │    │    │ IF │ ID │
         └────┴────┴────┴────┴────┘
                        ↑    ↑
                        冲突！都要访问内存

指令1 的 MEM 阶段和指令4 的 IF 阶段都要访问内存！
```

**解决方案：**
```
1. 哈佛架构 (Harvard Architecture):
   • 指令内存和数据内存分离
   • L1 I-Cache 和 L1 D-Cache 分离

2. 流水线暂停 (Stall):
   • 让后续指令等待一个周期
   • 插入气泡 (Bubble)

3. 增加硬件资源:
   • 多端口内存
   • 多个 ALU
```

### 2. 数据冒险 (Data Hazard)

**指令之间有数据依赖关系**

#### RAW (Read After Write) - 真依赖

```assembly
ADD R1, R2, R3    # R1 = R2 + R3
SUB R4, R1, R5    # R4 = R1 - R5  ← 需要 R1 的新值！

时钟周期:  1    2    3    4    5    6
         ┌────┬────┬────┬────┬────┬────┐
ADD:     │ IF │ ID │ EX │ MEM│ WB │    │
         ├────┼────┼────┼────┼────┼────┤
SUB:     │    │ IF │ ID │ EX │ MEM│ WB │
         └────┴────┴────┴────┴────┴────┘
                   ↑          ↑
                   读R1       R1写回

问题：SUB 在 ID 阶段读 R1，但 ADD 要到 WB 阶段才写入！
```

**解决方案 1：停顿 (Stall)**
```
时钟周期:  1    2    3    4    5    6    7
         ┌────┬────┬────┬────┬────┬────┬────┐
ADD:     │ IF │ ID │ EX │ MEM│ WB │    │    │
         ├────┼────┼────┼────┼────┼────┼────┤
SUB:     │    │ IF │ ID │暂停│暂停│ EX │ MEM│
         └────┴────┴────┴────┴────┴────┴────┘

性能损失：插入 2 个气泡
```

**解决方案 2：数据转发 (Forwarding / Bypassing)**
```
时钟周期:  1    2    3    4    5    6
         ┌────┬────┬────┬────┬────┬────┐
ADD:     │ IF │ ID │ EX │ MEM│ WB │    │
         ├────┼────┼────┼────┼────┼────┤
SUB:     │    │ IF │ ID │ EX │ MEM│ WB │
         └────┴────┴────┴────┴────┴────┘
                        │         ↑
                        └─转发────┘

ADD 的 EX 阶段完成后，直接转发结果给 SUB 的 EX 阶段！
无需等到 WB！
```

#### Load-Use 数据冒险

```assembly
LW  R1, 0(R2)     # R1 = Memory[R2]
ADD R3, R1, R4    # R3 = R1 + R4

时钟周期:  1    2    3    4    5    6
         ┌────┬────┬────┬────┬────┬────┐
LW:      │ IF │ ID │ EX │ MEM│ WB │    │
         ├────┼────┼────┼────┼────┼────┤
ADD:     │    │ IF │ ID │暂停│ EX │ MEM│
         └────┴────┴────┴────┴────┴────┘
                             ↑    ↑
                          数据就绪 使用数据

问题：数据要到 MEM 阶段才能获取，必须暂停 1 周期
```

**编译器优化：指令重排**
```assembly
# 原始代码
LW  R1, 0(R2)
ADD R3, R1, R4
SUB R5, R6, R7    # 不依赖 R1

# 编译器重排后
LW  R1, 0(R2)
SUB R5, R6, R7    # 移到这里执行，填充 Load 延迟
ADD R3, R1, R4    # 现在数据已经就绪
```

#### WAR 和 WAW (仅在乱序执行中出现)

```
WAR (Write After Read): 反依赖
WAW (Write After Write): 输出依赖

顺序流水线中不会出现，因为读写顺序固定。
```

### 3. 控制冒险 (Control Hazard)

**分支指令导致不知道下一条指令是什么**

```assembly
BEQ R1, R2, target  # if (R1 == R2) goto target
ADD R3, R4, R5      # 下一条指令？
...
target:
  SUB R6, R7, R8    # 还是这里？

时钟周期:  1    2    3    4    5
         ┌────┬────┬────┬────┬────┐
BEQ:     │ IF │ ID │ EX │ MEM│ WB │
         ├────┼────┼────┼────┼────┤
???:     │    │ IF │ ID │ ?? │ ?? │
         └────┴────┴────┴────┴────┘
                        ↑
                   分支结果才知道

问题：要到 EX 阶段才知道是否跳转！
已经取了下一条指令，可能取错了！
```

**解决方案：**

#### 1. 总是暂停 (Always Stall)
```
简单但慢：每个分支都暂停 2-3 个周期
```

#### 2. 预测不跳转 (Predict Not Taken)
```
假设分支不发生，继续执行
• 预测对：无损失
• 预测错：清空流水线（Flush）

静态预测准确率 ~60%
```

#### 3. 分支预测 (Branch Prediction)
```
动态预测分支结果

1位预测器:
  • 记录上次是否跳转
  • 准确率 ~80-85%

2位饱和计数器:
  ┌────────┐
  │ 00     │ 强不跳转
  │ 01     │ 弱不跳转
  │ 10     │ 弱跳转
  │ 11     │ 强跳转
  └────────┘

  准确率 ~90-95%

现代CPU:
  • 多级预测器
  • 神经网络预测
  • 准确率 >97%
```

#### 4. 延迟槽 (Delay Slot)
```assembly
# MIPS 的做法：分支后总是执行一条指令

BEQ R1, R2, target
ADD R3, R4, R5        ← 延迟槽指令，总是执行！
...

编译器填充有用的指令到延迟槽，避免浪费。
```

---

## 3️⃣ 超标量处理器 (Superscalar)

### 单发射 vs 多发射

```
标量流水线（单发射）:
  每个时钟周期发射 1 条指令

超标量（多发射）:
  每个时钟周期发射 N 条指令

Intel Core i7: 4-发射
  → 理论上每周期执行 4 条指令
```

### 超标量架构

```
┌─────────────────────────────────────────────┐
│           取指单元 (Fetch)                   │
│    每周期取 4-6 条指令                       │
└──────────────────┬──────────────────────────┘
                   │
┌──────────────────▼──────────────────────────┐
│           译码单元 (Decode)                  │
│    同时译码多条指令                          │
└──────────────────┬──────────────────────────┘
                   │
┌──────────────────▼──────────────────────────┐
│         发射队列 (Issue Queue)               │
│    检查依赖关系，选择可执行的指令            │
└───┬────────┬──────────┬──────────┬──────────┘
    │        │          │          │
┌───▼────┐┌──▼───┐  ┌───▼───┐  ┌──▼────┐
│ ALU 1  ││ ALU 2│  │ Load  │  │Store  │
│        ││      │  │ Unit  │  │ Unit  │
└───┬────┘└──┬───┘  └───┬───┘  └──┬────┘
    │        │          │          │
└───┴────────┴──────────┴──────────┴──────────┘
              写回阶段
```

### 指令级并行 (ILP)

```c
// 低 ILP：指令间有依赖
int a = b + c;
int d = a * 2;     // 依赖 a
int e = d - 1;     // 依赖 d

// 高 ILP：指令独立
int a = b + c;
int d = e * f;     // 独立
int g = h - i;     // 独立
int j = k / l;     // 独立

后者可以同时执行 4 条指令！
```

---

## 4️⃣ 乱序执行 (Out-of-Order Execution)

### 为什么需要乱序执行？

```assembly
# 顺序执行的问题
LW  R1, 0(R2)     # Load，延迟长
ADD R3, R1, R4    # 依赖 R1，必须等待
MUL R5, R6, R7    # 独立指令，但被阻塞！
SUB R8, R9, R10   # 也被阻塞！

# 乱序执行
LW  R1, 0(R2)     # 开始 Load
MUL R5, R6, R7    # 立即执行！
SUB R8, R9, R10   # 也执行！
ADD R3, R1, R4    # 等 Load 完成再执行

在 Load 延迟期间，执行了其他指令！
```

### Tomasulo 算法

**经典的乱序执行算法（IBM System/360）**

```
核心思想：
  1. 指令按序发射到保留站 (Reservation Station)
  2. 保留站检查依赖关系
  3. 操作数就绪的指令可以执行（乱序）
  4. 结果通过公共数据总线 (CDB) 广播
  5. 结果按序提交 (ROB: Re-Order Buffer)

┌──────────────────────────────────────┐
│        指令队列（按序）               │
└───────────────┬──────────────────────┘
                │ 发射
┌───────────────▼──────────────────────┐
│      保留站 (Reservation Stations)    │
│  • 等待操作数                         │
│  • 检测数据就绪                       │
└───┬───────────────────────┬──────────┘
    │ 就绪指令（乱序执行）  │
┌───▼───────┐      ┌────────▼─────┐
│  ALU 1    │      │   ALU 2      │
└───┬───────┘      └────────┬─────┘
    │                       │
    └───────┬───────────────┘
            │ 结果广播 (CDB)
┌───────────▼─────────────────────────┐
│  重排序缓冲 (ROB)                    │
│  确保按序提交                        │
└──────────────────────────────────────┘
```

### 寄存器重命名 (Register Renaming)

**解决 WAR 和 WAW 冒险**

```assembly
# 原始代码（有 WAR 冒险）
ADD R1, R2, R3
SUB R4, R1, R5    # RAW: 真依赖
MUL R1, R6, R7    # WAW: R1 被重写
DIV R8, R1, R9

# 重命名后（消除伪依赖）
ADD P10, R2, R3   # R1 → P10（物理寄存器）
SUB R4, P10, R5
MUL P11, R6, R7   # R1 → P11（不同的物理寄存器）
DIV R8, P11, R9

现在 ADD 和 MUL 可以并行执行！
```

**物理寄存器池：**
```
架构寄存器（ISA 定义）:
  x86-64: 16 个 GPRs
  RISC-V: 32 个

物理寄存器（实际硬件）:
  现代 CPU: 100-200 个物理寄存器

寄存器映射表 (RAT):
  R1 → P10
  R2 → P23
  R3 → P45
  ...
```

---

## 5️⃣ 多核并行 (Multi-core Parallelism)

### 单核到多核的演进

```
2000年代初：
  单核 CPU，不断提升频率
  问题：功耗墙（Power Wall）
    → 频率提升 → 功耗急剧上升 → 散热困难

2005年后：
  多核 CPU，降低频率
  思路：不追求单核性能，通过并行提升整体性能
```

### 多核架构

```
Intel Core i7 (4核8线程):
┌──────────────────────────────────────────────┐
│ ┌─────────┐  ┌─────────┐  ┌─────────┐  ┌────┴───┐
│ │ Core 0  │  │ Core 1  │  │ Core 2  │  │ Core 3 │
│ │ L1I L1D │  │ L1I L1D │  │ L1I L1D │  │ L1I L1D│
│ │  L2     │  │  L2     │  │  L2     │  │  L2    │
│ └────┬────┘  └────┬────┘  └────┬────┘  └────┬───┘
│      └────────────┴────────────┴─────────────┘
│                      │
│             ┌────────▼────────┐
│             │   L3 Cache      │  共享
│             │   (8-12 MB)     │
│             └────────┬────────┘
│                      │
│             ┌────────▼────────┐
│             │  Memory         │
│             └─────────────────┘
└──────────────────────────────────────────────┘
```

### 对称多处理 (SMP)

```
┌────────┐  ┌────────┐  ┌────────┐  ┌────────┐
│ Core 0 │  │ Core 1 │  │ Core 2 │  │ Core 3 │
└───┬────┘  └───┬────┘  └───┬────┘  └───┬────┘
    └───────────┴────────────┴───────────┘
                    │
          ┌─────────▼─────────┐
          │   共享内存         │
          └───────────────────┘

特点：
  • 所有核心平等
  • 共享内存地址空间
  • 需要解决缓存一致性
```

### Cache 一致性 (Cache Coherence)

**问题：多个核心缓存同一数据，如何保持一致？**

```
初始状态：
  Memory[X] = 0
  Core 0 Cache: X = 0
  Core 1 Cache: X = 0

Core 0 修改 X = 1:
  Core 0 Cache: X = 1
  Core 1 Cache: X = 0  ← 过期数据！
  Memory[X] = ???

如果 Core 1 读取 X，应该得到 0 还是 1？
```

### MESI 协议

**解决 Cache 一致性的经典协议**

```
Cache Line 的四种状态：

M (Modified):
  • 只有本核心有此数据
  • 数据已修改，与内存不一致
  • 本核心独占

E (Exclusive):
  • 只有本核心有此数据
  • 数据未修改，与内存一致
  • 本核心独占

S (Shared):
  • 多个核心都有此数据
  • 只读，与内存一致

I (Invalid):
  • 无效，数据不可用
```

**状态转换：**
```
Core 0 读取 X：
  I → E (独占)

Core 1 也读取 X：
  Core 0: E → S (共享)
  Core 1: I → S (共享)

Core 0 写入 X：
  Core 0: S → M (独占修改)
  Core 1: S → I (失效)
  → Core 1 的 Cache 被无效化
```

**实现：**
```
总线监听 (Bus Snooping):
  • 所有核心监听总线
  • 检测其他核心的读写操作
  • 根据 MESI 协议更新状态

目录协议 (Directory-based):
  • 用于大规模多核（>16核）
  • 目录记录每个 Cache line 的状态
```

---

## 6️⃣ SIMD 并行 (Single Instruction Multiple Data)

### 向量化指令

**一条指令操作多个数据**

```
标量加法（一次一个）:
  for (int i = 0; i < 4; i++) {
      c[i] = a[i] + b[i];
  }
  → 4 条 ADD 指令

SIMD 加法（一次四个）:
  c[0:3] = a[0:3] + b[0:3];
  → 1 条 VADD 指令

┌────────────────────────────────────┐
│  a[0]  │  a[1]  │  a[2]  │  a[3]  │
│    +   │    +   │    +   │    +   │
│  b[0]  │  b[1]  │  b[2]  │  b[3]  │
│    ↓   │    ↓   │    ↓   │    ↓   │
│  c[0]  │  c[1]  │  c[2]  │  c[3]  │
└────────────────────────────────────┘
      同时执行 4 个加法！
```

### SIMD 指令集

```
Intel:
  • MMX (1997): 64位寄存器，整数
  • SSE (1999): 128位寄存器，4×float
  • AVX (2011): 256位寄存器，8×float
  • AVX-512 (2015): 512位寄存器，16×float

ARM:
  • NEON: 128位寄存器
  • SVE: 可扩展向量扩展

RISC-V:
  • RVV: 可配置向量长度
```

### SIMD 示例

```c
// 标量代码
void add_arrays(float *a, float *b, float *c, int n) {
    for (int i = 0; i < n; i++) {
        c[i] = a[i] + b[i];
    }
}

// AVX2 向量化（8个 float 一次）
void add_arrays_avx(float *a, float *b, float *c, int n) {
    for (int i = 0; i < n; i += 8) {
        __m256 va = _mm256_load_ps(&a[i]);  // 加载 8 个 float
        __m256 vb = _mm256_load_ps(&b[i]);
        __m256 vc = _mm256_add_ps(va, vb);  // 同时加 8 个
        _mm256_store_ps(&c[i], vc);
    }
}

加速比：理论 8 倍，实际 4-6 倍
```

---

## 7️⃣ 多线程 (Multithreading)

### 超线程 (Hyper-Threading / SMT)

**一个物理核心模拟多个逻辑核心**

```
传统单线程：
  时钟周期: 1   2   3   4   5   6   7   8
  核心:     A   空  A   空  空  A   空  A
            │   ↑   │   ↑   ↑   │   ↑   │
            └───┘   └───┘   └───┘   └───┘
             很多周期浪费（等待 Cache、分支等）

超线程（2线程）：
  时钟周期: 1   2   3   4   5   6   7   8
  核心:     A   B   A   B   B   A   B   A
            ↑   ↑
         线程A 线程B 交替执行，填充空闲周期
```

**实现：**
```
硬件重复：
  • 程序计数器 (PC) × 2
  • 寄存器文件 × 2
  • 架构状态 × 2

硬件共享：
  • ALU
  • Cache
  • 流水线资源
```

**性能：**
```
单线程性能: 100%
双线程性能: 120-130% (不是 200%!)

为什么不是 2 倍？
  → 共享执行资源
  → Cache 竞争
  → 带宽限制
```

---

## 8️⃣ 实际应用

### 编写并行友好的代码

#### 1. 数据并行
```c
// 适合 SIMD 和多核
#pragma omp parallel for
for (int i = 0; i < n; i++) {
    output[i] = process(input[i]);  // 每个元素独立
}
```

#### 2. 避免伪共享
```c
// ❌ 伪共享
struct Counter {
    long count[4];  // 4个核心的计数器
};

// 每个核心修改自己的 count，但它们在同一个 Cache line
// → Cache line 来回失效

// ✅ 填充避免伪共享
struct Counter {
    long count;
    char padding[56];  // 填充到 64 字节
} counters[4];
```

#### 3. 减少分支预测失败
```c
// ❌ 不可预测的分支
for (int i = 0; i < n; i++) {
    if (data[i] < threshold) {  // 随机分支
        process_small(data[i]);
    } else {
        process_large(data[i]);
    }
}

// ✅ 先排序再处理（分支可预测）
sort(data, n);
int split = find_split_point(data, threshold);
for (int i = 0; i < split; i++) {
    process_small(data[i]);  // 总是执行
}
for (int i = split; i < n; i++) {
    process_large(data[i]);  // 总是执行
}
```

---

## 🔗 与其他概念的联系

### 与编译器优化
- **指令调度** - 编译器重排指令避免流水线停顿
- **循环展开** - 增加 ILP
- **向量化** - 生成 SIMD 指令

### 与操作系统
- **进程调度** - 多核负载均衡
- **CPU 亲和性** - 减少 Cache 失效
- **中断处理** - 可能清空流水线

参考：`systems/operating-systems/processes-threads.md`

### 与性能优化
- **热点代码** - 保持在指令 Cache 中
- **数据局部性** - 利用数据 Cache
- **并行算法** - 利用多核

---

## 📚 深入学习

### 推荐资源
- *Computer Architecture: A Quantitative Approach* - 附录 C（流水线）
- *Agner Fog's Optimization Manuals*
- Intel® 64 and IA-32 Architectures Optimization Reference Manual

### 实践项目
- 实现流水线模拟器
- 分析程序的分支预测性能
- 使用 SIMD 优化代码

### 下一步
- [性能评估](./performance-evaluation.md) - 量化并行效果
- [存储层次](./memory-hierarchy.md) - 理解 Cache 对并行的影响

---

**掌握流水线和并行，就掌握了现代 CPU 的核心技术！** 🚀
