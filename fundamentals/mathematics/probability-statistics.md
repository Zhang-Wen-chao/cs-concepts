# æ¦‚ç‡ä¸ç»Ÿè®¡ - Probability & Statistics

> ç ”ç©¶ä¸ç¡®å®šæ€§å’Œæ•°æ®è§„å¾‹çš„æ•°å­¦ï¼Œæ˜¯æœºå™¨å­¦ä¹ å’Œæ•°æ®ç§‘å­¦çš„æ ¸å¿ƒåŸºç¡€

## ğŸ¯ ä¸ºä»€ä¹ˆè¦å­¦æ¦‚ç‡ç»Ÿè®¡ï¼Ÿ

åœ¨è®¡ç®—æœºç§‘å­¦ä¸­ï¼Œæˆ‘ä»¬ç»å¸¸é¢å¯¹ä¸ç¡®å®šæ€§å’Œéœ€è¦ä»æ•°æ®ä¸­æå–ä¿¡æ¯ï¼š

- **æœºå™¨å­¦ä¹ **ï¼šè´å¶æ–¯æ¨ç†ã€æ¦‚ç‡å›¾æ¨¡å‹ã€å‚æ•°ä¼°è®¡
- **æ•°æ®ç§‘å­¦**ï¼šç»Ÿè®¡æ¨æ–­ã€å‡è®¾æ£€éªŒã€ç½®ä¿¡åŒºé—´
- **ç®—æ³•åˆ†æ**ï¼šéšæœºç®—æ³•ã€æœŸæœ›å¤æ‚åº¦åˆ†æ
- **ç½‘ç»œå®‰å…¨**ï¼šå¯†ç å­¦ä¸­çš„éšæœºæ€§ã€æ”»å‡»æ¦‚ç‡è¯„ä¼°
- **ç³»ç»Ÿè®¾è®¡**ï¼šå¯é æ€§åˆ†æã€æ€§èƒ½å»ºæ¨¡
- **äººå·¥æ™ºèƒ½**ï¼šä¸ç¡®å®šæ€§æ¨ç†ã€å†³ç­–ç†è®º

**æ ¸å¿ƒæ€æƒ³**ï¼šæ¦‚ç‡å¸®æˆ‘ä»¬é‡åŒ–ä¸ç¡®å®šæ€§ï¼Œç»Ÿè®¡å¸®æˆ‘ä»¬ä»æœ‰é™æ ·æœ¬æ¨æ–­æ€»ä½“è§„å¾‹ã€‚

## ğŸ“š æ ¸å¿ƒæ¦‚å¿µä½“ç³»

### 1. [æ¦‚ç‡åŸºç¡€](#æ¦‚ç‡åŸºç¡€)
- æ ·æœ¬ç©ºé—´å’Œäº‹ä»¶
- æ¦‚ç‡çš„å®šä¹‰å’Œæ€§è´¨
- æ¡ä»¶æ¦‚ç‡å’Œç‹¬ç«‹æ€§

### 2. [éšæœºå˜é‡](#éšæœºå˜é‡)
- ç¦»æ•£éšæœºå˜é‡
- è¿ç»­éšæœºå˜é‡
- æœŸæœ›å€¼å’Œæ–¹å·®

### 3. [é‡è¦åˆ†å¸ƒ](#é‡è¦åˆ†å¸ƒ)
- ç¦»æ•£åˆ†å¸ƒï¼šä¼¯åŠªåˆ©ã€äºŒé¡¹ã€æ³Šæ¾
- è¿ç»­åˆ†å¸ƒï¼šå‡åŒ€ã€æ­£æ€ã€æŒ‡æ•°

### 4. [ç»Ÿè®¡æ¨æ–­](#ç»Ÿè®¡æ¨æ–­)
- å‚æ•°ä¼°è®¡
- å‡è®¾æ£€éªŒ
- ç½®ä¿¡åŒºé—´

### 5. [è´å¶æ–¯æ¨ç†](#è´å¶æ–¯æ¨ç†)
- è´å¶æ–¯å®šç†
- å…ˆéªŒå’ŒåéªŒæ¦‚ç‡
- è´å¶æ–¯ç½‘ç»œ

---

## æ¦‚ç‡åŸºç¡€

### ä»€ä¹ˆæ˜¯æ¦‚ç‡ï¼Ÿ

**æ¦‚ç‡**æ˜¯å¯¹ä¸ç¡®å®šäº‹ä»¶å‘ç”Ÿå¯èƒ½æ€§çš„æ•°å€¼åº¦é‡ï¼Œä»‹äº0å’Œ1ä¹‹é—´ã€‚

**æ ·æœ¬ç©ºé—´**($\Omega$)ï¼šæ‰€æœ‰å¯èƒ½ç»“æœçš„é›†åˆ
**äº‹ä»¶**(A)ï¼šæ ·æœ¬ç©ºé—´çš„å­é›†

**ä¾‹å­**ï¼šæŠ›ç¡¬å¸
- æ ·æœ¬ç©ºé—´ï¼š$\Omega = \{æ­£é¢, åé¢\}$
- äº‹ä»¶Aï¼š"å¾—åˆ°æ­£é¢" = $\{æ­£é¢\}$
- $P(A) = 0.5$

### æ¦‚ç‡çš„å®šä¹‰

**å¤å…¸æ¦‚ç‡**ï¼ˆç­‰å¯èƒ½æƒ…å†µï¼‰ï¼š
$$P(A) = \frac{|A|}{|\Omega|} = \frac{\text{æœ‰åˆ©ç»“æœæ•°}}{\text{æ€»ç»“æœæ•°}}$$

**é¢‘ç‡å®šä¹‰**ï¼ˆå¤§æ•°å®šå¾‹ï¼‰ï¼š
$$P(A) = \lim_{n \to \infty} \frac{n(A)}{n}$$

**å…¬ç†åŒ–å®šä¹‰**ï¼ˆKolmogorovå…¬ç†ï¼‰ï¼š
1. $P(A) \geq 0$ å¯¹æ‰€æœ‰äº‹ä»¶A
2. $P(\Omega) = 1$
3. å¯¹äº’æ–¥äº‹ä»¶ï¼š$P(A \cup B) = P(A) + P(B)$

```python
import numpy as np
import matplotlib.pyplot as plt

# ç”¨é¢‘ç‡é€¼è¿‘æ¦‚ç‡ï¼šæŠ›ç¡¬å¸å®éªŒ
def coin_flip_simulation(n_trials):
    """æ¨¡æ‹ŸæŠ›ç¡¬å¸ï¼Œè§‚å¯Ÿé¢‘ç‡å¦‚ä½•é€¼è¿‘æ¦‚ç‡"""
    results = np.random.choice(['H', 'T'], n_trials)
    heads_count = np.cumsum(results == 'H')
    trials = np.arange(1, n_trials + 1)
    frequencies = heads_count / trials

    return trials, frequencies

# è¿è¡Œæ¨¡æ‹Ÿ
trials, freqs = coin_flip_simulation(10000)
print(f"10000æ¬¡è¯•éªŒåï¼Œæ­£é¢é¢‘ç‡: {freqs[-1]:.4f}")
print(f"ç†è®ºæ¦‚ç‡: 0.5000")
```

### æ¡ä»¶æ¦‚ç‡

**å®šä¹‰**ï¼šåœ¨äº‹ä»¶Bå‘ç”Ÿçš„æ¡ä»¶ä¸‹ï¼Œäº‹ä»¶Aå‘ç”Ÿçš„æ¦‚ç‡
$$P(A|B) = \frac{P(A \cap B)}{P(B)}$$

**ä¹˜æ³•è§„åˆ™**ï¼š
$$P(A \cap B) = P(A|B) \cdot P(B) = P(B|A) \cdot P(A)$$

**å…¨æ¦‚ç‡å…¬å¼**ï¼š
$$P(A) = \sum_{i} P(A|B_i) \cdot P(B_i)$$

**ä¾‹å­**ï¼šç–¾ç—…è¯Šæ–­
- $P(ç—…) = 0.01$ï¼ˆæ‚£ç—…ç‡1%ï¼‰
- $P(é˜³æ€§|ç—…) = 0.95$ï¼ˆæ•æ„Ÿåº¦95%ï¼‰
- $P(é˜´æ€§|å¥åº·) = 0.98$ï¼ˆç‰¹å¼‚åº¦98%ï¼‰

æ±‚ï¼šæ£€æµ‹é˜³æ€§æ—¶çœŸçš„æ‚£ç—…çš„æ¦‚ç‡ï¼Ÿ

```python
# ç–¾ç—…è¯Šæ–­çš„è´å¶æ–¯è®¡ç®—
def medical_diagnosis():
    # å…ˆéªŒæ¦‚ç‡
    P_disease = 0.01
    P_healthy = 1 - P_disease

    # ä¼¼ç„¶æ¦‚ç‡
    P_positive_given_disease = 0.95    # æ•æ„Ÿåº¦
    P_positive_given_healthy = 0.02    # 1 - ç‰¹å¼‚åº¦

    # å…¨æ¦‚ç‡ï¼šP(é˜³æ€§)
    P_positive = (P_positive_given_disease * P_disease +
                  P_positive_given_healthy * P_healthy)

    # è´å¶æ–¯å®šç†ï¼šP(ç—…|é˜³æ€§)
    P_disease_given_positive = (P_positive_given_disease * P_disease) / P_positive

    print(f"æ£€æµ‹é˜³æ€§æ—¶æ‚£ç—…æ¦‚ç‡: {P_disease_given_positive:.4f}")
    print(f"å³ä½¿æ£€æµ‹é˜³æ€§ï¼Œæ‚£ç—…æ¦‚ç‡åªæœ‰ {P_disease_given_positive:.1%}")

medical_diagnosis()
```

### ç‹¬ç«‹æ€§

**äº‹ä»¶ç‹¬ç«‹**ï¼šAçš„å‘ç”Ÿä¸å½±å“Bå‘ç”Ÿçš„æ¦‚ç‡
$$P(A \cap B) = P(A) \cdot P(B)$$
$$P(A|B) = P(A)$$

**é‡è¦æ€§è´¨**ï¼š
- ç‹¬ç«‹ä¸ç­‰äºäº’æ–¥ï¼ˆäº’æ–¥äº‹ä»¶é€šå¸¸æ˜¯ç›¸å…³çš„ï¼‰
- ç‹¬ç«‹æ€§æ˜¯å¯¹ç§°çš„ï¼šAç‹¬ç«‹äºBï¼Œåˆ™Bä¹Ÿç‹¬ç«‹äºA

---

## éšæœºå˜é‡

### ä»€ä¹ˆæ˜¯éšæœºå˜é‡ï¼Ÿ

**éšæœºå˜é‡**æ˜¯å°†æ ·æœ¬ç©ºé—´ä¸­çš„ç»“æœæ˜ å°„åˆ°å®æ•°çš„å‡½æ•°ã€‚

**ç¦»æ•£éšæœºå˜é‡**ï¼šå¯èƒ½å–å€¼ä¸ºæœ‰é™ä¸ªæˆ–å¯æ•°æ— ç©·ä¸ª
**è¿ç»­éšæœºå˜é‡**ï¼šå¯èƒ½å–å€¼ä¸ºä¸å¯æ•°æ— ç©·ä¸ªï¼ˆåŒºé—´ï¼‰

### æ¦‚ç‡åˆ†å¸ƒ

**æ¦‚ç‡è´¨é‡å‡½æ•°**ï¼ˆPMFï¼Œç¦»æ•£ï¼‰ï¼š
$$P(X = x) = p(x)$$

**æ¦‚ç‡å¯†åº¦å‡½æ•°**ï¼ˆPDFï¼Œè¿ç»­ï¼‰ï¼š
$$P(a \leq X \leq b) = \int_a^b f(x)dx$$

**ç´¯ç§¯åˆ†å¸ƒå‡½æ•°**ï¼ˆCDFï¼‰ï¼š
$$F(x) = P(X \leq x)$$

### æœŸæœ›å€¼å’Œæ–¹å·®

**æœŸæœ›å€¼**ï¼ˆå‡å€¼ï¼‰ï¼šéšæœºå˜é‡çš„"å¹³å‡"å–å€¼
$$E[X] = \begin{cases}
\sum_x x \cdot P(X = x) & \text{ç¦»æ•£} \\
\int_{-\infty}^{\infty} x \cdot f(x)dx & \text{è¿ç»­}
\end{cases}$$

**æ–¹å·®**ï¼šéšæœºå˜é‡åç¦»å‡å€¼çš„ç¨‹åº¦
$$\text{Var}(X) = E[(X - E[X])^2] = E[X^2] - (E[X])^2$$

**æ ‡å‡†å·®**ï¼š$\sigma = \sqrt{\text{Var}(X)}$

```python
import numpy as np
from scipy import stats
import matplotlib.pyplot as plt

# æ¨¡æ‹Ÿç¦»æ•£éšæœºå˜é‡ï¼šæ·éª°å­
def dice_simulation(n_rolls=10000):
    """æ¨¡æ‹Ÿæ·éª°å­ï¼Œè®¡ç®—æœŸæœ›å’Œæ–¹å·®"""
    rolls = np.random.randint(1, 7, n_rolls)

    # ç†è®ºå€¼
    theoretical_mean = (1 + 2 + 3 + 4 + 5 + 6) / 6  # 3.5
    theoretical_var = sum((x - 3.5)**2 for x in range(1, 7)) / 6  # 2.916

    # å®éªŒå€¼
    empirical_mean = np.mean(rolls)
    empirical_var = np.var(rolls)

    print(f"æ·éª°å­ {n_rolls} æ¬¡:")
    print(f"ç†è®ºæœŸæœ›: {theoretical_mean:.3f}, å®é™…: {empirical_mean:.3f}")
    print(f"ç†è®ºæ–¹å·®: {theoretical_var:.3f}, å®é™…: {empirical_var:.3f}")

    return rolls

rolls = dice_simulation()
```

---

## é‡è¦åˆ†å¸ƒ

### ç¦»æ•£åˆ†å¸ƒ

**1. ä¼¯åŠªåˆ©åˆ†å¸ƒ** Bernoulli(p)
- å•æ¬¡è¯•éªŒï¼ŒæˆåŠŸæ¦‚ç‡ä¸ºp
- $P(X = 1) = p, P(X = 0) = 1-p$
- $E[X] = p, \text{Var}(X) = p(1-p)$

**2. äºŒé¡¹åˆ†å¸ƒ** Binomial(n, p)
- næ¬¡ç‹¬ç«‹ä¼¯åŠªåˆ©è¯•éªŒä¸­æˆåŠŸçš„æ¬¡æ•°
- $P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}$
- $E[X] = np, \text{Var}(X) = np(1-p)$

**3. æ³Šæ¾åˆ†å¸ƒ** Poisson(Î»)
- å•ä½æ—¶é—´å†…éšæœºäº‹ä»¶å‘ç”Ÿæ¬¡æ•°
- $P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!}$
- $E[X] = \lambda, \text{Var}(X) = \lambda$

```python
# å¯è§†åŒ–é‡è¦çš„ç¦»æ•£åˆ†å¸ƒ
fig, axes = plt.subplots(1, 3, figsize=(15, 4))

# ä¼¯åŠªåˆ©åˆ†å¸ƒ
p = 0.3
x_bernoulli = [0, 1]
pmf_bernoulli = [1-p, p]
axes[0].bar(x_bernoulli, pmf_bernoulli)
axes[0].set_title(f'ä¼¯åŠªåˆ©åˆ†å¸ƒ (p={p})')
axes[0].set_xlabel('X')
axes[0].set_ylabel('P(X=k)')

# äºŒé¡¹åˆ†å¸ƒ
n, p = 10, 0.3
x_binomial = range(n+1)
pmf_binomial = [stats.binom.pmf(k, n, p) for k in x_binomial]
axes[1].bar(x_binomial, pmf_binomial)
axes[1].set_title(f'äºŒé¡¹åˆ†å¸ƒ (n={n}, p={p})')
axes[1].set_xlabel('X')

# æ³Šæ¾åˆ†å¸ƒ
lam = 3
x_poisson = range(15)
pmf_poisson = [stats.poisson.pmf(k, lam) for k in x_poisson]
axes[2].bar(x_poisson, pmf_poisson)
axes[2].set_title(f'æ³Šæ¾åˆ†å¸ƒ (Î»={lam})')
axes[2].set_xlabel('X')

plt.tight_layout()
plt.show()
```

### è¿ç»­åˆ†å¸ƒ

**1. å‡åŒ€åˆ†å¸ƒ** Uniform(a, b)
- åœ¨åŒºé—´[a,b]ä¸Šç­‰æ¦‚ç‡åˆ†å¸ƒ
- $f(x) = \frac{1}{b-a}$ for $x \in [a,b]$
- $E[X] = \frac{a+b}{2}, \text{Var}(X) = \frac{(b-a)^2}{12}$

**2. æ­£æ€åˆ†å¸ƒ** Normal(Î¼, ÏƒÂ²)
- æœ€é‡è¦çš„è¿ç»­åˆ†å¸ƒï¼Œé’Ÿå½¢æ›²çº¿
- $f(x) = \frac{1}{\sigma\sqrt{2\pi}} e^{-\frac{(x-\mu)^2}{2\sigma^2}}$
- $E[X] = \mu, \text{Var}(X) = \sigma^2$

**3. æŒ‡æ•°åˆ†å¸ƒ** Exponential(Î»)
- æè¿°äº‹ä»¶é—´éš”æ—¶é—´
- $f(x) = \lambda e^{-\lambda x}$ for $x \geq 0$
- $E[X] = \frac{1}{\lambda}, \text{Var}(X) = \frac{1}{\lambda^2}$

```python
# æ­£æ€åˆ†å¸ƒçš„é‡è¦æ€§è´¨
def normal_distribution_properties():
    """æ¼”ç¤ºæ­£æ€åˆ†å¸ƒçš„68-95-99.7æ³•åˆ™"""
    mu, sigma = 0, 1
    x = np.linspace(-4, 4, 1000)
    y = stats.norm.pdf(x, mu, sigma)

    plt.figure(figsize=(10, 6))
    plt.plot(x, y, 'b-', linewidth=2, label='N(0,1)')

    # 68-95-99.7æ³•åˆ™
    for k, color in [(1, 'red'), (2, 'green'), (3, 'orange')]:
        x_fill = x[(x >= -k) & (x <= k)]
        y_fill = stats.norm.pdf(x_fill, mu, sigma)
        plt.fill_between(x_fill, y_fill, alpha=0.3, color=color,
                        label=f'Â±{k}Ïƒ: {stats.norm.cdf(k) - stats.norm.cdf(-k):.1%}')

    plt.xlabel('X')
    plt.ylabel('æ¦‚ç‡å¯†åº¦')
    plt.title('æ­£æ€åˆ†å¸ƒçš„68-95-99.7æ³•åˆ™')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.show()

normal_distribution_properties()
```

---

## ç»Ÿè®¡æ¨æ–­

### å‚æ•°ä¼°è®¡

**ç›®æ ‡**ï¼šä»æ ·æœ¬æ•°æ®ä¼°è®¡æ€»ä½“å‚æ•°

**ç‚¹ä¼°è®¡**ï¼šç”¨å•ä¸ªå€¼ä¼°è®¡å‚æ•°
- **çŸ©æ–¹æ³•**ï¼šç”¨æ ·æœ¬çŸ©ä¼°è®¡æ€»ä½“çŸ©
- **æœ€å¤§ä¼¼ç„¶ä¼°è®¡**(MLE)ï¼šä½¿æ ·æœ¬å‡ºç°æ¦‚ç‡æœ€å¤§çš„å‚æ•°å€¼

**åŒºé—´ä¼°è®¡**ï¼šç»™å‡ºå‚æ•°çš„å¯èƒ½èŒƒå›´
- **ç½®ä¿¡åŒºé—´**ï¼šæœ‰ä¸€å®šæŠŠæ¡åŒ…å«çœŸå®å‚æ•°çš„åŒºé—´

```python
def parameter_estimation_example():
    """å‚æ•°ä¼°è®¡ç¤ºä¾‹ï¼šä¼°è®¡æ­£æ€åˆ†å¸ƒçš„å‡å€¼å’Œæ–¹å·®"""
    # ç”ŸæˆçœŸå®æ•°æ®ï¼ˆæœªçŸ¥å‚æ•°Î¼=5, Ïƒ=2ï¼‰
    true_mu, true_sigma = 5, 2
    n_samples = 100
    data = np.random.normal(true_mu, true_sigma, n_samples)

    # ç‚¹ä¼°è®¡
    sample_mean = np.mean(data)
    sample_std = np.std(data, ddof=1)  # æ— åä¼°è®¡

    # 95%ç½®ä¿¡åŒºé—´ï¼ˆå‡å€¼ï¼‰
    se = sample_std / np.sqrt(n_samples)  # æ ‡å‡†è¯¯å·®
    ci_lower = sample_mean - 1.96 * se
    ci_upper = sample_mean + 1.96 * se

    print(f"çœŸå®å‚æ•°: Î¼={true_mu}, Ïƒ={true_sigma}")
    print(f"ç‚¹ä¼°è®¡: Î¼Ì‚={sample_mean:.3f}, ÏƒÌ‚={sample_std:.3f}")
    print(f"å‡å€¼95%ç½®ä¿¡åŒºé—´: [{ci_lower:.3f}, {ci_upper:.3f}]")

    # æ£€æŸ¥ç½®ä¿¡åŒºé—´æ˜¯å¦åŒ…å«çœŸå®å€¼
    contains_true = ci_lower <= true_mu <= ci_upper
    print(f"ç½®ä¿¡åŒºé—´åŒ…å«çœŸå®å‡å€¼: {contains_true}")

parameter_estimation_example()
```

### å‡è®¾æ£€éªŒ

**åŸºæœ¬æ€æƒ³**ï¼šå¯¹æ€»ä½“å‚æ•°æå‡ºå‡è®¾ï¼Œç”¨æ ·æœ¬æ•°æ®æ£€éªŒå‡è®¾æ˜¯å¦æˆç«‹

**æ­¥éª¤**ï¼š
1. å»ºç«‹å‡è®¾ï¼š$H_0$ï¼ˆåŸå‡è®¾ï¼‰vs $H_1$ï¼ˆå¤‡æ‹©å‡è®¾ï¼‰
2. é€‰æ‹©æ£€éªŒç»Ÿè®¡é‡
3. ç¡®å®šæ˜¾è‘—æ€§æ°´å¹³Î±ï¼ˆé€šå¸¸0.05ï¼‰
4. è®¡ç®—på€¼
5. åšå‡ºå†³ç­–ï¼šæ‹’ç»æˆ–æ¥å—$H_0$

**ä¸¤ç±»é”™è¯¯**ï¼š
- **ç¬¬Iç±»é”™è¯¯**ï¼šæ‹’ç»æ­£ç¡®çš„$H_0$ï¼ˆå‡é˜³æ€§ï¼‰
- **ç¬¬IIç±»é”™è¯¯**ï¼šæ¥å—é”™è¯¯çš„$H_0$ï¼ˆå‡é˜´æ€§ï¼‰

```python
def hypothesis_testing_example():
    """å‡è®¾æ£€éªŒç¤ºä¾‹ï¼šæ£€éªŒç¡¬å¸æ˜¯å¦å…¬å¹³"""
    # åŸå‡è®¾ï¼šp = 0.5ï¼ˆç¡¬å¸å…¬å¹³ï¼‰
    # å¤‡æ‹©å‡è®¾ï¼šp â‰  0.5ï¼ˆç¡¬å¸ä¸å…¬å¹³ï¼‰

    n_flips = 100
    observed_heads = 60  # è§‚å¯Ÿåˆ°60æ¬¡æ­£é¢

    # ä½¿ç”¨äºŒé¡¹æ£€éªŒ
    from scipy.stats import binom_test

    # åŒè¾¹æ£€éªŒ
    p_value = binom_test(observed_heads, n_flips, 0.5, alternative='two-sided')
    alpha = 0.05

    print(f"å®éªŒè®¾ç½®: æŠ›ç¡¬å¸{n_flips}æ¬¡ï¼Œè§‚å¯Ÿåˆ°{observed_heads}æ¬¡æ­£é¢")
    print(f"åŸå‡è®¾H0: p = 0.5 (ç¡¬å¸å…¬å¹³)")
    print(f"å¤‡æ‹©å‡è®¾H1: p â‰  0.5 (ç¡¬å¸ä¸å…¬å¹³)")
    print(f"æ˜¾è‘—æ€§æ°´å¹³Î± = {alpha}")
    print(f"på€¼ = {p_value:.4f}")

    if p_value < alpha:
        print("æ‹’ç»åŸå‡è®¾ï¼Œç¡¬å¸å¯èƒ½ä¸å…¬å¹³")
    else:
        print("æ— è¶³å¤Ÿè¯æ®æ‹’ç»åŸå‡è®¾ï¼Œç¡¬å¸å¯èƒ½æ˜¯å…¬å¹³çš„")

hypothesis_testing_example()
```

---

## è´å¶æ–¯æ¨ç†

### è´å¶æ–¯å®šç†

è´å¶æ–¯å®šç†æè¿°å¦‚ä½•æ ¹æ®æ–°è¯æ®æ›´æ–°æˆ‘ä»¬å¯¹å‡è®¾çš„ä¿¡å¿µï¼š

$$P(H|E) = \frac{P(E|H) \cdot P(H)}{P(E)}$$

å…¶ä¸­ï¼š
- $P(H|E)$ï¼šåéªŒæ¦‚ç‡ï¼ˆçœ‹åˆ°è¯æ®åå¯¹å‡è®¾çš„ä¿¡å¿µï¼‰
- $P(E|H)$ï¼šä¼¼ç„¶ï¼ˆå‡è®¾ä¸ºçœŸæ—¶è¯æ®å‡ºç°çš„æ¦‚ç‡ï¼‰
- $P(H)$ï¼šå…ˆéªŒæ¦‚ç‡ï¼ˆçœ‹åˆ°è¯æ®å‰å¯¹å‡è®¾çš„ä¿¡å¿µï¼‰
- $P(E)$ï¼šè¯æ®çš„è¾¹é™…æ¦‚ç‡

### è´å¶æ–¯æ¨ç†è¿‡ç¨‹

1. **å…ˆéªŒ**ï¼šåŸºäºå·²æœ‰çŸ¥è¯†å¯¹å‚æ•°çš„åˆå§‹ä¿¡å¿µ
2. **ä¼¼ç„¶**ï¼šç»™å®šå‚æ•°å€¼æ—¶è§‚æµ‹æ•°æ®çš„æ¦‚ç‡
3. **åéªŒ**ï¼šç»“åˆæ•°æ®å’Œå…ˆéªŒåå¯¹å‚æ•°çš„æ›´æ–°ä¿¡å¿µ

**è´å¶æ–¯ vs é¢‘ç‡æ´¾**ï¼š
- **é¢‘ç‡æ´¾**ï¼šå‚æ•°æ˜¯å›ºå®šä½†æœªçŸ¥çš„å¸¸æ•°
- **è´å¶æ–¯æ´¾**ï¼šå‚æ•°æœ¬èº«ä¹Ÿæ˜¯éšæœºå˜é‡ï¼Œæœ‰æ¦‚ç‡åˆ†å¸ƒ

```python
def bayesian_coin_flip():
    """è´å¶æ–¯ç¡¬å¸ç¿»è½¬ï¼šåŠ¨æ€æ›´æ–°å¯¹ç¡¬å¸åå‘æ€§çš„ä¿¡å¿µ"""
    # å…ˆéªŒï¼šBeta(1,1) = å‡åŒ€åˆ†å¸ƒï¼Œå³å¯¹pæ²¡æœ‰åè§
    alpha_prior = 1
    beta_prior = 1

    # è§‚æµ‹æ•°æ®ï¼š10æ¬¡æŠ›æ·çš„ç»“æœ
    observations = [1, 0, 1, 1, 0, 1, 1, 1, 0, 1]  # 1=æ­£é¢, 0=åé¢

    alpha = alpha_prior
    beta = beta_prior

    print("è´å¶æ–¯ç¡¬å¸ç¿»è½¬æ¨ç†è¿‡ç¨‹ï¼š")
    print(f"å…ˆéªŒåˆ†å¸ƒ: Beta({alpha_prior}, {beta_prior})")

    for i, obs in enumerate(observations, 1):
        # æ›´æ–°åéªŒåˆ†å¸ƒå‚æ•°
        if obs == 1:  # è§‚å¯Ÿåˆ°æ­£é¢
            alpha += 1
        else:  # è§‚å¯Ÿåˆ°åé¢
            beta += 1

        # è®¡ç®—åéªŒå‡å€¼å’Œæ–¹å·®
        posterior_mean = alpha / (alpha + beta)
        posterior_var = (alpha * beta) / ((alpha + beta)**2 * (alpha + beta + 1))

        print(f"è§‚æµ‹ {i}: {obs} -> åéªŒ Beta({alpha}, {beta}), "
              f"E[p] = {posterior_mean:.3f}, Var[p] = {posterior_var:.4f}")

bayesian_coin_flip()
```

### è´å¶æ–¯ç½‘ç»œ

è´å¶æ–¯ç½‘ç»œæ˜¯è¡¨ç¤ºå˜é‡é—´æ¦‚ç‡ä¾èµ–å…³ç³»çš„å›¾æ¨¡å‹ï¼š

```python
def simple_bayesian_network():
    """ç®€å•çš„åŒ»ç–—è¯Šæ–­è´å¶æ–¯ç½‘ç»œ"""
    # ç½‘ç»œç»“æ„ï¼šå¸çƒŸ -> è‚ºç™Œ -> Xå…‰å¼‚å¸¸
    #            è‚ºç™Œ -> å’³å—½

    # å…ˆéªŒæ¦‚ç‡
    P_smoking = 0.3

    # æ¡ä»¶æ¦‚ç‡è¡¨
    # P(è‚ºç™Œ|å¸çƒŸ)
    P_cancer_given_smoking = 0.1
    P_cancer_given_no_smoking = 0.01

    # P(å’³å—½|è‚ºç™Œ)
    P_cough_given_cancer = 0.8
    P_cough_given_no_cancer = 0.2

    # P(Xå…‰å¼‚å¸¸|è‚ºç™Œ)
    P_xray_given_cancer = 0.9
    P_xray_given_no_cancer = 0.05

    # æ¨ç†ï¼šç»™å®šå¸çƒŸå’Œå’³å—½ï¼Œæ±‚è‚ºç™Œæ¦‚ç‡
    # P(è‚ºç™Œ|å¸çƒŸ,å’³å—½) âˆ P(å’³å—½|è‚ºç™Œ) * P(è‚ºç™Œ|å¸çƒŸ)

    # è®¡ç®—è”åˆæ¦‚ç‡
    # æƒ…å†µ1ï¼šå¸çƒŸï¼Œè‚ºç™Œï¼Œå’³å—½
    prob1 = P_smoking * P_cancer_given_smoking * P_cough_given_cancer

    # æƒ…å†µ2ï¼šå¸çƒŸï¼Œæ— è‚ºç™Œï¼Œå’³å—½
    prob2 = P_smoking * (1 - P_cancer_given_smoking) * P_cough_given_no_cancer

    # å½’ä¸€åŒ–å¾—åˆ°åéªŒæ¦‚ç‡
    posterior_cancer = prob1 / (prob1 + prob2)

    print(f"å¸çƒŸä¸”å’³å—½çš„æƒ…å†µä¸‹ï¼Œæ‚£è‚ºç™Œçš„æ¦‚ç‡: {posterior_cancer:.3f}")

simple_bayesian_network()
```

---

## ğŸš€ å®é™…åº”ç”¨æ¡ˆä¾‹

### 1. A/Bæµ‹è¯•

```python
def ab_test_analysis():
    """A/Bæµ‹è¯•çš„ç»Ÿè®¡åˆ†æ"""
    # ç½‘ç«™è½¬åŒ–ç‡æµ‹è¯•
    # ç‰ˆæœ¬Aï¼š1000ç”¨æˆ·ï¼Œ50è½¬åŒ–
    # ç‰ˆæœ¬Bï¼š1000ç”¨æˆ·ï¼Œ65è½¬åŒ–

    n_a, x_a = 1000, 50  # Aç»„æ ·æœ¬é‡å’Œè½¬åŒ–æ•°
    n_b, x_b = 1000, 65  # Bç»„æ ·æœ¬é‡å’Œè½¬åŒ–æ•°

    p_a = x_a / n_a  # Aç»„è½¬åŒ–ç‡
    p_b = x_b / n_b  # Bç»„è½¬åŒ–ç‡

    # è®¡ç®—å·®å¼‚çš„æ ‡å‡†è¯¯å·®
    se_diff = np.sqrt(p_a * (1 - p_a) / n_a + p_b * (1 - p_b) / n_b)

    # Zæ£€éªŒç»Ÿè®¡é‡
    z_score = (p_b - p_a) / se_diff

    # åŒè¾¹æ£€éªŒçš„på€¼
    p_value = 2 * (1 - stats.norm.cdf(abs(z_score)))

    print(f"A/Bæµ‹è¯•ç»“æœï¼š")
    print(f"Aç»„è½¬åŒ–ç‡: {p_a:.3f} ({x_a}/{n_a})")
    print(f"Bç»„è½¬åŒ–ç‡: {p_b:.3f} ({x_b}/{n_b})")
    print(f"å·®å¼‚: {p_b - p_a:.3f}")
    print(f"Zç»Ÿè®¡é‡: {z_score:.3f}")
    print(f"på€¼: {p_value:.4f}")

    if p_value < 0.05:
        print("ç»“è®ºï¼šBç‰ˆæœ¬æ˜¾è‘—ä¼˜äºAç‰ˆæœ¬")
    else:
        print("ç»“è®ºï¼šæ²¡æœ‰æ˜¾è‘—å·®å¼‚")

ab_test_analysis()
```

### 2. æœ´ç´ è´å¶æ–¯åˆ†ç±»å™¨

```python
def naive_bayes_classifier():
    """æœ´ç´ è´å¶æ–¯æ–‡æœ¬åˆ†ç±»ç¤ºä¾‹"""
    # ç®€åŒ–çš„åƒåœ¾é‚®ä»¶åˆ†ç±»
    # ç‰¹å¾ï¼šé‚®ä»¶ä¸­åŒ…å«ç‰¹å®šè¯æ±‡

    # è®­ç»ƒæ•°æ®ï¼ˆè¯æ±‡å‡ºç°æ¦‚ç‡ï¼‰
    # P(è¯æ±‡|åƒåœ¾é‚®ä»¶)
    spam_word_probs = {
        'free': 0.8,
        'money': 0.7,
        'meeting': 0.1,
        'project': 0.05
    }

    # P(è¯æ±‡|æ­£å¸¸é‚®ä»¶)
    ham_word_probs = {
        'free': 0.2,
        'money': 0.1,
        'meeting': 0.6,
        'project': 0.7
    }

    # å…ˆéªŒæ¦‚ç‡
    P_spam = 0.4
    P_ham = 0.6

    # æµ‹è¯•é‚®ä»¶ï¼šåŒ…å« 'free' å’Œ 'project'
    test_words = ['free', 'project']

    # è®¡ç®—ä¼¼ç„¶ï¼ˆå‡è®¾è¯æ±‡ç‹¬ç«‹ï¼‰
    likelihood_spam = P_spam
    likelihood_ham = P_ham

    for word in test_words:
        likelihood_spam *= spam_word_probs.get(word, 0.01)  # å¹³æ»‘
        likelihood_ham *= ham_word_probs.get(word, 0.01)

    # å½’ä¸€åŒ–å¾—åˆ°åéªŒæ¦‚ç‡
    total_likelihood = likelihood_spam + likelihood_ham
    P_spam_given_words = likelihood_spam / total_likelihood
    P_ham_given_words = likelihood_ham / total_likelihood

    print(f"æµ‹è¯•é‚®ä»¶åŒ…å«è¯æ±‡: {test_words}")
    print(f"P(åƒåœ¾é‚®ä»¶|è¯æ±‡) = {P_spam_given_words:.3f}")
    print(f"P(æ­£å¸¸é‚®ä»¶|è¯æ±‡) = {P_ham_given_words:.3f}")

    if P_spam_given_words > P_ham_given_words:
        print("åˆ†ç±»ç»“æœï¼šåƒåœ¾é‚®ä»¶")
    else:
        print("åˆ†ç±»ç»“æœï¼šæ­£å¸¸é‚®ä»¶")

naive_bayes_classifier()
```

---

## ğŸš€ å­¦ä¹ å»ºè®®

1. **æ•°å­¦åŸºç¡€è¦æ‰å®**ï¼šæ¦‚ç‡è®ºæ¶‰åŠå¤§é‡ç§¯åˆ†å’Œæé™æ¦‚å¿µ
2. **å¤šåšè®¡ç®—ç»ƒä¹ **ï¼šæ‰‹ç®—ç®€å•é—®é¢˜ï¼ŒåŸ¹å…»ç›´è§‰
3. **ç†è§£æ¦‚å¿µæœ¬è´¨**ï¼šä¸è¦æ­»è®°å…¬å¼ï¼Œè¦ç†è§£èƒŒåçš„é€»è¾‘
4. **ç»“åˆå®é™…åº”ç”¨**ï¼šæ¯ä¸ªæ¦‚å¿µéƒ½æƒ³æƒ³åœ¨CSä¸­çš„ç”¨é€”
5. **ä½¿ç”¨ç¼–ç¨‹éªŒè¯**ï¼šç”¨æ¨¡æ‹Ÿå®éªŒéªŒè¯ç†è®ºç»“æœ

## ğŸ”— ç›¸å…³æ¦‚å¿µ

- [çº¿æ€§ä»£æ•°](linear-algebra.md) - å¤šå…ƒç»Ÿè®¡çš„åŸºç¡€
- [ç¦»æ•£æ•°å­¦](discrete-math.md) - ç»„åˆæ¦‚ç‡çš„åŸºç¡€
- [æœºå™¨å­¦ä¹ ](../../applications/artificial-intelligence/machine-learning/) - æ¦‚ç‡æ¨¡å‹çš„åº”ç”¨
- [ç®—æ³•åˆ†æ](../algorithms/) - éšæœºç®—æ³•çš„åˆ†æ

---

**è®°ä½**ï¼šæ¦‚ç‡ç»Ÿè®¡ä¸ä»…æ˜¯æ•°å­¦å·¥å…·ï¼Œæ›´æ˜¯ä¸€ç§æ€ç»´æ–¹å¼ã€‚å®ƒæ•™ä¼šæˆ‘ä»¬å¦‚ä½•åœ¨ä¸ç¡®å®šæ€§ä¸­åšå‡ºç†æ€§å†³ç­–ï¼Œè¿™åœ¨æ•°æ®é©±åŠ¨çš„ç°ä»£è®¡ç®—æœºç§‘å­¦ä¸­è‡³å…³é‡è¦ï¼