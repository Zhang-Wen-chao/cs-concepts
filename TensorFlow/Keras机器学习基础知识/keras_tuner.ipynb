{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tce3stUlHN0L"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "execution": {
     "iopub.execute_input": "2023-11-08T00:34:44.508580Z",
     "iopub.status.busy": "2023-11-08T00:34:44.508306Z",
     "iopub.status.idle": "2023-11-08T00:34:44.512543Z",
     "shell.execute_reply": "2023-11-08T00:34:44.511858Z"
    },
    "id": "tuOe1ymfHZPu"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qFdPvlXBOdUN"
   },
   "source": [
    "# Keras Tuner 简介"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfBg1C5NB3X0"
   },
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>     <a target=\"_blank\" href=\"https://tensorflow.google.cn/tutorials/keras/keras_tuner\"><img src=\"https://tensorflow.google.cn/images/tf_logo_32px.png\"> 在 TensorFlow.org 上查看</a>   </td>\n",
    "  <td><a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/keras/keras_tuner.ipynb\"><img src=\"https://tensorflow.google.cn/images/colab_logo_32px.png\">在 Google Colab 中运行</a></td>\n",
    "  <td><a target=\"_blank\" href=\"https://github.com/tensorflow/docs-l10n/blob/master/site/zh-cn/tutorials/keras/keras_tuner.ipynb\"><img src=\"https://tensorflow.google.cn/images/GitHub-Mark-32px.png\">在 GitHub 上查看源代码</a></td>\n",
    "  <td><a href=\"https://storage.googleapis.com/tensorflow_docs/docs-l10n/site/zh-cn/tutorials/keras/keras_tuner.ipynb\"><img src=\"https://tensorflow.google.cn/images/download_logo_32px.png\">下载笔记本</a></td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHxb-dlhMIzW"
   },
   "source": [
    "## 概述\n",
    "\n",
    "Keras Tuner 是一个库，可帮助您为 TensorFlow 程序选择最佳的超参数集。为您的机器学习 (ML) 应用选择正确的超参数集，这一过程称为*超参数调节*或*超调*。\n",
    "\n",
    "超参数是控制训练过程和 ML 模型拓扑的变量。这些变量在训练过程中保持不变，并会直接影响 ML 程序的性能。超参数有两种类型：\n",
    "\n",
    "1. **模型超参数**：影响模型的选择，例如隐藏层的数量和宽度\n",
    "2. **算法超参数**：影响学习算法的速度和质量，例如随机梯度下降 (SGD) 的学习率以及 k 近邻 (KNN) 分类器的近邻数\n",
    "\n",
    "在本教程中，您将使用 Keras Tuner 对图像分类应用执行超调。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUXex9ctTuDB"
   },
   "source": [
    "## 设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T00:34:44.516316Z",
     "iopub.status.busy": "2023-11-08T00:34:44.516091Z",
     "iopub.status.idle": "2023-11-08T00:34:47.108394Z",
     "shell.execute_reply": "2023-11-08T00:34:47.107577Z"
    },
    "id": "IqR2PQG4ZaZ0"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g83Lwsy-Aq2_"
   },
   "source": [
    "安装并导入 Keras Tuner。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T00:34:47.113108Z",
     "iopub.status.busy": "2023-11-08T00:34:47.112636Z",
     "iopub.status.idle": "2023-11-08T00:34:49.575931Z",
     "shell.execute_reply": "2023-11-08T00:34:49.574737Z"
    },
    "id": "hpMLpbt9jcO6"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T00:34:49.580641Z",
     "iopub.status.busy": "2023-11-08T00:34:49.580301Z",
     "iopub.status.idle": "2023-11-08T00:34:49.961945Z",
     "shell.execute_reply": "2023-11-08T00:34:49.960909Z"
    },
    "id": "_leAIdFKAxAD"
   },
   "outputs": [],
   "source": [
    "import keras_tuner as kt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ReV_UXOgCZvx"
   },
   "source": [
    "## 下载并准备数据集\n",
    "\n",
    "在本教程中，您将使用 Keras Tuner 为某个对 [Fashion MNIST 数据集](https://github.com/zalandoresearch/fashion-mnist)内的服装图像进行分类的机器学习模型找到最佳超参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HljH_ENLEdHa"
   },
   "source": [
    "加载数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T00:34:49.966935Z",
     "iopub.status.busy": "2023-11-08T00:34:49.966282Z",
     "iopub.status.idle": "2023-11-08T00:34:50.397180Z",
     "shell.execute_reply": "2023-11-08T00:34:50.396128Z"
    },
    "id": "OHlHs9Wj_PUM"
   },
   "outputs": [],
   "source": [
    "(img_train, label_train), (img_test, label_test) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T00:34:50.401629Z",
     "iopub.status.busy": "2023-11-08T00:34:50.401339Z",
     "iopub.status.idle": "2023-11-08T00:34:50.504587Z",
     "shell.execute_reply": "2023-11-08T00:34:50.503477Z"
    },
    "id": "bLVhXs3xrUD0"
   },
   "outputs": [],
   "source": [
    "# Normalize pixel values between 0 and 1\n",
    "img_train = img_train.astype('float32') / 255.0\n",
    "img_test = img_test.astype('float32') / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5YEL2H2Ax3e"
   },
   "source": [
    "## 定义模型\n",
    "\n",
    "构建用于超调的模型时，除了模型架构之外，还要定义超参数搜索空间。您为超调设置的模型称为*超模型*。\n",
    "\n",
    "您可以通过两种方式定义超模型：\n",
    "\n",
    "- 使用模型构建工具函数\n",
    "- 将 Keras Tuner API 的 `HyperModel` 类子类化\n",
    "\n",
    "您还可以将两个预定义的 <code>HyperModel</code> 类 [HyperXception](https://keras.io/api/keras_tuner/hypermodels/hyper_xception/) 和 [HyperResNet](https://keras.io/api/keras_tuner/hypermodels/hyper_resnet/) 用于计算机视觉应用。\n",
    "\n",
    "在本教程中，您将使用模型构建工具函数来定义图像分类模型。模型构建工具函数将返回已编译的模型，并使用您以内嵌方式定义的超参数对模型进行超调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T00:34:50.509036Z",
     "iopub.status.busy": "2023-11-08T00:34:50.508739Z",
     "iopub.status.idle": "2023-11-08T00:34:50.515195Z",
     "shell.execute_reply": "2023-11-08T00:34:50.514353Z"
    },
    "id": "ZQKodC-jtsva"
   },
   "outputs": [],
   "source": [
    "def model_builder(hp):\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "  # Tune the number of units in the first Dense layer\n",
    "  # Choose an optimal value between 32-512\n",
    "  hp_units = hp.Int('units', min_value=32, max_value=512, step=32)\n",
    "  model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
    "  model.add(keras.layers.Dense(10))\n",
    "\n",
    "  # Tune the learning rate for the optimizer\n",
    "  # Choose an optimal value from 0.01, 0.001, or 0.0001\n",
    "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
    "\n",
    "  model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),\n",
    "                loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0J1VYw4q3x0b"
   },
   "source": [
    "## 实例化调节器并执行超调\n",
    "\n",
    "实例化调节器以执行超调。Keras Tuner 提供了四种调节器：`RandomSearch`、`Hyperband`、`BayesianOptimization` 和 `Sklearn`。在本教程中，您将使用 [Hyperband](https://arxiv.org/pdf/1603.06560.pdf) 调节器。\n",
    "\n",
    "要实例化 Hyperband 调节器，必须指定超模型、要优化的 `objective` 和要训练的最大周期数 (`max_epochs`)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T00:34:50.518664Z",
     "iopub.status.busy": "2023-11-08T00:34:50.518395Z",
     "iopub.status.idle": "2023-11-08T00:34:52.882548Z",
     "shell.execute_reply": "2023-11-08T00:34:52.881757Z"
    },
    "id": "oichQFly6Y46"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/TensorFlow/lib/python3.11/site-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "tuner = kt.Hyperband(model_builder,\n",
    "                     objective='val_accuracy',\n",
    "                     max_epochs=10,\n",
    "                     factor=3,\n",
    "                     directory='my_dir',\n",
    "                     project_name='intro_to_kt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaIhhdKf9VtI"
   },
   "source": [
    "Hyperband 调节算法使用自适应资源分配和早停法来快速收敛到高性能模型。该过程采用了体育竞技争冠模式的排除法。算法会将大量模型训练多个周期，并仅将性能最高的一半模型送入下一轮训练。Hyperband 通过计算 1 + log<sub><code>factor</code></sub>(`max_epochs`) 并将其向上舍入到最接近的整数来确定要训练的模型的数量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cwhBdXx0Ekj8"
   },
   "source": [
    "创建回调以在验证损失达到特定值后提前停止训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T00:34:52.886969Z",
     "iopub.status.busy": "2023-11-08T00:34:52.886703Z",
     "iopub.status.idle": "2023-11-08T00:34:52.890838Z",
     "shell.execute_reply": "2023-11-08T00:34:52.890031Z"
    },
    "id": "WT9IkS9NEjLc"
   },
   "outputs": [],
   "source": [
    "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UKghEo15Tduy"
   },
   "source": [
    "运行超参数搜索。除了上面的回调外，搜索方法的参数也与 `tf.keras.model.fit` 所用参数相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T00:34:52.894250Z",
     "iopub.status.busy": "2023-11-08T00:34:52.893979Z",
     "iopub.status.idle": "2023-11-08T00:43:56.048521Z",
     "shell.execute_reply": "2023-11-08T00:43:56.047643Z"
    },
    "id": "dSBQcTHF9cKt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 30 Complete [00h 00m 12s]\n",
      "val_accuracy: 0.8727499842643738\n",
      "\n",
      "Best val_accuracy So Far: 0.8928333520889282\n",
      "Total elapsed time: 00h 02m 40s\n",
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 224 and the optimal learning rate for the optimizer\n",
      "is 0.001.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tuner.search(img_train, label_train, epochs=50, validation_split=0.2, callbacks=[stop_early])\n",
    "\n",
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "\n",
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units')} and the optimal learning rate for the optimizer\n",
    "is {best_hps.get('learning_rate')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lak_ylf88xBv"
   },
   "source": [
    "## 训练模型\n",
    "\n",
    "使用从搜索中获得的超参数找到训练模型的最佳周期数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T00:43:56.052138Z",
     "iopub.status.busy": "2023-11-08T00:43:56.051850Z",
     "iopub.status.idle": "2023-11-08T00:47:14.494448Z",
     "shell.execute_reply": "2023-11-08T00:47:14.493641Z"
    },
    "id": "McO82AXOuxXh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 904us/step - accuracy: 0.7739 - loss: 0.6418 - val_accuracy: 0.8438 - val_loss: 0.4320\n",
      "Epoch 2/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 0.8614 - loss: 0.3897 - val_accuracy: 0.8694 - val_loss: 0.3602\n",
      "Epoch 3/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.8749 - loss: 0.3403 - val_accuracy: 0.8721 - val_loss: 0.3555\n",
      "Epoch 4/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 766us/step - accuracy: 0.8852 - loss: 0.3105 - val_accuracy: 0.8715 - val_loss: 0.3465\n",
      "Epoch 5/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 856us/step - accuracy: 0.8926 - loss: 0.2967 - val_accuracy: 0.8814 - val_loss: 0.3246\n",
      "Epoch 6/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.9003 - loss: 0.2691 - val_accuracy: 0.8839 - val_loss: 0.3288\n",
      "Epoch 7/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 787us/step - accuracy: 0.9044 - loss: 0.2545 - val_accuracy: 0.8882 - val_loss: 0.3252\n",
      "Epoch 8/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 769us/step - accuracy: 0.9047 - loss: 0.2536 - val_accuracy: 0.8823 - val_loss: 0.3318\n",
      "Epoch 9/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.9130 - loss: 0.2330 - val_accuracy: 0.8880 - val_loss: 0.3193\n",
      "Epoch 10/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9152 - loss: 0.2289 - val_accuracy: 0.8867 - val_loss: 0.3238\n",
      "Epoch 11/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 796us/step - accuracy: 0.9204 - loss: 0.2133 - val_accuracy: 0.8848 - val_loss: 0.3446\n",
      "Epoch 12/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.9205 - loss: 0.2102 - val_accuracy: 0.8894 - val_loss: 0.3080\n",
      "Epoch 13/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 814us/step - accuracy: 0.9256 - loss: 0.2002 - val_accuracy: 0.8918 - val_loss: 0.3173\n",
      "Epoch 14/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.9255 - loss: 0.1963 - val_accuracy: 0.8889 - val_loss: 0.3315\n",
      "Epoch 15/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 779us/step - accuracy: 0.9309 - loss: 0.1856 - val_accuracy: 0.8927 - val_loss: 0.3181\n",
      "Epoch 16/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 784us/step - accuracy: 0.9336 - loss: 0.1768 - val_accuracy: 0.8901 - val_loss: 0.3250\n",
      "Epoch 17/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 771us/step - accuracy: 0.9340 - loss: 0.1766 - val_accuracy: 0.8817 - val_loss: 0.3728\n",
      "Epoch 18/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 884us/step - accuracy: 0.9351 - loss: 0.1712 - val_accuracy: 0.8903 - val_loss: 0.3458\n",
      "Epoch 19/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 762us/step - accuracy: 0.9381 - loss: 0.1651 - val_accuracy: 0.8867 - val_loss: 0.3487\n",
      "Epoch 20/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 773us/step - accuracy: 0.9412 - loss: 0.1605 - val_accuracy: 0.8923 - val_loss: 0.3391\n",
      "Epoch 21/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 776us/step - accuracy: 0.9431 - loss: 0.1539 - val_accuracy: 0.8978 - val_loss: 0.3236\n",
      "Epoch 22/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 774us/step - accuracy: 0.9435 - loss: 0.1486 - val_accuracy: 0.8968 - val_loss: 0.3446\n",
      "Epoch 23/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 804us/step - accuracy: 0.9469 - loss: 0.1418 - val_accuracy: 0.8912 - val_loss: 0.3517\n",
      "Epoch 24/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 817us/step - accuracy: 0.9468 - loss: 0.1416 - val_accuracy: 0.8936 - val_loss: 0.3376\n",
      "Epoch 25/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 746us/step - accuracy: 0.9483 - loss: 0.1369 - val_accuracy: 0.8932 - val_loss: 0.3621\n",
      "Epoch 26/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 761us/step - accuracy: 0.9514 - loss: 0.1294 - val_accuracy: 0.8914 - val_loss: 0.3755\n",
      "Epoch 27/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 770us/step - accuracy: 0.9521 - loss: 0.1282 - val_accuracy: 0.8857 - val_loss: 0.4131\n",
      "Epoch 28/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 859us/step - accuracy: 0.9515 - loss: 0.1267 - val_accuracy: 0.8946 - val_loss: 0.3788\n",
      "Epoch 29/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 760us/step - accuracy: 0.9551 - loss: 0.1233 - val_accuracy: 0.8925 - val_loss: 0.3971\n",
      "Epoch 30/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.9545 - loss: 0.1204 - val_accuracy: 0.8854 - val_loss: 0.4154\n",
      "Epoch 31/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806us/step - accuracy: 0.9556 - loss: 0.1191 - val_accuracy: 0.8942 - val_loss: 0.4080\n",
      "Epoch 32/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.9558 - loss: 0.1164 - val_accuracy: 0.8913 - val_loss: 0.4154\n",
      "Epoch 33/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 742us/step - accuracy: 0.9560 - loss: 0.1174 - val_accuracy: 0.8974 - val_loss: 0.3953\n",
      "Epoch 34/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 839us/step - accuracy: 0.9582 - loss: 0.1083 - val_accuracy: 0.8879 - val_loss: 0.4484\n",
      "Epoch 35/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 847us/step - accuracy: 0.9600 - loss: 0.1062 - val_accuracy: 0.8903 - val_loss: 0.4052\n",
      "Epoch 36/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 777us/step - accuracy: 0.9594 - loss: 0.1055 - val_accuracy: 0.8935 - val_loss: 0.4091\n",
      "Epoch 37/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 861us/step - accuracy: 0.9606 - loss: 0.1029 - val_accuracy: 0.8891 - val_loss: 0.4406\n",
      "Epoch 38/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 923us/step - accuracy: 0.9627 - loss: 0.0976 - val_accuracy: 0.8926 - val_loss: 0.4208\n",
      "Epoch 39/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 913us/step - accuracy: 0.9654 - loss: 0.0928 - val_accuracy: 0.8943 - val_loss: 0.4456\n",
      "Epoch 40/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 781us/step - accuracy: 0.9642 - loss: 0.0953 - val_accuracy: 0.8928 - val_loss: 0.4378\n",
      "Epoch 41/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809us/step - accuracy: 0.9659 - loss: 0.0926 - val_accuracy: 0.8958 - val_loss: 0.4419\n",
      "Epoch 42/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 867us/step - accuracy: 0.9635 - loss: 0.0929 - val_accuracy: 0.8942 - val_loss: 0.4558\n",
      "Epoch 43/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 921us/step - accuracy: 0.9667 - loss: 0.0892 - val_accuracy: 0.8897 - val_loss: 0.4779\n",
      "Epoch 44/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 745us/step - accuracy: 0.9681 - loss: 0.0866 - val_accuracy: 0.8923 - val_loss: 0.4547\n",
      "Epoch 45/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 736us/step - accuracy: 0.9688 - loss: 0.0828 - val_accuracy: 0.8832 - val_loss: 0.5106\n",
      "Epoch 46/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 757us/step - accuracy: 0.9666 - loss: 0.0873 - val_accuracy: 0.8924 - val_loss: 0.4752\n",
      "Epoch 47/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815us/step - accuracy: 0.9698 - loss: 0.0800 - val_accuracy: 0.8931 - val_loss: 0.4841\n",
      "Epoch 48/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.9712 - loss: 0.0761 - val_accuracy: 0.8958 - val_loss: 0.4812\n",
      "Epoch 49/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.9705 - loss: 0.0777 - val_accuracy: 0.8949 - val_loss: 0.5040\n",
      "Epoch 50/50\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 768us/step - accuracy: 0.9704 - loss: 0.0766 - val_accuracy: 0.8940 - val_loss: 0.5147\n",
      "Best epoch: 21\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(img_train, label_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_accuracy']\n",
    "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uOTSirSTI3Gp"
   },
   "source": [
    "重新实例化超模型并使用上面的最佳周期数对其进行训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T00:47:14.498504Z",
     "iopub.status.busy": "2023-11-08T00:47:14.497846Z",
     "iopub.status.idle": "2023-11-08T00:48:41.996845Z",
     "shell.execute_reply": "2023-11-08T00:48:41.995804Z"
    },
    "id": "NoiPUEHmMhCe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7736 - loss: 0.6402 - val_accuracy: 0.8593 - val_loss: 0.3981\n",
      "Epoch 2/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8620 - loss: 0.3837 - val_accuracy: 0.8596 - val_loss: 0.3856\n",
      "Epoch 3/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8750 - loss: 0.3402 - val_accuracy: 0.8645 - val_loss: 0.3677\n",
      "Epoch 4/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 845us/step - accuracy: 0.8865 - loss: 0.3097 - val_accuracy: 0.8742 - val_loss: 0.3487\n",
      "Epoch 5/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 748us/step - accuracy: 0.8909 - loss: 0.2944 - val_accuracy: 0.8838 - val_loss: 0.3197\n",
      "Epoch 6/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 828us/step - accuracy: 0.8988 - loss: 0.2726 - val_accuracy: 0.8762 - val_loss: 0.3383\n",
      "Epoch 7/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 754us/step - accuracy: 0.9023 - loss: 0.2627 - val_accuracy: 0.8881 - val_loss: 0.3172\n",
      "Epoch 8/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 765us/step - accuracy: 0.9086 - loss: 0.2462 - val_accuracy: 0.8932 - val_loss: 0.3024\n",
      "Epoch 9/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 808us/step - accuracy: 0.9091 - loss: 0.2406 - val_accuracy: 0.8844 - val_loss: 0.3298\n",
      "Epoch 10/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9135 - loss: 0.2295 - val_accuracy: 0.8946 - val_loss: 0.3037\n",
      "Epoch 11/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 892us/step - accuracy: 0.9169 - loss: 0.2186 - val_accuracy: 0.8871 - val_loss: 0.3193\n",
      "Epoch 12/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 852us/step - accuracy: 0.9222 - loss: 0.2075 - val_accuracy: 0.8893 - val_loss: 0.3215\n",
      "Epoch 13/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9227 - loss: 0.2048 - val_accuracy: 0.8898 - val_loss: 0.3190\n",
      "Epoch 14/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 782us/step - accuracy: 0.9254 - loss: 0.1978 - val_accuracy: 0.8896 - val_loss: 0.3281\n",
      "Epoch 15/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 759us/step - accuracy: 0.9313 - loss: 0.1871 - val_accuracy: 0.8933 - val_loss: 0.3154\n",
      "Epoch 16/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 819us/step - accuracy: 0.9306 - loss: 0.1826 - val_accuracy: 0.8866 - val_loss: 0.3480\n",
      "Epoch 17/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 821us/step - accuracy: 0.9308 - loss: 0.1845 - val_accuracy: 0.8928 - val_loss: 0.3421\n",
      "Epoch 18/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 826us/step - accuracy: 0.9373 - loss: 0.1715 - val_accuracy: 0.8939 - val_loss: 0.3416\n",
      "Epoch 19/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 786us/step - accuracy: 0.9348 - loss: 0.1698 - val_accuracy: 0.8910 - val_loss: 0.3561\n",
      "Epoch 20/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 841us/step - accuracy: 0.9415 - loss: 0.1558 - val_accuracy: 0.8875 - val_loss: 0.3551\n",
      "Epoch 21/21\n",
      "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 783us/step - accuracy: 0.9413 - loss: 0.1532 - val_accuracy: 0.8911 - val_loss: 0.3458\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x325397c10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)\n",
    "\n",
    "# Retrain the model\n",
    "hypermodel.fit(img_train, label_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MqU5ZVAaag2v"
   },
   "source": [
    "要完成本教程，请在测试数据上评估超模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-08T00:48:42.001166Z",
     "iopub.status.busy": "2023-11-08T00:48:42.000406Z",
     "iopub.status.idle": "2023-11-08T00:48:42.874908Z",
     "shell.execute_reply": "2023-11-08T00:48:42.873936Z"
    },
    "id": "9E0BTp9Ealjb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 339us/step - accuracy: 0.8862 - loss: 0.3813\n",
      "[test loss, test accuracy]: [0.3802078664302826, 0.886900007724762]\n"
     ]
    }
   ],
   "source": [
    "eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EQRpPHZsz-eC"
   },
   "source": [
    "`my_dir/intro_to_kt` 目录中包含了在超参数搜索期间每次试验（模型配置）运行的详细日志和检查点。如果重新运行超参数搜索，Keras Tuner 将使用这些日志中记录的现有状态来继续搜索。要停用此行为，请在实例化调节器时传递一个附加的 `overwrite = True` 参数。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sKwLOzKpFGAj"
   },
   "source": [
    "## 总结\n",
    "\n",
    "在本教程中，您学习了如何使用 Keras Tuner 调节模型的超参数。要详细了解 Keras Tuner，请查看以下其他资源：\n",
    "\n",
    "- [TensorFlow 博客上的 Keras Tuner](https://blog.tensorflow.org/2020/01/hyperparameter-tuning-with-keras-tuner.html)\n",
    "- [Keras Tuner 网站](https://keras-team.github.io/keras-tuner/)\n",
    "\n",
    "另请查看 TensorBoard 中的 [HParams Dashboard](https://tensorflow.google.cn/tensorboard/hyperparameter_tuning_with_hparams)，以交互方式调节模型超参数。"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Tce3stUlHN0L"
   ],
   "name": "keras_tuner.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
