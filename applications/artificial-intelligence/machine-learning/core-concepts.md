# 机器学习核心概念 (Machine Learning Core Concepts)

> 从数据中自动学习规律的基础知识

## 🎯 什么是机器学习？

**一句话理解：**
机器学习 = 让计算机从数据中自动学习规律，而不是显式编程

**传统编程 vs 机器学习：**
```
传统编程：
规则 + 数据 → 输出
例：if x > 10: return "大"

机器学习：
数据 + 输出 → 规则
例：给很多(x, "大"/"小")的例子 → 学到规则
```

---

## 📖 三大学习范式

### 1. 监督学习 (Supervised Learning)

**核心思想：** 从标注的数据中学习

```
有老师教学：
• 给数据：猫的照片
• 给答案：这是猫
• 学习：识别猫的规律
```

**例子：**
```python
# 训练数据（有标签）
X_train = [[身高, 体重], ...]  # 特征
y_train = [男, 女, 男, ...]     # 标签（答案）

# 学习
model.fit(X_train, y_train)

# 预测
X_new = [[180, 75]]
prediction = model.predict(X_new)  # → 男
```

**应用场景：**
- 图像分类（猫狗识别）
- 垃圾邮件检测
- 房价预测
- **推荐系统中的点击率预估** ⭐️

**两种类型：**

**分类 (Classification)：** 输出是离散的类别
```
输入：邮件内容
输出：垃圾邮件 / 正常邮件

输入：用户特征 + 物品特征
输出：点击 / 不点击  ← 推荐系统
```

**回归 (Regression)：** 输出是连续的数值
```
输入：房子特征（面积、地段）
输出：房价（100万、150万...）

输入：用户历史行为
输出：停留时长（0.5秒、10秒...）
```

---

### 2. 无监督学习 (Unsupervised Learning)

**核心思想：** 从未标注的数据中发现模式

```
没有老师，自己探索：
• 给数据：大量照片
• 不给答案
• 学习：发现数据的结构/分组
```

**例子：**
```python
# 训练数据（无标签）
X = [[用户行为特征], ...]

# 聚类
clusters = model.fit_predict(X)
# 自动发现：用户分为3类
# 类0：重度游戏玩家
# 类1：购物爱好者
# 类2：视频观看者
```

**应用场景：**
- 用户分群（市场细分）
- 异常检测
- 降维（PCA）
- **推荐系统中的物品聚类** ⭐️

**常见算法：**
- K-means 聚类
- 层次聚类
- 主成分分析（PCA）

---

### 3. 强化学习 (Reinforcement Learning)

**核心思想：** 通过试错和奖励学习策略

```
像训练宠物：
• 做对了 → 奖励
• 做错了 → 惩罚
• 学习：最大化长期奖励
```

**例子：**
- AlphaGo（围棋）
- 游戏AI
- 机器人控制
- 推荐系统的长期收益优化

---

## 📊 机器学习工作流程

### 1. 数据准备

**数据集划分：**
```
所有数据 (100%)
├── 训练集 (70-80%)     → 学习规律
├── 验证集 (10-15%)     → 调整参数
└── 测试集 (10-15%)     → 最终评估

为什么要分？
• 训练集：学习
• 验证集：选择最好的模型（防止过拟合）
• 测试集：评估真实性能（从未见过）
```

**重要原则：**
```
❌ 测试集的数据绝对不能用于训练
❌ 不能根据测试集调整模型
✅ 测试集只在最后评估时用一次
```

**特征 (Features) 和 标签 (Labels)：**
```python
# 推荐系统例子
features = {
    "user_id": 12345,
    "user_age": 25,
    "user_gender": "M",
    "item_id": 67890,
    "item_category": "电子产品",
    "item_price": 999.0
}

label = 1  # 1 = 点击, 0 = 不点击
```

---

### 2. 模型训练

**核心概念：损失函数 (Loss Function)**

损失函数衡量预测和真实值的差距

**常见损失函数：**

**均方误差 (MSE) - 用于回归：**
```
Loss = 1/n × Σ(预测值 - 真实值)²

例子：
真实值：[10, 20, 30]
预测值：[12, 18, 32]
MSE = ((10-12)² + (20-18)² + (30-32)²) / 3
    = (4 + 4 + 4) / 3 = 4
```

**交叉熵损失 (Cross Entropy) - 用于分类：**
```
Loss = -Σ y × log(ŷ)

用于推荐系统的点击率预估！⭐️

例子：
真实值：点击 (y=1)
预测概率：0.8
Loss = -1 × log(0.8) = 0.22

真实值：不点击 (y=0)
预测概率：0.2（不点击概率0.8）
Loss = -0 × log(0.2) = 0
```

**为什么需要损失函数？**
```
损失函数 → 量化模型的"错误程度"
         → 指导模型如何改进
         → 通过最小化损失来学习
```

---

### 3. 优化算法：梯度下降 (Gradient Descent)

**核心思想：** 沿着损失函数减小的方向更新参数

**形象理解：**
```
想象你在山上，想走到最低点（最小损失）：
1. 看看脚下哪个方向是下坡（计算梯度）
2. 朝那个方向走一小步（更新参数）
3. 重复，直到到达山谷底部（收敛）
```

**数学表达：**
```
θ_new = θ_old - α × ∇Loss

θ: 模型参数（如权重）
α: 学习率（步长）
∇Loss: 损失函数的梯度（方向）
```

**学习率的影响：**
```
学习率太大：
• 步子太大
• 可能跳过最优点
• 损失震荡

学习率太小：
• 步子太小
• 收敛很慢
• 可能卡在局部最优

通常：α = 0.001 ~ 0.1
```

**变种算法：**
```
SGD（随机梯度下降）：
• 每次只用一个样本更新
• 速度快，但不稳定

Mini-batch SGD：
• 每次用一小批样本（如32个）
• 推荐系统常用！⭐️

Adam（自适应学习率）：
• 自动调整学习率
• 效果好，最常用
• 深度学习推荐
```

---

## 🎯 核心概念：过拟合与欠拟合

### 欠拟合 (Underfitting)

**问题：** 模型太简单，学不到规律

```
比喻：
用直线拟合曲线 → 拟合不好

表现：
• 训练集上表现差
• 测试集上也表现差
```

**解决方法：**
- 增加模型复杂度
- 增加特征
- 训练更长时间

---

### 过拟合 (Overfitting)

**问题：** 模型太复杂，记住了训练数据的噪声

```
比喻：
死记硬背考题 → 考原题100分
换个题目 → 不会做

表现：
• 训练集上表现好（准确率很高）
• 测试集上表现差（泛化能力差）
```

**如何发现过拟合？**
```python
训练集准确率：95%
测试集准确率：70%  ← 差距大，过拟合！

理想情况：
训练集准确率：85%
测试集准确率：83%  ← 差距小，泛化好
```

**解决方法：**

**1. 获取更多数据**
```
数据越多，越难记住所有细节
```

**2. 正则化 (Regularization)**
```
在损失函数中惩罚复杂模型：
Loss = 原始Loss + λ × ||权重||²

λ: 正则化系数
• λ大 → 模型简单（可能欠拟合）
• λ小 → 模型复杂（可能过拟合）
```

**3. Dropout（深度学习）**
```
训练时随机关闭一些神经元：
• 防止神经元之间过度依赖
• 推荐系统常用！⭐️
```

**4. Early Stopping**
```
监控验证集性能：
• 验证集性能开始下降 → 停止训练
• 防止在训练集上过度优化
```

---

## 📈 模型评估指标

### 分类问题

**混淆矩阵 (Confusion Matrix)：**
```
              预测为正   预测为负
实际为正      TP         FN
实际为负      FP         TN

TP (True Positive):  正确预测为正
FP (False Positive): 错误预测为正
TN (True Negative):  正确预测为负
FN (False Negative): 错误预测为负
```

**准确率 (Accuracy)：**
```
Accuracy = (TP + TN) / (TP + TN + FP + FN)

例子：100个样本，90个预测对 → 90%准确率

问题：样本不平衡时会误导
例：100个样本，95个负样本，5个正样本
全部预测为负 → 95%准确率（但模型无用）
```

**精确率 (Precision) 和 召回率 (Recall)：**
```
Precision = TP / (TP + FP)
"预测为正的里面，有多少真的是正"

Recall = TP / (TP + FN)
"实际为正的里面，找到了多少"

推荐系统例子：
Precision: 推荐的100个物品中，有20个被点击 → 20%
Recall: 用户感兴趣的50个物品中，推荐了15个 → 30%
```

**F1 Score：**
```
F1 = 2 × (Precision × Recall) / (Precision + Recall)

平衡精确率和召回率
```

**AUC (Area Under Curve)：**
```
ROC曲线下的面积
• AUC = 1: 完美分类器
• AUC = 0.5: 随机猜测
• AUC = 0.8+: 不错的模型

推荐系统常用指标！⭐️
不受样本不平衡影响
```

---

### 回归问题

**均方误差 (MSE)：**
```
MSE = 1/n × Σ(预测值 - 真实值)²

值越小越好
```

**平均绝对误差 (MAE)：**
```
MAE = 1/n × Σ|预测值 - 真实值|

对异常值不敏感
```

**R² (决定系数)：**
```
R² = 1 - (模型误差 / 基准误差)

• R² = 1: 完美预测
• R² = 0: 和平均值一样
• R² < 0: 比平均值还差
```

---

## 🔧 特征工程

### 什么是特征？

```
特征 = 用来描述数据的属性

推荐系统的特征：
用户特征：年龄、性别、地域、历史行为...
物品特征：类别、价格、品牌、销量...
交叉特征：用户年龄×物品类别
```

### 特征类型

**1. 数值特征 (Numerical)**
```
例子：年龄、价格、评分
可以直接用于模型
```

**2. 类别特征 (Categorical)**
```
例子：性别、城市、商品类别

需要编码：
• One-hot 编码
  性别: 男 → [1, 0]
        女 → [0, 1]

• Embedding（推荐系统常用）⭐️
  user_id: 12345 → [0.2, -0.5, 0.8, ...]  (64维向量)
  item_id: 67890 → [0.1, 0.3, -0.2, ...]  (64维向量)
```

**3. 文本特征**
```
例子：商品描述、用户评论

需要处理：
• TF-IDF
• Word Embedding (Word2Vec, BERT)
```

**4. 序列特征**
```
例子：用户历史行为序列

商品浏览序列：[item1, item2, item3, ...]
需要特殊处理（RNN, Transformer）
```

### 特征归一化

**为什么需要？**
```
特征尺度差异大会影响模型：
年龄：20-60
收入：3000-50000  ← 比年龄大很多

梯度下降会偏向大数值特征
```

**常见方法：**

**Min-Max 归一化：**
```
x_new = (x - min) / (max - min)
结果：[0, 1]
```

**标准化 (Z-score)：**
```
x_new = (x - mean) / std
结果：均值0，方差1
```

---

## 🎓 推荐系统中的机器学习

### 核心任务

**1. 点击率预估 (CTR Prediction)**
```
输入：用户特征 + 物品特征
输出：点击概率 [0, 1]

本质：二分类问题
模型：逻辑回归 → DNN → DeepFM
损失：交叉熵
```

**2. 排序 (Ranking)**
```
输入：候选物品列表
输出：按相关性排序的列表

评估：NDCG, MRR
```

**3. 召回 (Recall/Retrieval)**
```
从海量物品中快速筛选候选集

方法：
• 协同过滤
• 双塔模型 ⭐️
• 向量检索（ANN）
```

### 关键特点

**样本不平衡：**
```
点击样本：1%
未点击样本：99%

需要：
• 样本加权
• 负采样
```

**实时性要求：**
```
推理延迟：< 100ms
需要：
• 模型压缩
• 特征缓存
• 离线向量化
```

**冷启动问题：**
```
新用户、新物品没有历史数据

解决：
• 基于内容的推荐
• 探索与利用平衡
```

---

## 🔗 与其他概念的联系

### 与深度学习
```
机器学习 ⊃ 深度学习
• 机器学习：更广泛的概念
• 深度学习：基于神经网络的机器学习

推荐系统演进：
LR → FM → Wide&Deep → DNN → DeepFM → DIN
```
参考：[神经网络基础](../deep-learning/neural-networks.md)

### 与数学基础
```
线性代数：矩阵运算、特征分解
概率统计：最大似然估计、贝叶斯
微积分：梯度、导数、优化
```
参考：[数学基础](../../../fundamentals/mathematics/)

### 与算法
```
优化算法：梯度下降
搜索算法：超参数搜索
```
参考：[算法基础](../../../fundamentals/algorithms/)

---

## 📚 学习资源

### 入门课程
- **吴恩达《机器学习》** - Coursera，最适合入门
- **李宏毅《机器学习》** - YouTube，中文讲解

### 实践工具
```python
# Scikit-learn - 经典机器学习
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForest
from sklearn.metrics import accuracy_score, auc

# TensorFlow/PyTorch - 深度学习
import tensorflow as tf
import torch
```

### 推荐阅读
- 《机器学习》- 周志华（西瓜书）
- 《统计学习方法》- 李航
- 《Hands-On Machine Learning》- Aurélien Géron

---

## 🎯 核心要点总结

```
1. 三大范式
   • 监督学习：有标签数据（推荐系统主要用）
   • 无监督学习：无标签数据（聚类、降维）
   • 强化学习：通过奖励学习（长期优化）

2. 训练流程
   • 数据划分：训练/验证/测试
   • 损失函数：MSE（回归）、交叉熵（分类）
   • 优化：梯度下降及变种（Adam）

3. 关键挑战
   • 过拟合：正则化、Dropout、Early Stopping
   • 欠拟合：增加复杂度、更多特征
   • 评估：准确率、AUC、F1

4. 推荐系统应用
   • CTR预估：二分类 + 交叉熵
   • 样本不平衡：加权、负采样
   • 特征：数值、类别、Embedding
```

---

**掌握这些核心概念，你就可以开始学习推荐系统了！** 🚀

**下一步：** [神经网络基础](../deep-learning/neural-networks.md)
