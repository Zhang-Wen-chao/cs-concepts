# 推荐系统基础 (Recommendation Systems Basics)

> 从海量信息中为用户推荐感兴趣的内容

## 🎯 什么是推荐系统？

**一句话理解：**
推荐系统 = 连接"人"和"物"的智能匹配系统

**核心问题：**
```
问题：信息过载
• 淘宝：10亿+商品
• YouTube：每分钟上传500小时视频
• 抖音：海量短视频

用户无法浏览所有内容 → 需要推荐系统帮助筛选
```

**推荐系统的价值：**
```
对用户：
• 发现感兴趣的内容
• 节省搜索时间
• 提升体验

对平台：
• 增加用户停留时间
• 提升点击率、转化率
• 增加营收

数据：
• YouTube：70%观看来自推荐
• Amazon：35%销售来自推荐
• Netflix：80%观看来自推荐
```

---

## 📖 推荐系统架构

### 典型的四层架构

```
召回层 (Recall/Retrieval)
    ↓
粗排层 (Pre-ranking)
    ↓
精排层 (Ranking)
    ↓
重排层 (Re-ranking)
```

### 1. 召回层 ⭐️ 重要

**目标：** 从海量候选中快速筛选出几百到几千个候选

```
输入：全部物品（百万~亿级）
输出：候选集（几百~几千）

要求：
• 速度快（毫秒级）
• 召回率高（不能漏掉好的）
• 多样性好
```

**常见召回策略：**

**多路召回：**
```
路1：协同过滤
    • 喜欢A的人也喜欢B
    • 200个候选

路2：内容召回
    • 基于物品相似度
    • 150个候选

路3：热门召回
    • 最近流行的
    • 100个候选

路4：双塔召回 ⭐️
    • 用户向量 × 物品向量
    • 300个候选

合并：去重 → 总共500个候选
```

**双塔召回（重点）：**
```
训练阶段：
用户特征 → 用户塔(MLP) → 用户向量(64维)
物品特征 → 物品塔(MLP) → 物品向量(64维)
相似度 = dot(用户向量, 物品向量)
损失 = 交叉熵(相似度, 是否点击)

离线阶段：
• 预计算所有物品的向量
• 存入向量数据库（如Faiss）

在线召回：
• 实时计算用户向量
• ANN检索最相似的Top-K物品
• 速度：<50ms
```

---

### 2. 粗排层

**目标：** 进一步筛选，从几千降到几百

```
输入：500个候选
输出：100个候选

特点：
• 比召回慢，但比精排快
• 使用简化的模型
• 减轻精排压力
```

**常用方法：**
```
• 简化版的精排模型
• 更少的特征
• 更小的网络
```

---

### 3. 精排层 ⭐️ 核心

**目标：** 精确预测用户对每个物品的兴趣程度

```
输入：100个候选
输出：每个候选的预测分数

特点：
• 可以用复杂模型
• 更多特征
• 更准确
```

**核心任务：CTR预估（点击率预估）**
```
输入：用户特征 + 物品特征 + 上下文特征
输出：点击概率 P(click | user, item, context)

模型演进：
LR → FM → FFM → Wide&Deep → DeepFM → DIN → DIEN
```

---

### 4. 重排层

**目标：** 调整顺序，考虑业务规则和多样性

```
输入：精排后的列表
输出：最终展示给用户的列表

考虑因素：
• 多样性（不能全是同类型）
• 业务规则（广告、新物品）
• 探索与利用平衡
```

---

## 🎯 推荐问题建模

### 问题类型

**1. 显式反馈 (Explicit Feedback)**
```
用户明确表达喜好：
• 评分：1-5星
• 点赞/点踩
• 收藏

优点：信号明确
缺点：数据稀疏（大部分用户不评分）
```

**2. 隐式反馈 (Implicit Feedback)** ⭐️ 主流
```
从用户行为推断喜好：
• 点击
• 观看时长
• 购买
• 分享

优点：数据丰富
缺点：信号不明确（点击≠喜欢）

推荐系统主要处理隐式反馈！
```

### 推荐任务

**1. 评分预测**
```
预测用户会给物品打几分
例：Netflix电影评分预测

模型输出：连续值 [1, 5]
损失函数：MSE
```

**2. Top-N 推荐** ⭐️ 主流
```
给用户推荐N个最可能喜欢的物品
例：淘宝首页的商品推荐

模型输出：排序列表
评估指标：召回率@K, NDCG@K
```

**3. CTR 预估** ⭐️ 核心
```
预测用户点击物品的概率
例：推荐系统中的精排

模型输出：概率 [0, 1]
损失函数：交叉熵
评估指标：AUC, LogLoss
```

---

## 📊 常用特征

### 用户特征 (User Features)

**基础特征：**
```python
user_features = {
    # 人口统计学特征
    "user_id": "u_12345",
    "age": 25,
    "gender": "M",
    "city": "北京",

    # 统计特征
    "register_days": 365,
    "total_clicks": 1234,
    "total_purchases": 56,
    "avg_price": 89.5,
}
```

**行为特征：**
```python
user_behavior = {
    # 历史行为序列
    "clicked_items": ["i1", "i2", "i3", ...],  # 最近点击
    "purchased_items": ["i10", "i20", ...],    # 购买历史

    # 兴趣标签
    "interest_tags": ["电子产品", "运动", "游戏"],

    # 时间特征
    "active_hours": [20, 21, 22],  # 活跃时段
}
```

---

### 物品特征 (Item Features)

**基础特征：**
```python
item_features = {
    # 标识特征
    "item_id": "i_67890",

    # 内容特征
    "category": "电子产品",
    "brand": "小米",
    "price": 999.0,
    "tags": ["手机", "5G", "拍照"],

    # 统计特征
    "click_count": 10000,
    "purchase_count": 500,
    "avg_rating": 4.5,
    "publish_days": 30,
}
```

**文本特征：**
```python
item_content = {
    "title": "小米13 5G手机",
    "description": "骁龙8处理器，徕卡相机...",
}
# 需要用NLP处理：BERT, Word2Vec等
```

---

### 上下文特征 (Context Features)

```python
context = {
    # 时间特征
    "hour": 20,          # 当前小时
    "day_of_week": 5,    # 周五
    "is_weekend": False,

    # 设备特征
    "device": "mobile",
    "os": "iOS",
    "app_version": "3.2.1",

    # 场景特征
    "page": "首页",
    "position": 3,       # 推荐位置
}
```

---

### 交叉特征 (Cross Features)

```python
cross_features = {
    # 简单交叉
    "user_age_item_category": "25_电子产品",
    "user_gender_item_price_range": "M_中等",

    # 统计交叉
    "user_click_rate_on_category": 0.15,  # 用户对该类别的点击率
    "item_ctr_for_age_group": 0.08,       # 物品在该年龄段的CTR
}
```

**为什么需要交叉特征？**
```
单独特征：
user_age = 25
item_category = "游戏"

交叉特征捕获组合模式：
"25岁用户喜欢游戏"（年轻人喜欢游戏）
"40岁用户不喜欢游戏"

传统方法：手工构造交叉特征
深度学习：自动学习交叉 ⭐️
```

---

## 🎓 经典推荐算法

### 1. 协同过滤 (Collaborative Filtering)

**核心思想：** 利用用户行为的相似性

**User-based CF：**
```
找到相似用户 → 推荐他们喜欢的物品

例子：
• 你喜欢：A, B, C
• 相似用户喜欢：A, B, C, D
• 推荐给你：D

计算相似度：
sim(u1, u2) = cosine(vec_u1, vec_u2)
```

**Item-based CF：**
```
找到相似物品 → 推荐给喜欢这类物品的用户

例子：
• 你喜欢物品A
• 与A相似的是B
• 推荐给你：B

亚马逊："买了这个的人也买了..."
```

**优点：**
- 简单有效
- 不需要物品特征
- 可解释性强

**缺点：**
- 冷启动问题（新用户、新物品）
- 数据稀疏
- 可扩展性差（大规模数据慢）

---

### 2. 矩阵分解 (Matrix Factorization)

**核心思想：** 将用户-物品交互矩阵分解为低维表示

```
R (m×n) ≈ U (m×k) × V (n×k)ᵀ

R: 用户-物品评分矩阵（稀疏）
U: 用户隐向量矩阵
V: 物品隐向量矩阵
k: 隐向量维度（如50）

预测：
r_ui = u_u · v_i  (内积)
```

**训练：**
```
最小化：Σ (r_ui - u_u · v_i)² + λ(||u_u||² + ||v_i||²)
        已知的评分     预测      正则化
```

**代表算法：**
- SVD（奇异值分解）
- ALS（交替最小二乘）
- **BPR**（Bayesian Personalized Ranking）

**优点：**
- 处理稀疏数据
- 可扩展
- 效果好

**缺点：**
- 仍有冷启动
- 线性模型，表达能力有限

---

### 3. 深度学习方法 ⭐️ 主流

**为什么用深度学习？**
```
传统方法：
• 特征工程复杂
• 交叉特征需要手工设计
• 线性模型，表达能力有限

深度学习：
• 自动特征学习
• 自动特征交叉
• 强大的非线性表达能力
```

**经典模型：**

**Wide & Deep (Google, 2016)：**
```
Wide 部分（线性）：
• 记忆（Memorization）
• 人工交叉特征

Deep 部分（MLP）：
• 泛化（Generalization）
• 自动学习特征

concat → 输出
```

**DeepFM (2017)：**
```
FM 部分：
• 二阶特征交叉
• 代替Wide部分

Deep 部分：
• 高阶特征交叉

共享Embedding
```

**双塔模型 (Two-Tower)：** ⭐️
```
用户塔 → 用户向量
物品塔 → 物品向量
相似度 = dot(user_vec, item_vec)

优点：
• 用户和物品独立计算
• 支持大规模检索
• 召回阶段常用
```

**DIN (Deep Interest Network, Alibaba 2018)：**
```
核心：注意力机制

用户历史行为序列 + 候选物品
       ↓
   注意力权重（相关的行为权重大）
       ↓
   加权求和 → 用户兴趣表示
       ↓
      预测
```

---

## 🔧 推荐系统特有的挑战

### 1. 样本不平衡

```
正样本（点击）：1%
负样本（未点击）：99%

问题：
• 模型倾向预测全部为负
• 准确率99%但没用

解决：
• 负采样（只用一部分负样本）
• 样本加权（正样本权重大）
• Focal Loss（难样本权重大）
```

### 2. 冷启动 (Cold Start)

```
新用户：
• 没有历史行为
• 无法协同过滤

解决：
• 基于内容的推荐
• 热门物品推荐
• 引导用户标注兴趣

新物品：
• 没有被点击过
• 无法计算相似度

解决：
• 基于物品特征推荐
• 探索策略（给新物品曝光机会）
```

### 3. 探索与利用 (Exploration vs Exploitation)

```
利用（Exploitation）：
• 推荐已知用户喜欢的
• 短期收益高
• 但会造成信息茧房

探索（Exploration）：
• 推荐新的、不确定的
• 短期收益可能低
• 但有助于发现新兴趣

平衡：
• ε-greedy：90%利用，10%探索
• Thompson Sampling
• UCB算法
```

### 4. 马太效应

```
热门物品：
• 曝光多 → 点击多 → 更热门
• 形成正反馈循环

长尾物品：
• 曝光少 → 点击少 → 更冷门

问题：
• 长尾物品得不到曝光
• 降低多样性

解决：
• 多样性约束
• 打散策略
• 给长尾物品更多机会
```

---

## 📈 评估指标

### 离线评估

**1. 分类指标（CTR预估）**
```
AUC (Area Under Curve)：⭐️ 最常用
• 衡量排序能力
• 不受阈值影响
• AUC > 0.65 一般认为不错

LogLoss（交叉熵）：
• 衡量预测概率的准确性
• 越小越好
```

**2. 排序指标（Top-N推荐）**
```
Precision@K：
• 推荐的K个中，有多少是正确的
• P@10 = 3/10 = 30%

Recall@K：
• 所有正确的中，推荐了多少
• R@10 = 3/20 = 15%

NDCG@K (Normalized Discounted Cumulative Gain)：⭐️
• 考虑排序位置（前面的更重要）
• [0, 1]，越大越好
```

### 在线评估（A/B测试）

```
对照组：旧算法
实验组：新算法

关键指标：
• CTR（点击率）：点击数 / 曝光数
• CVR（转化率）：购买数 / 点击数
• 停留时长
• 日活、留存

统计显著性：
• p-value < 0.05
• 确保差异不是随机的
```

---

## 🔗 与其他概念的联系

### 与机器学习
```
推荐系统 = 机器学习的应用
• 监督学习：CTR预估
• 无监督学习：聚类、降维
• 强化学习：长期收益优化
```
参考：[机器学习核心概念](../machine-learning/core-concepts.md)

### 与深度学习
```
深度推荐模型：
• MLP：基础
• Embedding：类别特征
• 注意力机制：DIN
• 序列模型：RNN, Transformer
```
参考：[神经网络基础](../deep-learning/neural-networks.md)

---

## 🎯 核心要点总结

```
1. 推荐系统架构
   • 召回：从百万到千级
   • 粗排：从千到百级
   • 精排：精确打分
   • 重排：多样性调整

2. 核心任务
   • CTR预估：二分类问题
   • 双塔召回：向量检索
   • 排序：Top-N推荐

3. 关键特征
   • 用户特征：人口、行为
   • 物品特征：内容、统计
   • 上下文：时间、设备
   • 交叉特征：组合信息

4. 经典算法
   • 协同过滤：基于相似度
   • 矩阵分解：隐向量
   • 深度学习：自动特征交叉

5. 核心挑战
   • 样本不平衡
   • 冷启动
   • 探索与利用
   • 多样性
```

---

**掌握这些基础概念，你就可以深入学习具体的推荐模型了！** 🚀

**下一步：** [深度学习推荐系统学习路径](deep-learning-recsys-learning-path.md)
