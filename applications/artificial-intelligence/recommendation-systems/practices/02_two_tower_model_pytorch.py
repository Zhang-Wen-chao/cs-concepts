"""
åŒå¡”æ¨¡å‹ (Two-Tower Model) - PyTorchå®ç°
æ¨èç³»ç»Ÿå¬å›é˜¶æ®µçš„æ ¸å¿ƒæ·±åº¦å­¦ä¹ æ¶æ„

ä½œè€…: Zhang Wenchao
æ—¥æœŸ: 2025-11-22

====================================================================
ğŸ“– æ¨èç³»ç»Ÿå®Œæ•´é“¾è·¯
====================================================================

ç”¨æˆ·è¯·æ±‚
   â†“
1. å¬å›ï¼ˆRetrievalï¼‰â† æˆ‘ä»¬åœ¨è¿™é‡Œï¼
   - ä»ç™¾ä¸‡çº§ç‰©å“ä¸­å¿«é€Ÿç­›é€‰å‡ºå‡ åƒä¸ªå€™é€‰
   - åŒå¡”æ¨¡å‹ï¼šç”¨æˆ·å¡” + ç‰©å“å¡” â†’ å‘é‡ç›¸ä¼¼åº¦
   â†“
2. ç²—æ’ï¼ˆPre-Rankingï¼Œå¯é€‰ï¼‰
   - å‡ åƒä¸ª â†’ å‡ ç™¾ä¸ª
   â†“
3. ç²¾æ’ï¼ˆRankingï¼‰
   - å‡ ç™¾ä¸ª â†’ å‡ åä¸ª
   - Wide & Deep, DeepFM, DIN ç­‰
   â†“
4. é‡æ’ï¼ˆRe-Rankingï¼‰
   - å¤šæ ·æ€§ã€æ‰“æ•£
   â†“
5. æ··æ’
   - æ’å…¥å¹¿å‘Šã€è¿è¥å†…å®¹
   â†“
å±•ç¤ºç»™ç”¨æˆ·

====================================================================
ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦åŒå¡”æ¨¡å‹ï¼Ÿ
====================================================================

ä¼ ç»Ÿå¬å›é—®é¢˜ï¼š
- ååŒè¿‡æ»¤ï¼šæ— æ³•åˆ©ç”¨ä¸°å¯Œçš„ç‰¹å¾ï¼ˆå¹´é¾„ã€æ€§åˆ«ã€ç±»åˆ«ç­‰ï¼‰
- çŸ©é˜µåˆ†è§£ï¼šåªèƒ½å¤„ç† user_id å’Œ item_id

åŒå¡”æ¨¡å‹ä¼˜åŠ¿ï¼š
âœ“ å¯ä»¥ä½¿ç”¨ä»»æ„ç‰¹å¾ï¼ˆIDã€ç±»åˆ«ã€æ–‡æœ¬ã€å›¾åƒï¼‰
âœ“ è®­ç»ƒå’Œæ¨ç†åˆ†ç¦»ï¼ˆç¦»çº¿å‘é‡åŒ– + åœ¨çº¿ ANN æ£€ç´¢ï¼‰
âœ“ å¯æ‰©å±•åˆ°ç™¾ä¸‡çº§ç”¨æˆ·å’Œç‰©å“

====================================================================
ğŸ—ï¸ åŒå¡”æ¨¡å‹æ¶æ„
====================================================================

è®­ç»ƒé˜¶æ®µï¼š
    ç”¨æˆ·ç‰¹å¾                    ç‰©å“ç‰¹å¾
    [user_id,                  [item_id,
     age,                       category,
     gender,          Ã—         price,
     history...]                tags...]
        â†“                          â†“
    ç”¨æˆ·å¡”(MLP)              ç‰©å“å¡”(MLP)
    512â†’256â†’128              256â†’128
        â†“                          â†“
    ç”¨æˆ·å‘é‡(128ç»´)  â”€â”€â”€â”€â”€Ã—â”€â”€â”€â”€â”€  ç‰©å“å‘é‡(128ç»´)
                         â†“
                    ä½™å¼¦ç›¸ä¼¼åº¦
                         â†“
                      åˆ†æ•° (0-1)
                         â†“
                    äº¤å‰ç†µæŸå¤±

æ¨ç†é˜¶æ®µï¼ˆä¸¤æ­¥èµ°ï¼‰ï¼š
    1. ç¦»çº¿ï¼šå¯¹æ‰€æœ‰ç‰©å“ç”Ÿæˆå‘é‡ï¼Œå­˜å…¥å‘é‡æ•°æ®åº“
    2. åœ¨çº¿ï¼š
       - ç”¨æˆ·å¡”ç”Ÿæˆç”¨æˆ·å‘é‡
       - ANN æ£€ç´¢æœ€ç›¸ä¼¼çš„ top-K ç‰©å“å‘é‡
       - è¿”å›å¯¹åº”çš„ç‰©å“ID

====================================================================
âš ï¸ æ ¸å¿ƒé—®é¢˜ï¼šmask åº”è¯¥åœ¨å“ªé‡Œï¼Ÿ
====================================================================

âŒ é”™è¯¯ä½ç½®ï¼šåœ¨é¢„æµ‹åˆ†æ•°è®¡ç®—ä¸­
    pred = torch.sum(logits * mask, dim=-1)  # é”™è¯¯ï¼

âœ“ æ­£ç¡®ä½ç½®ï¼šåœ¨æŸå¤±å‡½æ•°ä¸­
    loss = criterion(pred, label) * mask     # æ­£ç¡®ï¼
    loss = loss.sum() / mask.sum()

åŸå› ï¼š
1. mask æ˜¯è®­ç»ƒæŠ€å·§ï¼ˆæ ·æœ¬åŠ æƒï¼‰ï¼Œä¸æ˜¯æ¨¡å‹é€»è¾‘
2. æ¨ç†æ—¶æ²¡æœ‰ maskï¼Œå¦‚æœ mask åœ¨ pred é‡Œä¼šå¯¼è‡´ä¸ä¸€è‡´
3. mask åªå½±å“æ¢¯åº¦ä¼ æ’­ï¼Œä¸åº”è¯¥æ”¹å˜æ¨¡å‹è¾“å‡º

====================================================================
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from collections import defaultdict

# è®¾ç½®éšæœºç§å­
torch.manual_seed(42)
np.random.seed(42)

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# ============ 1. æ•°æ®å‡†å¤‡ï¼ˆæ¨¡æ‹Ÿ MovieLens é£æ ¼ï¼‰============

class MovieLensDataset(Dataset):
    """æ¨¡æ‹Ÿ MovieLens æ•°æ®é›†

    ç”¨æˆ·ç‰¹å¾ï¼šuser_id, age_group, gender
    ç‰©å“ç‰¹å¾ï¼šitem_id, category, year
    äº¤äº’ï¼šrating (1-5)ï¼Œæˆ‘ä»¬å°† >=4 çš„è§†ä¸ºæ­£æ ·æœ¬
    """

    def __init__(self, num_users=1000, num_items=500, num_samples=10000):
        self.num_users = num_users
        self.num_items = num_items

        # ç”Ÿæˆç”¨æˆ·ç‰¹å¾
        self.user_ages = np.random.randint(0, 5, num_users)  # 5ä¸ªå¹´é¾„æ®µ
        self.user_genders = np.random.randint(0, 2, num_users)  # 2ç§æ€§åˆ«

        # ç”Ÿæˆç‰©å“ç‰¹å¾
        self.item_categories = np.random.randint(0, 10, num_items)  # 10ä¸ªç±»åˆ«
        self.item_years = np.random.randint(0, 5, num_items)  # 5ä¸ªå¹´ä»£

        # ç”Ÿæˆäº¤äº’æ•°æ®ï¼ˆç”¨æˆ·-ç‰©å“å¯¹ + æ ‡ç­¾ï¼‰
        self.samples = []
        for _ in range(num_samples):
            user_id = np.random.randint(0, num_users)
            item_id = np.random.randint(0, num_items)

            # æ¨¡æ‹Ÿç›¸ä¼¼åº¦ï¼šåŒå¹´é¾„æ®µç”¨æˆ·å–œæ¬¢åŒç±»åˆ«ç‰©å“ï¼ˆç®€åŒ–è§„åˆ™ï¼‰
            user_age = self.user_ages[user_id]
            item_cat = self.item_categories[item_id]

            # å¦‚æœç”¨æˆ·å¹´é¾„æ®µå’Œç‰©å“ç±»åˆ«åŒ¹é…ï¼Œæ›´å¯èƒ½æ˜¯æ­£æ ·æœ¬
            label = 1 if (user_age % 10 == item_cat % 10) and np.random.rand() > 0.3 else 0

            self.samples.append((user_id, item_id, label))

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        user_id, item_id, label = self.samples[idx]

        # ç”¨æˆ·ç‰¹å¾
        user_age = self.user_ages[user_id]
        user_gender = self.user_genders[user_id]

        # ç‰©å“ç‰¹å¾
        item_cat = self.item_categories[item_id]
        item_year = self.item_years[item_id]

        return {
            'user_id': torch.LongTensor([user_id]),
            'user_age': torch.LongTensor([user_age]),
            'user_gender': torch.LongTensor([user_gender]),
            'item_id': torch.LongTensor([item_id]),
            'item_cat': torch.LongTensor([item_cat]),
            'item_year': torch.LongTensor([item_year]),
            'label': torch.FloatTensor([label])
        }


# ============ 2. åŒå¡”æ¨¡å‹ ============

class UserTower(nn.Module):
    """ç”¨æˆ·å¡”ï¼šå°†ç”¨æˆ·ç‰¹å¾æ˜ å°„ä¸ºå›ºå®šç»´åº¦çš„å‘é‡"""

    def __init__(self, num_users, num_ages, num_genders, embedding_dim=32, hidden_dim=128):
        super().__init__()

        # Embedding å±‚ï¼ˆå°†ç¦»æ•£ç‰¹å¾æ˜ å°„ä¸ºå‘é‡ï¼‰
        self.user_embedding = nn.Embedding(num_users, embedding_dim)
        self.age_embedding = nn.Embedding(num_ages, embedding_dim // 2)
        self.gender_embedding = nn.Embedding(num_genders, embedding_dim // 4)

        # MLP å±‚ï¼ˆå¤šå±‚æ„ŸçŸ¥æœºï¼‰
        input_dim = embedding_dim + embedding_dim // 2 + embedding_dim // 4
        self.mlp = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim // 2, hidden_dim // 2)  # æœ€ç»ˆç”¨æˆ·å‘é‡ç»´åº¦
        )

    def forward(self, user_id, user_age, user_gender):
        """
        å‚æ•°:
            user_id: (batch_size, 1)
            user_age: (batch_size, 1)
            user_gender: (batch_size, 1)

        è¿”å›:
            user_vector: (batch_size, hidden_dim // 2) - ç”¨æˆ·å‘é‡
        """
        # 1. Embedding
        user_emb = self.user_embedding(user_id).squeeze(1)  # (batch, embedding_dim)
        age_emb = self.age_embedding(user_age).squeeze(1)
        gender_emb = self.gender_embedding(user_gender).squeeze(1)

        # 2. æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
        x = torch.cat([user_emb, age_emb, gender_emb], dim=1)

        # 3. é€šè¿‡ MLP å¾—åˆ°ç”¨æˆ·å‘é‡
        user_vector = self.mlp(x)

        # 4. L2 å½’ä¸€åŒ–ï¼ˆé‡è¦ï¼ä¿è¯å‘é‡åœ¨å•ä½çƒé¢ä¸Šï¼Œä½™å¼¦ç›¸ä¼¼åº¦ = ç‚¹ç§¯ï¼‰
        user_vector = F.normalize(user_vector, p=2, dim=1)

        return user_vector


class ItemTower(nn.Module):
    """ç‰©å“å¡”ï¼šå°†ç‰©å“ç‰¹å¾æ˜ å°„ä¸ºå›ºå®šç»´åº¦çš„å‘é‡"""

    def __init__(self, num_items, num_categories, num_years, embedding_dim=32, hidden_dim=128):
        super().__init__()

        # Embedding å±‚
        self.item_embedding = nn.Embedding(num_items, embedding_dim)
        self.cat_embedding = nn.Embedding(num_categories, embedding_dim // 2)
        self.year_embedding = nn.Embedding(num_years, embedding_dim // 4)

        # MLP å±‚
        input_dim = embedding_dim + embedding_dim // 2 + embedding_dim // 4
        self.mlp = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_dim // 2, hidden_dim // 2)  # æœ€ç»ˆç‰©å“å‘é‡ç»´åº¦
        )

    def forward(self, item_id, item_cat, item_year):
        """
        å‚æ•°:
            item_id: (batch_size, 1)
            item_cat: (batch_size, 1)
            item_year: (batch_size, 1)

        è¿”å›:
            item_vector: (batch_size, hidden_dim // 2) - ç‰©å“å‘é‡
        """
        item_emb = self.item_embedding(item_id).squeeze(1)
        cat_emb = self.cat_embedding(item_cat).squeeze(1)
        year_emb = self.year_embedding(item_year).squeeze(1)

        x = torch.cat([item_emb, cat_emb, year_emb], dim=1)
        item_vector = self.mlp(x)

        # L2 å½’ä¸€åŒ–
        item_vector = F.normalize(item_vector, p=2, dim=1)

        return item_vector


class TwoTowerModel(nn.Module):
    """å®Œæ•´çš„åŒå¡”æ¨¡å‹"""

    def __init__(self, num_users, num_items, num_ages=5, num_genders=2,
                 num_categories=10, num_years=5, embedding_dim=32, hidden_dim=128):
        super().__init__()

        self.user_tower = UserTower(num_users, num_ages, num_genders, embedding_dim, hidden_dim)
        self.item_tower = ItemTower(num_items, num_categories, num_years, embedding_dim, hidden_dim)

    def forward(self, user_id, user_age, user_gender, item_id, item_cat, item_year):
        """
        è®­ç»ƒæ—¶çš„å‰å‘ä¼ æ’­

        è¿”å›:
            similarity: (batch_size,) - ç”¨æˆ·-ç‰©å“ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
            user_vector: (batch_size, dim) - ç”¨æˆ·å‘é‡ï¼ˆç”¨äºåˆ†æï¼‰
            item_vector: (batch_size, dim) - ç‰©å“å‘é‡ï¼ˆç”¨äºåˆ†æï¼‰
        """
        # 1. ç”Ÿæˆç”¨æˆ·å‘é‡å’Œç‰©å“å‘é‡
        user_vector = self.user_tower(user_id, user_age, user_gender)
        item_vector = self.item_tower(item_id, item_cat, item_year)

        # 2. è®¡ç®—ç›¸ä¼¼åº¦ï¼ˆç‚¹ç§¯ï¼Œå› ä¸ºå·²ç»å½’ä¸€åŒ–ï¼Œæ‰€ä»¥ç­‰ä»·äºä½™å¼¦ç›¸ä¼¼åº¦ï¼‰
        similarity = torch.sum(user_vector * item_vector, dim=1)  # (batch_size,)

        # 3. æ˜ å°„åˆ° (0, 1) åŒºé—´ï¼ˆä½¿ç”¨ sigmoidï¼‰
        similarity = torch.sigmoid(similarity)

        return similarity, user_vector, item_vector

    def get_user_vector(self, user_id, user_age, user_gender):
        """æ¨ç†æ—¶ï¼šåªè·å–ç”¨æˆ·å‘é‡"""
        return self.user_tower(user_id, user_age, user_gender)

    def get_item_vector(self, item_id, item_cat, item_year):
        """æ¨ç†æ—¶ï¼šåªè·å–ç‰©å“å‘é‡ï¼ˆç”¨äºç¦»çº¿å‘é‡åŒ–ï¼‰"""
        return self.item_tower(item_id, item_cat, item_year)


# ============ 3. è®­ç»ƒ ============

def train_model(model, train_loader, val_loader, device, num_epochs=20, lr=0.001):
    """è®­ç»ƒåŒå¡”æ¨¡å‹"""
    criterion = nn.BCELoss()  # äºŒåˆ†ç±»äº¤å‰ç†µ
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}

    print("\nå¼€å§‹è®­ç»ƒåŒå¡”æ¨¡å‹...")
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        train_correct = 0
        train_total = 0

        for batch in train_loader:
            user_id = batch['user_id'].to(device)
            user_age = batch['user_age'].to(device)
            user_gender = batch['user_gender'].to(device)
            item_id = batch['item_id'].to(device)
            item_cat = batch['item_cat'].to(device)
            item_year = batch['item_year'].to(device)
            label = batch['label'].to(device).squeeze()

            optimizer.zero_grad()

            # å‰å‘ä¼ æ’­
            pred, _, _ = model(user_id, user_age, user_gender, item_id, item_cat, item_year)

            # è®¡ç®—æŸå¤±ï¼ˆæ³¨æ„ï¼šè¿™é‡Œæ²¡æœ‰ maskï¼ï¼‰
            loss = criterion(pred, label)

            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()

            # ç»Ÿè®¡
            train_loss += loss.item()
            train_correct += ((pred > 0.5) == label).sum().item()
            train_total += label.size(0)

        train_loss /= len(train_loader)
        train_acc = 100. * train_correct / train_total

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0
        val_correct = 0
        val_total = 0

        with torch.no_grad():
            for batch in val_loader:
                user_id = batch['user_id'].to(device)
                user_age = batch['user_age'].to(device)
                user_gender = batch['user_gender'].to(device)
                item_id = batch['item_id'].to(device)
                item_cat = batch['item_cat'].to(device)
                item_year = batch['item_year'].to(device)
                label = batch['label'].to(device).squeeze()

                pred, _, _ = model(user_id, user_age, user_gender, item_id, item_cat, item_year)
                loss = criterion(pred, label)

                val_loss += loss.item()
                val_correct += ((pred > 0.5) == label).sum().item()
                val_total += label.size(0)

        val_loss /= len(val_loader)
        val_acc = 100. * val_correct / val_total

        history['train_loss'].append(train_loss)
        history['train_acc'].append(train_acc)
        history['val_loss'].append(val_loss)
        history['val_acc'].append(val_acc)

        if (epoch + 1) % 5 == 0:
            print(f'Epoch {epoch+1}/{num_epochs}:')
            print(f'  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%')
            print(f'  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%')

    return history


# ============ 4. æ¨ç†ï¼ˆå¬å›ï¼‰============

def build_item_index(model, dataset, device):
    """ç¦»çº¿æ„å»ºç‰©å“å‘é‡ç´¢å¼•

    åœ¨å®é™…ç”Ÿäº§ä¸­ï¼Œè¿™ä¸€æ­¥ä¼šï¼š
    1. å¯¹æ‰€æœ‰ç‰©å“ç”Ÿæˆå‘é‡
    2. å­˜å…¥å‘é‡æ•°æ®åº“ï¼ˆFaiss, Milvus ç­‰ï¼‰
    3. æ”¯æŒ ANNï¼ˆè¿‘ä¼¼æœ€è¿‘é‚»ï¼‰æ£€ç´¢
    """
    model.eval()
    item_vectors = []
    item_ids = []

    print("\næ„å»ºç‰©å“å‘é‡ç´¢å¼•...")
    with torch.no_grad():
        for item_id in range(dataset.num_items):
            item_cat = dataset.item_categories[item_id]
            item_year = dataset.item_years[item_id]

            # è½¬æ¢ä¸º tensor
            item_id_t = torch.LongTensor([[item_id]]).to(device)
            item_cat_t = torch.LongTensor([[item_cat]]).to(device)
            item_year_t = torch.LongTensor([[item_year]]).to(device)

            # ç”Ÿæˆç‰©å“å‘é‡
            item_vec = model.get_item_vector(item_id_t, item_cat_t, item_year_t)

            item_vectors.append(item_vec.cpu().numpy())
            item_ids.append(item_id)

    item_vectors = np.vstack(item_vectors)  # (num_items, vector_dim)
    print(f"ç‰©å“å‘é‡ç´¢å¼•æ„å»ºå®Œæˆï¼š{item_vectors.shape}")

    return item_vectors, item_ids


def recall_for_user(model, user_id, dataset, item_vectors, item_ids, device, top_k=10):
    """åœ¨çº¿å¬å›ï¼šä¸ºç”¨æˆ·å¬å› top-K ç‰©å“

    åœ¨å®é™…ç”Ÿäº§ä¸­ï¼š
    1. å®æ—¶ç”Ÿæˆç”¨æˆ·å‘é‡
    2. åœ¨å‘é‡æ•°æ®åº“ä¸­æ£€ç´¢æœ€ç›¸ä¼¼çš„ top-K ç‰©å“å‘é‡
    3. è¿”å›ç‰©å“ ID
    """
    model.eval()

    with torch.no_grad():
        # è·å–ç”¨æˆ·ç‰¹å¾
        user_age = dataset.user_ages[user_id]
        user_gender = dataset.user_genders[user_id]

        # è½¬æ¢ä¸º tensor
        user_id_t = torch.LongTensor([[user_id]]).to(device)
        user_age_t = torch.LongTensor([[user_age]]).to(device)
        user_gender_t = torch.LongTensor([[user_gender]]).to(device)

        # ç”Ÿæˆç”¨æˆ·å‘é‡
        user_vec = model.get_user_vector(user_id_t, user_age_t, user_gender_t)
        user_vec = user_vec.cpu().numpy()  # (1, vector_dim)

        # è®¡ç®—ä¸æ‰€æœ‰ç‰©å“çš„ç›¸ä¼¼åº¦ï¼ˆæš´åŠ›æ£€ç´¢ï¼Œå®é™…ç”¨ ANNï¼‰
        similarities = np.dot(item_vectors, user_vec.T).squeeze()  # (num_items,)

        # è·å– top-K
        top_k_indices = np.argsort(similarities)[::-1][:top_k]
        top_k_items = [item_ids[i] for i in top_k_indices]
        top_k_scores = similarities[top_k_indices]

    return top_k_items, top_k_scores


# ============ 5. å¯è§†åŒ– ============

def plot_training_history(history):
    """ç»˜åˆ¶è®­ç»ƒå†å²"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

    ax1.plot(history['train_loss'], label='Train Loss')
    ax1.plot(history['val_loss'], label='Val Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Training and Validation Loss')
    ax1.legend()
    ax1.grid(True)

    ax2.plot(history['train_acc'], label='Train Acc')
    ax2.plot(history['val_acc'], label='Val Acc')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Accuracy (%)')
    ax2.set_title('Training and Validation Accuracy')
    ax2.legend()
    ax2.grid(True)

    plt.tight_layout()
    plt.savefig('two_tower_training.png', dpi=150)
    print("\nè®­ç»ƒå†å²å·²ä¿å­˜åˆ° two_tower_training.png")
    plt.close()


# ============ ä¸»å‡½æ•° ============

def main():
    print("\n" + "ğŸš€ " + "=" * 58)
    print("  åŒå¡”æ¨¡å‹ (Two-Tower Model) - PyTorchå®ç°")
    print("  æ¨èç³»ç»Ÿå¬å›é˜¶æ®µçš„æ ¸å¿ƒæ¶æ„")
    print("=" * 60)

    # æ£€æŸ¥è®¾å¤‡
    print(f"\nä½¿ç”¨è®¾å¤‡: {DEVICE}")
    if torch.cuda.is_available():
        print(f"GPUå‹å·: {torch.cuda.get_device_name(0)}")

    # åˆ›å»ºæ•°æ®é›†
    print("\n" + "=" * 60)
    print("åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®é›†")
    print("=" * 60)

    train_dataset = MovieLensDataset(num_users=1000, num_items=500, num_samples=20000)
    val_dataset = MovieLensDataset(num_users=1000, num_items=500, num_samples=5000)

    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)

    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}")
    print(f"ç”¨æˆ·æ•°: {train_dataset.num_users}")
    print(f"ç‰©å“æ•°: {train_dataset.num_items}")

    # åˆ›å»ºæ¨¡å‹
    print("\n" + "=" * 60)
    print("åˆ›å»ºåŒå¡”æ¨¡å‹")
    print("=" * 60)

    model = TwoTowerModel(
        num_users=train_dataset.num_users,
        num_items=train_dataset.num_items,
        num_ages=5,
        num_genders=2,
        num_categories=10,
        num_years=5,
        embedding_dim=32,
        hidden_dim=128
    ).to(DEVICE)

    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")
    print(f"ç”¨æˆ·å‘é‡ç»´åº¦: 64")
    print(f"ç‰©å“å‘é‡ç»´åº¦: 64")

    # è®­ç»ƒæ¨¡å‹
    print("\n" + "=" * 60)
    print("è®­ç»ƒæ¨¡å‹")
    print("=" * 60)

    history = train_model(model, train_loader, val_loader, DEVICE, num_epochs=30, lr=0.001)

    # å¯è§†åŒ–
    plot_training_history(history)

    # æ„å»ºç‰©å“ç´¢å¼•
    print("\n" + "=" * 60)
    print("æ„å»ºç‰©å“å‘é‡ç´¢å¼•ï¼ˆç¦»çº¿ï¼‰")
    print("=" * 60)

    item_vectors, item_ids = build_item_index(model, train_dataset, DEVICE)

    # æµ‹è¯•å¬å›
    print("\n" + "=" * 60)
    print("æµ‹è¯•å¬å›ï¼ˆåœ¨çº¿ï¼‰")
    print("=" * 60)

    test_user_ids = [0, 10, 100]
    for user_id in test_user_ids:
        top_items, scores = recall_for_user(model, user_id, train_dataset, item_vectors, item_ids, DEVICE, top_k=10)

        print(f"\nç”¨æˆ· {user_id} çš„å¬å›ç»“æœ (Top-10):")
        print(f"  ç”¨æˆ·ç‰¹å¾: age={train_dataset.user_ages[user_id]}, gender={train_dataset.user_genders[user_id]}")
        print(f"  å¬å›ç‰©å“ID: {top_items}")
        print(f"  ç›¸ä¼¼åº¦åˆ†æ•°: {[f'{s:.3f}' for s in scores]}")

    # æ€»ç»“
    print("\n" + "=" * 60)
    print("å­¦ä¹ æ€»ç»“")
    print("=" * 60)

    print("""
1. åŒå¡”æ¨¡å‹ç»“æ„
   âœ“ ç”¨æˆ·å¡”: ç”¨æˆ·ç‰¹å¾ â†’ ç”¨æˆ·å‘é‡
   âœ“ ç‰©å“å¡”: ç‰©å“ç‰¹å¾ â†’ ç‰©å“å‘é‡
   âœ“ ç›¸ä¼¼åº¦: ç‚¹ç§¯/ä½™å¼¦ç›¸ä¼¼åº¦

2. è®­ç»ƒä¸æ¨ç†åˆ†ç¦»
   âœ“ è®­ç»ƒ: åŒæ—¶è®¡ç®—ç”¨æˆ·å’Œç‰©å“å‘é‡ï¼Œä¼˜åŒ–ç›¸ä¼¼åº¦
   âœ“ æ¨ç†:
     - ç¦»çº¿: ç”Ÿæˆæ‰€æœ‰ç‰©å“å‘é‡ï¼Œå­˜å…¥å‘é‡æ•°æ®åº“
     - åœ¨çº¿: ç”Ÿæˆç”¨æˆ·å‘é‡ï¼ŒANN æ£€ç´¢ top-K

3. å…³é”®æŠ€æœ¯ç‚¹
   âœ“ L2 å½’ä¸€åŒ–: ä¿è¯å‘é‡åœ¨å•ä½çƒé¢ä¸Š
   âœ“ ä½™å¼¦ç›¸ä¼¼åº¦ = å½’ä¸€åŒ–åçš„ç‚¹ç§¯
   âœ“ Embedding: å°†ç¦»æ•£ç‰¹å¾æ˜ å°„ä¸ºè¿ç»­å‘é‡
   âœ“ MLP: å­¦ä¹ ç‰¹å¾çš„éçº¿æ€§ç»„åˆ

4. mask çš„æ­£ç¡®ä½ç½® âš ï¸
   âœ“ è®­ç»ƒæ—¶: åœ¨æŸå¤±å‡½æ•°ä¸­ä½¿ç”¨ maskï¼ˆæ ·æœ¬åŠ æƒï¼‰
   âœ— ä¸è¦åœ¨æ¨¡å‹è¾“å‡ºä¸­ä½¿ç”¨ maskï¼

   åŸå› :
   - mask æ˜¯è®­ç»ƒæŠ€å·§ï¼Œä¸æ˜¯æ¨¡å‹é€»è¾‘
   - æ¨ç†æ—¶æ²¡æœ‰ maskï¼Œä¼šå¯¼è‡´ä¸ä¸€è‡´
   - mask åªå½±å“æ¢¯åº¦ï¼Œä¸åº”æ”¹å˜è¾“å‡º

5. å·¥ä¸šå®è·µ
   âœ“ å‘é‡æ•°æ®åº“: Faiss, Milvus, Elasticsearch
   âœ“ ANN æ£€ç´¢: HNSW, IVF, Product Quantization
   âœ“ ç‰¹å¾å·¥ç¨‹: IDã€ç±»åˆ«ã€ç»Ÿè®¡ã€åºåˆ—ç‰¹å¾
   âœ“ è´Ÿé‡‡æ ·: éšæœºè´Ÿæ ·æœ¬ã€éš¾è´Ÿæ ·æœ¬

6. ä¸‹ä¸€æ­¥
   â†’ Wide & Deep (ç²¾æ’æ¨¡å‹)
   â†’ DeepFM (ç‰¹å¾äº¤å‰)
   â†’ DIN (æ³¨æ„åŠ›æœºåˆ¶)
   â†’ å¤šä»»åŠ¡å­¦ä¹  (MMoE)
    """)

    print("\nâœ… åŒå¡”æ¨¡å‹å­¦ä¹ å®Œæˆï¼")
    print("\næç¤º: åŒå¡”æ¨¡å‹æ˜¯å¬å›é˜¶æ®µçš„åŸºç¡€ï¼Œæ¥ä¸‹æ¥å¯ä»¥å­¦ä¹ ç²¾æ’æ¨¡å‹")


if __name__ == "__main__":
    main()
