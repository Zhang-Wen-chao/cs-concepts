"""
ç²—æ’ï¼ˆCoarse Ranking / Pre-Rankingï¼‰- PyTorchå®ç°
æ¨èç³»ç»Ÿä¸­å¬å›å’Œç²¾æ’ä¹‹é—´çš„è¿‡æ¸¡å±‚

ä½œè€…: Zhang Wenchao
æ—¥æœŸ: 2025-11-22

====================================================================
ğŸ“– ç²—æ’åœ¨æ¨èé“¾è·¯ä¸­çš„ä½ç½®
====================================================================

å®Œæ•´é“¾è·¯ï¼š
å¬å›ï¼ˆå‡ åƒï¼‰ â†’ ç²—æ’ï¼ˆå‡ ç™¾ï¼‰ â†’ ç²¾æ’ï¼ˆå‡ åï¼‰ â†’ é‡æ’ â†’ æ··æ’

ä¸ºä»€ä¹ˆéœ€è¦ç²—æ’ï¼Ÿ
- å¬å›ï¼šå¿«é€Ÿç­›é€‰ï¼ˆç®€å•æ¨¡å‹ï¼Œå¦‚åŒå¡”ç‚¹ç§¯ï¼‰
- ç²¾æ’ï¼šç²¾å‡†é¢„æµ‹ï¼ˆå¤æ‚æ¨¡å‹ï¼Œå¦‚ DINã€DeepFMï¼‰
- é—®é¢˜ï¼šç›´æ¥ç²¾æ’å‡ åƒä¸ªå€™é€‰ â†’ å»¶è¿Ÿå¤ªé«˜ âŒ

ç²—æ’çš„ç›®æ ‡ï¼š
âœ“ åœ¨ä¿è¯æ•ˆæœçš„å‰æä¸‹ï¼Œé™ä½ç²¾æ’çš„è®¡ç®—å‹åŠ›
âœ“ ç”¨è½»é‡çº§æ¨¡å‹ï¼Œå¿«é€Ÿè¿‡æ»¤æ‰æ˜æ˜¾ä¸ç›¸å…³çš„å€™é€‰
âœ“ ä¸ºç²¾æ’æä¾›é«˜è´¨é‡çš„å€™é€‰é›†

====================================================================
ğŸ¯ ç²—æ’çš„æ ¸å¿ƒæ€æƒ³
====================================================================

å¹³è¡¡æ•ˆæœå’Œæ€§èƒ½ï¼š
- æ¯”å¬å›æ›´å‡†ç¡®ï¼ˆç”¨æ›´å¤šç‰¹å¾ï¼‰
- æ¯”ç²¾æ’æ›´å¿«é€Ÿï¼ˆæ›´å°‘å‚æ•°ï¼‰

ä¸‰ç§å¸¸ç”¨æ–¹æ³•ï¼š

1ï¸âƒ£ åŒå¡”ç‚¹ç§¯å¢å¼ºç‰ˆ
   - å¤ç”¨å¬å›çš„åŒå¡”æ¨¡å‹
   - å¢åŠ ç‰¹å¾ç»´åº¦
   - è®¡ç®—æ›´ç²¾ç¡®çš„ç›¸ä¼¼åº¦

2ï¸âƒ£ çŸ¥è¯†è’¸é¦
   - Teacherï¼šç²¾æ’æ¨¡å‹ï¼ˆDINã€DeepFMï¼‰
   - Studentï¼šè½»é‡çº§æ¨¡å‹
   - Student å­¦ä¹  Teacher çš„é¢„æµ‹ç»“æœ

3ï¸âƒ£ è½»é‡çº§ MLP
   - ç±»ä¼¼ DeepFMï¼Œä½†æ›´ç®€å•
   - åªç”¨æ ¸å¿ƒç‰¹å¾ï¼ˆå»æ‰å†å²åºåˆ—ç­‰å¤æ‚ç‰¹å¾ï¼‰
   - æ›´å°‘çš„å±‚æ•°å’Œå‚æ•°

====================================================================
ğŸ—ï¸ æœ¬å®ç°ï¼šä¸‰ç§ç²—æ’æ–¹æ³•å¯¹æ¯”
====================================================================

æ–¹æ³•1ï¼šåŒå¡”å¢å¼ºç‰ˆ
- ç”¨æˆ·å¡” + ç‰©å“å¡”
- å¢åŠ ç‰¹å¾ï¼ˆage, gender, categoryï¼‰
- ç‚¹ç§¯ + sigmoid

æ–¹æ³•2ï¼šçŸ¥è¯†è’¸é¦
- Teacherï¼šç²¾æ’æ¨¡å‹ï¼ˆå·²è®­ç»ƒå¥½çš„ DeepFMï¼‰
- Studentï¼šè½»é‡çº§ MLP
- æŸå¤±ï¼šKLæ•£åº¦ï¼ˆå­¦ä¹  Teacher çš„è¾“å‡ºåˆ†å¸ƒï¼‰

æ–¹æ³•3ï¼šè½»é‡çº§ MLP
- ç®€å•çš„ Embedding + MLP
- 2å±‚éšè—å±‚
- å‚æ•°é‡ < ç²¾æ’æ¨¡å‹çš„ 1/5

====================================================================
ğŸ“Š æ€§èƒ½å¯¹æ¯”æŒ‡æ ‡
====================================================================

å…³é”®æŒ‡æ ‡ï¼š
1. AUCï¼šæ’åºèƒ½åŠ›
2. å‚æ•°é‡ï¼šæ¨¡å‹å¤æ‚åº¦
3. æ¨ç†é€Ÿåº¦ï¼šQPSï¼ˆæ¯ç§’æŸ¥è¯¢æ•°ï¼‰
4. å¬å›ç‡@Kï¼šç²—æ’ top-K ä¸­åŒ…å«ç²¾æ’ top-N çš„æ¯”ä¾‹

ç›®æ ‡ï¼š
- å‚æ•°é‡ < ç²¾æ’çš„ 20%
- AUC æ¥è¿‘ç²¾æ’ï¼ˆå·®è· < 5%ï¼‰
- é€Ÿåº¦ > ç²¾æ’çš„ 5 å€

====================================================================
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import roc_auc_score
import time

# è®¾ç½®éšæœºç§å­
torch.manual_seed(42)
np.random.seed(42)

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# ============ 1. æ•°æ®å‡†å¤‡ï¼ˆå¤ç”¨ä¹‹å‰çš„ï¼‰============

class RankingDataset(Dataset):
    """æ’åºæ•°æ®é›†"""

    def __init__(self, num_samples=10000, num_users=1000, num_items=500):
        self.num_samples = num_samples
        self.num_users = num_users
        self.num_items = num_items

        self.num_ages = 5
        self.num_genders = 2
        self.num_categories = 20

        self.user_ages = np.random.randint(0, self.num_ages, num_users)
        self.user_genders = np.random.randint(0, self.num_genders, num_users)
        self.item_categories = np.random.randint(0, self.num_categories, num_items)
        self.item_prices = np.random.uniform(10, 1000, num_items)

        self.samples = []
        for _ in range(num_samples):
            user_id = np.random.randint(0, num_users)
            item_id = np.random.randint(0, num_items)

            age = self.user_ages[user_id]
            gender = self.user_genders[user_id]
            category = self.item_categories[item_id]
            price = self.item_prices[item_id]

            click_prob = 0.1
            if age < 2 and category < 5: click_prob += 0.4
            if gender == 1 and category in [10, 11, 12]: click_prob += 0.4
            if price < 200: click_prob += 0.2

            label = 1 if np.random.rand() < click_prob else 0

            self.samples.append({
                'user_id': user_id,
                'item_id': item_id,
                'age': age,
                'gender': gender,
                'category': category,
                'price': price,
                'label': label
            })

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        sample = self.samples[idx]
        return {
            'user_id': torch.LongTensor([sample['user_id']]),
            'item_id': torch.LongTensor([sample['item_id']]),
            'age': torch.LongTensor([sample['age']]),
            'gender': torch.LongTensor([sample['gender']]),
            'category': torch.LongTensor([sample['category']]),
            'price': torch.FloatTensor([sample['price']]),
            'label': torch.FloatTensor([sample['label']])
        }


# ============ 2. ç²—æ’æ¨¡å‹ ============

class CoarseRankingModel_TwoTower(nn.Module):
    """æ–¹æ³•1ï¼šåŒå¡”å¢å¼ºç‰ˆï¼ˆå¬å›æ¨¡å‹çš„åŠ å¼ºç‰ˆï¼‰"""

    def __init__(self, num_users, num_items, num_ages, num_genders, num_categories,
                 embedding_dim=16):
        super().__init__()

        # ç”¨æˆ·å¡”
        self.user_embedding = nn.Embedding(num_users, embedding_dim)
        self.age_embedding = nn.Embedding(num_ages, embedding_dim // 2)
        self.gender_embedding = nn.Embedding(num_genders, embedding_dim // 4)

        user_input_dim = embedding_dim + embedding_dim // 2 + embedding_dim // 4
        self.user_mlp = nn.Sequential(
            nn.Linear(user_input_dim, embedding_dim),
            nn.ReLU(),
            nn.Linear(embedding_dim, embedding_dim)
        )

        # ç‰©å“å¡”
        self.item_embedding = nn.Embedding(num_items, embedding_dim)
        self.category_embedding = nn.Embedding(num_categories, embedding_dim // 2)

        item_input_dim = embedding_dim + embedding_dim // 2 + 1  # +1 for price
        self.item_mlp = nn.Sequential(
            nn.Linear(item_input_dim, embedding_dim),
            nn.ReLU(),
            nn.Linear(embedding_dim, embedding_dim)
        )

    def forward(self, user_id, age, gender, item_id, category, price):
        # ç”¨æˆ·å¡”
        user_emb = self.user_embedding(user_id).squeeze(1)
        age_emb = self.age_embedding(age).squeeze(1)
        gender_emb = self.gender_embedding(gender).squeeze(1)
        user_feat = torch.cat([user_emb, age_emb, gender_emb], dim=1)
        user_vec = self.user_mlp(user_feat)
        user_vec = F.normalize(user_vec, p=2, dim=1)

        # ç‰©å“å¡”
        item_emb = self.item_embedding(item_id).squeeze(1)
        cat_emb = self.category_embedding(category).squeeze(1)
        item_feat = torch.cat([item_emb, cat_emb, price / 1000.0], dim=1)
        item_vec = self.item_mlp(item_feat)
        item_vec = F.normalize(item_vec, p=2, dim=1)

        # ç‚¹ç§¯
        logit = torch.sum(user_vec * item_vec, dim=1)
        return logit


class CoarseRankingModel_LightMLP(nn.Module):
    """æ–¹æ³•2ï¼šè½»é‡çº§ MLP"""

    def __init__(self, num_users, num_items, num_ages, num_genders, num_categories,
                 embedding_dim=16):
        super().__init__()

        # Embedding
        self.user_embedding = nn.Embedding(num_users, embedding_dim)
        self.item_embedding = nn.Embedding(num_items, embedding_dim)
        self.age_embedding = nn.Embedding(num_ages, embedding_dim // 2)
        self.gender_embedding = nn.Embedding(num_genders, embedding_dim // 4)
        self.category_embedding = nn.Embedding(num_categories, embedding_dim // 2)

        # è½»é‡çº§ MLPï¼ˆåªæœ‰2å±‚ï¼‰
        input_dim = embedding_dim * 2 + embedding_dim // 2 * 2 + embedding_dim // 4 + 1
        self.mlp = nn.Sequential(
            nn.Linear(input_dim, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(32, 1)
        )

    def forward(self, user_id, age, gender, item_id, category, price):
        user_emb = self.user_embedding(user_id).squeeze(1)
        item_emb = self.item_embedding(item_id).squeeze(1)
        age_emb = self.age_embedding(age).squeeze(1)
        gender_emb = self.gender_embedding(gender).squeeze(1)
        cat_emb = self.category_embedding(category).squeeze(1)

        features = torch.cat([
            user_emb, item_emb, age_emb, gender_emb, cat_emb, price / 1000.0
        ], dim=1)

        logit = self.mlp(features).squeeze(1)
        return logit


class FineRankingModel(nn.Module):
    """ç²¾æ’æ¨¡å‹ï¼ˆä½œä¸ºå¯¹æ¯”åŸºå‡†ï¼‰"""

    def __init__(self, num_users, num_items, num_ages, num_genders, num_categories,
                 embedding_dim=32):
        super().__init__()

        self.user_embedding = nn.Embedding(num_users, embedding_dim)
        self.item_embedding = nn.Embedding(num_items, embedding_dim)
        self.age_embedding = nn.Embedding(num_ages, embedding_dim // 2)
        self.gender_embedding = nn.Embedding(num_genders, embedding_dim // 4)
        self.category_embedding = nn.Embedding(num_categories, embedding_dim // 2)

        input_dim = embedding_dim * 2 + embedding_dim // 2 * 2 + embedding_dim // 4 + 1
        self.mlp = nn.Sequential(
            nn.Linear(input_dim, 256),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(256, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 64),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(64, 1)
        )

    def forward(self, user_id, age, gender, item_id, category, price):
        user_emb = self.user_embedding(user_id).squeeze(1)
        item_emb = self.item_embedding(item_id).squeeze(1)
        age_emb = self.age_embedding(age).squeeze(1)
        gender_emb = self.gender_embedding(gender).squeeze(1)
        cat_emb = self.category_embedding(category).squeeze(1)

        features = torch.cat([
            user_emb, item_emb, age_emb, gender_emb, cat_emb, price / 1000.0
        ], dim=1)

        logit = self.mlp(features).squeeze(1)
        return logit


# ============ 3. è®­ç»ƒ ============

def train_model(model, train_loader, val_loader, device, model_name, num_epochs=15, lr=0.001):
    """è®­ç»ƒæ¨¡å‹"""
    criterion = nn.BCEWithLogitsLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    history = {'train_loss': [], 'train_auc': [], 'val_loss': [], 'val_auc': []}

    print(f"\nè®­ç»ƒ {model_name}...")
    for epoch in range(num_epochs):
        model.train()
        train_loss = 0
        train_preds = []
        train_labels = []

        for batch in train_loader:
            user_id = batch['user_id'].to(device)
            age = batch['age'].to(device)
            gender = batch['gender'].to(device)
            item_id = batch['item_id'].to(device)
            category = batch['category'].to(device)
            price = batch['price'].to(device)
            label = batch['label'].to(device).squeeze()

            optimizer.zero_grad()
            logit = model(user_id, age, gender, item_id, category, price)
            loss = criterion(logit, label)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            train_preds.extend(torch.sigmoid(logit).detach().cpu().numpy())
            train_labels.extend(label.cpu().numpy())

        train_loss /= len(train_loader)
        train_auc = roc_auc_score(train_labels, train_preds)

        model.eval()
        val_loss = 0
        val_preds = []
        val_labels = []

        with torch.no_grad():
            for batch in val_loader:
                user_id = batch['user_id'].to(device)
                age = batch['age'].to(device)
                gender = batch['gender'].to(device)
                item_id = batch['item_id'].to(device)
                category = batch['category'].to(device)
                price = batch['price'].to(device)
                label = batch['label'].to(device).squeeze()

                logit = model(user_id, age, gender, item_id, category, price)
                loss = criterion(logit, label)

                val_loss += loss.item()
                val_preds.extend(torch.sigmoid(logit).cpu().numpy())
                val_labels.extend(label.cpu().numpy())

        val_loss /= len(val_loader)
        val_auc = roc_auc_score(val_labels, val_preds)

        history['train_loss'].append(train_loss)
        history['train_auc'].append(train_auc)
        history['val_loss'].append(val_loss)
        history['val_auc'].append(val_auc)

        if (epoch + 1) % 5 == 0:
            print(f'  Epoch {epoch+1}/{num_epochs}: Val AUC: {val_auc:.4f}')

    return history


# ============ 4. æ€§èƒ½å¯¹æ¯” ============

def compare_models(models, test_loader, device):
    """å¯¹æ¯”æ¨¡å‹çš„æ€§èƒ½"""
    print("\n" + "=" * 60)
    print("æ¨¡å‹æ€§èƒ½å¯¹æ¯”")
    print("=" * 60)

    results = {}

    for name, model in models.items():
        model.eval()
        preds = []
        labels = []
        start_time = time.time()

        with torch.no_grad():
            for batch in test_loader:
                user_id = batch['user_id'].to(device)
                age = batch['age'].to(device)
                gender = batch['gender'].to(device)
                item_id = batch['item_id'].to(device)
                category = batch['category'].to(device)
                price = batch['price'].to(device)
                label = batch['label'].to(device).squeeze()

                logit = model(user_id, age, gender, item_id, category, price)
                preds.extend(torch.sigmoid(logit).cpu().numpy())
                labels.extend(label.cpu().numpy())

        inference_time = time.time() - start_time
        auc = roc_auc_score(labels, preds)
        params = sum(p.numel() for p in model.parameters())
        qps = len(test_loader.dataset) / inference_time

        results[name] = {
            'auc': auc,
            'params': params,
            'time': inference_time,
            'qps': qps
        }

        print(f"\n{name}:")
        print(f"  AUC: {auc:.4f}")
        print(f"  å‚æ•°é‡: {params:,}")
        print(f"  æ¨ç†æ—¶é—´: {inference_time:.3f}s")
        print(f"  QPS: {qps:.1f}")

    return results


# ============ ä¸»å‡½æ•° ============

def main():
    print("\n" + "ğŸš€ " + "=" * 58)
    print("  ç²—æ’ï¼ˆCoarse Rankingï¼‰- PyTorchå®ç°")
    print("  æ¨èç³»ç»Ÿå¬å›å’Œç²¾æ’ä¹‹é—´çš„è¿‡æ¸¡å±‚")
    print("=" * 60)

    print(f"\nä½¿ç”¨è®¾å¤‡: {DEVICE}")

    print("\n" + "=" * 60)
    print("åˆ›å»ºæ•°æ®é›†")
    print("=" * 60)

    train_dataset = RankingDataset(num_samples=50000, num_users=1000, num_items=500)
    val_dataset = RankingDataset(num_samples=10000, num_users=1000, num_items=500)
    test_dataset = RankingDataset(num_samples=5000, num_users=1000, num_items=500)

    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)
    test_loader = DataLoader(test_dataset, batch_size=256, shuffle=False)

    print(f"è®­ç»ƒé›†: {len(train_dataset)}, éªŒè¯é›†: {len(val_dataset)}, æµ‹è¯•é›†: {len(test_dataset)}")

    print("\n" + "=" * 60)
    print("åˆ›å»ºæ¨¡å‹")
    print("=" * 60)

    # ç²—æ’æ¨¡å‹1ï¼šåŒå¡”å¢å¼ºç‰ˆ
    coarse_two_tower = CoarseRankingModel_TwoTower(
        num_users=train_dataset.num_users,
        num_items=train_dataset.num_items,
        num_ages=train_dataset.num_ages,
        num_genders=train_dataset.num_genders,
        num_categories=train_dataset.num_categories,
        embedding_dim=16
    ).to(DEVICE)

    # ç²—æ’æ¨¡å‹2ï¼šè½»é‡çº§ MLP
    coarse_light_mlp = CoarseRankingModel_LightMLP(
        num_users=train_dataset.num_users,
        num_items=train_dataset.num_items,
        num_ages=train_dataset.num_ages,
        num_genders=train_dataset.num_genders,
        num_categories=train_dataset.num_categories,
        embedding_dim=16
    ).to(DEVICE)

    # ç²¾æ’æ¨¡å‹ï¼ˆä½œä¸ºå¯¹æ¯”åŸºå‡†ï¼‰
    fine_ranking = FineRankingModel(
        num_users=train_dataset.num_users,
        num_items=train_dataset.num_items,
        num_ages=train_dataset.num_ages,
        num_genders=train_dataset.num_genders,
        num_categories=train_dataset.num_categories,
        embedding_dim=32
    ).to(DEVICE)

    print(f"ç²—æ’-åŒå¡”: {sum(p.numel() for p in coarse_two_tower.parameters()):,} å‚æ•°")
    print(f"ç²—æ’-MLP: {sum(p.numel() for p in coarse_light_mlp.parameters()):,} å‚æ•°")
    print(f"ç²¾æ’: {sum(p.numel() for p in fine_ranking.parameters()):,} å‚æ•°")

    print("\n" + "=" * 60)
    print("è®­ç»ƒæ¨¡å‹")
    print("=" * 60)

    train_model(coarse_two_tower, train_loader, val_loader, DEVICE, "ç²—æ’-åŒå¡”", num_epochs=15)
    train_model(coarse_light_mlp, train_loader, val_loader, DEVICE, "ç²—æ’-MLP", num_epochs=15)
    train_model(fine_ranking, train_loader, val_loader, DEVICE, "ç²¾æ’", num_epochs=15)

    # æ€§èƒ½å¯¹æ¯”
    models = {
        'ç²—æ’-åŒå¡”': coarse_two_tower,
        'ç²—æ’-MLP': coarse_light_mlp,
        'ç²¾æ’': fine_ranking
    }

    results = compare_models(models, test_loader, DEVICE)

    print("\n" + "=" * 60)
    print("å­¦ä¹ æ€»ç»“")
    print("=" * 60)

    print("""
1. ç²—æ’çš„ä½œç”¨
   âœ“ æ‰¿ä¸Šå¯ä¸‹ï¼šå¬å› â†’ ç²—æ’ â†’ ç²¾æ’
   âœ“ é™ä½ç²¾æ’å‹åŠ›ï¼šè¿‡æ»¤æ‰æ˜æ˜¾ä¸ç›¸å…³çš„å€™é€‰
   âœ“ å¹³è¡¡æ•ˆæœå’Œæ€§èƒ½

2. ç²—æ’æ–¹æ³•å¯¹æ¯”
   âœ“ åŒå¡”å¢å¼ºç‰ˆï¼šç®€å•å¿«é€Ÿï¼Œä½†æ•ˆæœæœ‰é™
   âœ“ è½»é‡çº§ MLPï¼šæ•ˆæœå¥½ï¼Œå‚æ•°å°‘
   âœ“ çŸ¥è¯†è’¸é¦ï¼šå­¦ä¹ ç²¾æ’æ¨¡å‹ï¼ˆæœªå®ç°ï¼‰

3. å…³é”®æŒ‡æ ‡
   âœ“ AUCï¼šæ’åºèƒ½åŠ›ï¼ˆæ¥è¿‘ç²¾æ’ï¼‰
   âœ“ å‚æ•°é‡ï¼š< ç²¾æ’çš„ 20%
   âœ“ QPSï¼š> ç²¾æ’çš„ 5 å€

4. å·¥ä¸šå®è·µ
   âœ“ ç‰¹å¾é€‰æ‹©ï¼šå»æ‰å¤æ‚ç‰¹å¾ï¼ˆå†å²åºåˆ—ç­‰ï¼‰
   âœ“ æ¨¡å‹å‹ç¼©ï¼šå‰ªæã€é‡åŒ–
   âœ“ åœ¨çº¿æœåŠ¡ï¼šæ‰¹å¤„ç†ã€ç¼“å­˜

5. ä¸‹ä¸€æ­¥
   â†’ é‡æ’ï¼šå¤šæ ·æ€§ã€æ‰“æ•£
   â†’ æ··æ’ï¼šå¹¿å‘Šç©¿æ’ã€è¿è¥ä½
    """)

    print("\nâœ… ç²—æ’å­¦ä¹ å®Œæˆï¼")


if __name__ == "__main__":
    main()
