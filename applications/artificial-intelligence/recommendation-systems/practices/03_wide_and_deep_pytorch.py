"""
Wide & Deep æ¨¡å‹ - PyTorchå®ç°
æ¨èç³»ç»Ÿç²¾æ’é˜¶æ®µçš„ç»å…¸æ¶æ„ï¼ˆGoogle 2016ï¼‰

ä½œè€…: Zhang Wenchao
æ—¥æœŸ: 2025-11-22

====================================================================
ğŸ“– æ¨èç³»ç»Ÿé“¾è·¯ä¸­çš„ä½ç½®
====================================================================

ç”¨æˆ·è¯·æ±‚
   â†“
1. å¬å›ï¼ˆRetrievalï¼‰âœ… å·²å­¦ä¹ 
   - åŒå¡”æ¨¡å‹ï¼šç™¾ä¸‡ â†’ å‡ åƒ
   â†“
2. ç²—æ’ï¼ˆPre-Rankingï¼Œå¯é€‰ï¼‰
   - å‡ åƒ â†’ å‡ ç™¾
   â†“
3. ç²¾æ’ï¼ˆRankingï¼‰â† æˆ‘ä»¬åœ¨è¿™é‡Œï¼
   - Wide & Deepï¼šå‡ ç™¾ â†’ å‡ å
   - ç²¾å‡†é¢„æµ‹ç”¨æˆ·ç‚¹å‡»/è´­ä¹°æ¦‚ç‡
   â†“
4. é‡æ’ï¼ˆRe-Rankingï¼‰
   - å¤šæ ·æ€§ã€æ‰“æ•£
   â†“
å±•ç¤ºç»™ç”¨æˆ·

====================================================================
ğŸ¯ ä¸ºä»€ä¹ˆéœ€è¦ Wide & Deepï¼Ÿ
====================================================================

å¬å›é˜¶æ®µçš„é—®é¢˜ï¼š
- åŒå¡”æ¨¡å‹ï¼šåªèƒ½ç”¨ç‚¹ç§¯è®¡ç®—ç›¸ä¼¼åº¦
- æ— æ³•å»ºæ¨¡ç‰¹å¾ä¹‹é—´çš„äº¤å‰ï¼ˆå¦‚ï¼šå¹´é¾„Ã—æ€§åˆ«ã€ç±»åˆ«Ã—ä»·æ ¼ï¼‰
- åªé€‚åˆå¿«é€Ÿç­›é€‰ï¼Œä¸é€‚åˆç²¾å‡†æ’åº

ç²¾æ’é˜¶æ®µçš„éœ€æ±‚ï¼š
âœ“ ç²¾å‡†é¢„æµ‹ç‚¹å‡»ç‡/è½¬åŒ–ç‡ï¼ˆCTR/CVRï¼‰
âœ“ åˆ©ç”¨ä¸°å¯Œçš„ç‰¹å¾äº¤å‰
âœ“ å¹³è¡¡è®°å¿†èƒ½åŠ›å’Œæ³›åŒ–èƒ½åŠ›

====================================================================
ğŸ—ï¸ Wide & Deep æ¶æ„
====================================================================

                   ç”¨æˆ·ç‰¹å¾ + ç‰©å“ç‰¹å¾ + äº¤äº’ç‰¹å¾
                            â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                                       â†“
    Wide éƒ¨åˆ†                               Deep éƒ¨åˆ†
  (çº¿æ€§æ¨¡å‹)                              (æ·±åº¦ç½‘ç»œ)
        â†“                                       â†“
  äº¤å‰ç‰¹å¾ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€ Embedding + MLP
  [ageÃ—gender,         â”‚              â”‚     [user_emb,
   categoryÃ—price]     â”‚              â”‚      item_emb,
        â†“              â”‚              â”‚      age, gender...]
   Linear(ç¨€ç–)        â”‚              â”‚          â†“
        â†“              â”‚              â”‚      MLP(256â†’128â†’64)
     logit_wide â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€ logit_deep
                            â†“
                      logit = logit_wide + logit_deep
                            â†“
                      sigmoid(logit) â†’ é¢„æµ‹æ¦‚ç‡ (0-1)

====================================================================
ğŸ”‘ Wide vs Deep çš„åŒºåˆ«
====================================================================

Wide éƒ¨åˆ†ï¼ˆè®°å¿†èƒ½åŠ› - Memorizationï¼‰ï¼š
- çº¿æ€§æ¨¡å‹ï¼šy = wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + b
- ç‰¹å¾ï¼šäººå·¥è®¾è®¡çš„äº¤å‰ç‰¹å¾ï¼ˆå¦‚ AND(gender=female, category=ç¾å¦†)ï¼‰
- ä¼˜ç‚¹ï¼šè®°ä½è®­ç»ƒæ•°æ®ä¸­çš„è§„åˆ™ï¼ˆå¥³æ€§ + ç¾å¦† â†’ é«˜ç‚¹å‡»ï¼‰
- ç¼ºç‚¹ï¼šæ— æ³•æ³›åŒ–åˆ°æœªè§è¿‡çš„ç»„åˆ

Deep éƒ¨åˆ†ï¼ˆæ³›åŒ–èƒ½åŠ› - Generalizationï¼‰ï¼š
- æ·±åº¦ç½‘ç»œï¼šè‡ªåŠ¨å­¦ä¹ ç‰¹å¾è¡¨ç¤º
- ç‰¹å¾ï¼šåŸå§‹ç‰¹å¾ + Embedding
- ä¼˜ç‚¹ï¼šæ³›åŒ–åˆ°æ–°ç»„åˆï¼ˆç±»ä¼¼ç¾å¦†çš„ç±»åˆ«ä¹Ÿå¯èƒ½è¢«æ¨èï¼‰
- ç¼ºç‚¹ï¼šå¯èƒ½å¿½ç•¥é‡è¦çš„è§„åˆ™

ç»„åˆçš„å¥½å¤„ï¼š
âœ“ Wideï¼šè®°ä½ç¡®å®šçš„è§„åˆ™ï¼ˆå¦‚ä¿ƒé”€å•†å“ + ä»·æ ¼æ•æ„Ÿç”¨æˆ·ï¼‰
âœ“ Deepï¼šå‘ç°æ½œåœ¨çš„æ¨¡å¼ï¼ˆå¦‚ç›¸ä¼¼ç”¨æˆ·çš„è¡Œä¸ºï¼‰
âœ“ äº’è¡¥ï¼šæ—¢ç²¾å‡†åˆèƒ½æ³›åŒ–

====================================================================
ğŸ“Š æ•°æ®æ ¼å¼ç¤ºä¾‹
====================================================================

è¾“å…¥ç‰¹å¾ï¼š
{
    # ç”¨æˆ·ç‰¹å¾
    'user_id': 123,
    'age': 25,
    'gender': 1,
    'city': 'Beijing',

    # ç‰©å“ç‰¹å¾
    'item_id': 456,
    'category': 'Electronics',
    'price': 999,
    'brand': 'Apple',

    # äº¤äº’ç‰¹å¾
    'hour': 14,  # è®¿é—®æ—¶é—´
    'device': 'mobile'
}

è¾“å‡ºï¼š
- label: 1 (ç‚¹å‡») / 0 (æœªç‚¹å‡»)
- é¢„æµ‹: 0.85 (85% æ¦‚ç‡ä¼šç‚¹å‡»)

====================================================================
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import matplotlib.pyplot as plt
from torch.utils.data import Dataset, DataLoader
from sklearn.metrics import roc_auc_score, log_loss

# è®¾ç½®éšæœºç§å­
torch.manual_seed(42)
np.random.seed(42)

DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')


# ============ 1. æ•°æ®å‡†å¤‡ ============

class CTRDataset(Dataset):
    """ç‚¹å‡»ç‡é¢„æµ‹æ•°æ®é›†ï¼ˆæ¨¡æ‹Ÿç”µå•†åœºæ™¯ï¼‰

    ç‰¹å¾ï¼š
    - ç”¨æˆ·ï¼šuser_id, age, gender, city
    - ç‰©å“ï¼šitem_id, category, price, brand
    - ä¸Šä¸‹æ–‡ï¼šhour, device

    æ ‡ç­¾ï¼šæ˜¯å¦ç‚¹å‡» (0/1)
    """

    def __init__(self, num_samples=10000, num_users=1000, num_items=500):
        self.num_samples = num_samples
        self.num_users = num_users
        self.num_items = num_items

        # ç‰¹å¾ç©ºé—´å¤§å°
        self.num_ages = 5       # 5ä¸ªå¹´é¾„æ®µ
        self.num_genders = 2    # 2ç§æ€§åˆ«
        self.num_cities = 10    # 10ä¸ªåŸå¸‚
        self.num_categories = 20  # 20ä¸ªç±»ç›®
        self.num_brands = 50    # 50ä¸ªå“ç‰Œ
        self.num_hours = 24     # 24å°æ—¶
        self.num_devices = 2    # 2ç§è®¾å¤‡

        # ç”Ÿæˆç”¨æˆ·ç”»åƒ
        self.user_ages = np.random.randint(0, self.num_ages, num_users)
        self.user_genders = np.random.randint(0, self.num_genders, num_users)
        self.user_cities = np.random.randint(0, self.num_cities, num_users)

        # ç”Ÿæˆç‰©å“å±æ€§
        self.item_categories = np.random.randint(0, self.num_categories, num_items)
        self.item_brands = np.random.randint(0, self.num_brands, num_items)
        self.item_prices = np.random.uniform(10, 1000, num_items)  # ä»·æ ¼10-1000

        # ç”Ÿæˆäº¤äº’æ•°æ®
        self.samples = []
        for _ in range(num_samples):
            user_id = np.random.randint(0, num_users)
            item_id = np.random.randint(0, num_items)
            hour = np.random.randint(0, self.num_hours)
            device = np.random.randint(0, self.num_devices)

            # æ¨¡æ‹Ÿç‚¹å‡»è§„å¾‹ï¼ˆç®€åŒ–ç‰ˆï¼‰
            age = self.user_ages[user_id]
            gender = self.user_genders[user_id]
            category = self.item_categories[item_id]
            price = self.item_prices[item_id]

            # è§„åˆ™1ï¼šå¹´è½»äºº(age<2) + ç”µå­äº§å“(category<5) â†’ é«˜ç‚¹å‡»
            rule1 = (age < 2 and category < 5)

            # è§„åˆ™2ï¼šå¥³æ€§(gender=1) + ç¾å¦†(category in [10,11,12]) â†’ é«˜ç‚¹å‡»
            rule2 = (gender == 1 and category in [10, 11, 12])

            # è§„åˆ™3ï¼šæ™šä¸Š(hour>18) + å¨±ä¹(category in [15,16,17]) â†’ é«˜ç‚¹å‡»
            rule3 = (hour > 18 and category in [15, 16, 17])

            # è§„åˆ™4ï¼šä½ä»·(<100) â†’ é«˜ç‚¹å‡»
            rule4 = (price < 100)

            # ç»¼åˆåˆ¤æ–­
            click_prob = 0.1  # åŸºç¡€ç‚¹å‡»ç‡
            if rule1: click_prob += 0.4
            if rule2: click_prob += 0.4
            if rule3: click_prob += 0.3
            if rule4: click_prob += 0.2

            label = 1 if np.random.rand() < click_prob else 0

            self.samples.append({
                'user_id': user_id,
                'item_id': item_id,
                'age': self.user_ages[user_id],
                'gender': self.user_genders[user_id],
                'city': self.user_cities[user_id],
                'category': category,
                'brand': self.item_brands[item_id],
                'price': price,
                'hour': hour,
                'device': device,
                'label': label
            })

    def __len__(self):
        return self.num_samples

    def __getitem__(self, idx):
        sample = self.samples[idx]
        return {
            # IDç‰¹å¾
            'user_id': torch.LongTensor([sample['user_id']]),
            'item_id': torch.LongTensor([sample['item_id']]),

            # ç±»åˆ«ç‰¹å¾
            'age': torch.LongTensor([sample['age']]),
            'gender': torch.LongTensor([sample['gender']]),
            'city': torch.LongTensor([sample['city']]),
            'category': torch.LongTensor([sample['category']]),
            'brand': torch.LongTensor([sample['brand']]),
            'hour': torch.LongTensor([sample['hour']]),
            'device': torch.LongTensor([sample['device']]),

            # æ•°å€¼ç‰¹å¾
            'price': torch.FloatTensor([sample['price']]),

            # æ ‡ç­¾
            'label': torch.FloatTensor([sample['label']])
        }


# ============ 2. Wide & Deep æ¨¡å‹ ============

class WideAndDeepModel(nn.Module):
    """Wide & Deep æ¨¡å‹

    Wide éƒ¨åˆ†ï¼šçº¿æ€§æ¨¡å‹ + äº¤å‰ç‰¹å¾
    Deep éƒ¨åˆ†ï¼šEmbedding + MLP
    """

    def __init__(self,
                 num_users, num_items, num_ages, num_genders, num_cities,
                 num_categories, num_brands, num_hours, num_devices,
                 embedding_dim=16, hidden_dims=[256, 128, 64]):
        super().__init__()

        # ============ Deep éƒ¨åˆ† ============

        # Embedding å±‚ï¼ˆå°†IDå’Œç±»åˆ«ç‰¹å¾æ˜ å°„ä¸ºç¨ å¯†å‘é‡ï¼‰
        self.user_embedding = nn.Embedding(num_users, embedding_dim)
        self.item_embedding = nn.Embedding(num_items, embedding_dim)
        self.age_embedding = nn.Embedding(num_ages, embedding_dim // 2)
        self.gender_embedding = nn.Embedding(num_genders, embedding_dim // 4)
        self.city_embedding = nn.Embedding(num_cities, embedding_dim // 2)
        self.category_embedding = nn.Embedding(num_categories, embedding_dim // 2)
        self.brand_embedding = nn.Embedding(num_brands, embedding_dim // 2)
        self.hour_embedding = nn.Embedding(num_hours, embedding_dim // 4)
        self.device_embedding = nn.Embedding(num_devices, embedding_dim // 4)

        # è®¡ç®— Deep éƒ¨åˆ†çš„è¾“å…¥ç»´åº¦
        deep_input_dim = (
            embedding_dim * 2 +              # user + item
            (embedding_dim // 2) * 4 +       # age + city + category + brand
            (embedding_dim // 4) * 3 +       # gender + hour + device
            1                                # price (æ•°å€¼ç‰¹å¾)
        )

        # Deep MLP
        layers = []
        input_dim = deep_input_dim
        for hidden_dim in hidden_dims:
            layers.append(nn.Linear(input_dim, hidden_dim))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(0.2))
            input_dim = hidden_dim

        self.deep_mlp = nn.Sequential(*layers)
        self.deep_output = nn.Linear(hidden_dims[-1], 1)

        # ============ Wide éƒ¨åˆ† ============

        # Wide éƒ¨åˆ†ä½¿ç”¨åŸå§‹ç‰¹å¾ + äº¤å‰ç‰¹å¾
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼šä¸ºæ¯ç§äº¤å‰ç»„åˆåˆ›å»º Embedding
        # å®é™…ç”Ÿäº§ä¸­ä¼šç”¨ç¨€ç–çŸ©é˜µæˆ– Feature Hashing

        # äº¤å‰ç‰¹å¾1ï¼šage Ã— genderï¼ˆ5 Ã— 2 = 10ç§ç»„åˆï¼‰
        self.cross_age_gender = nn.Embedding(num_ages * num_genders, 1)

        # äº¤å‰ç‰¹å¾2ï¼šcategory Ã— genderï¼ˆ20 Ã— 2 = 40ç§ç»„åˆï¼‰
        self.cross_category_gender = nn.Embedding(num_categories * num_genders, 1)

        # äº¤å‰ç‰¹å¾3ï¼šhour Ã— deviceï¼ˆ24 Ã— 2 = 48ç§ç»„åˆï¼‰
        self.cross_hour_device = nn.Embedding(num_hours * num_devices, 1)

        # Wide çš„çº¿æ€§è¾“å‡º
        self.wide_output = nn.Linear(3, 1)  # 3ä¸ªäº¤å‰ç‰¹å¾

        # ä¿å­˜ç‰¹å¾ç©ºé—´å¤§å°ï¼ˆç”¨äºè®¡ç®—äº¤å‰ç‰¹å¾IDï¼‰
        self.num_genders = num_genders
        self.num_devices = num_devices

    def forward(self, user_id, item_id, age, gender, city, category, brand,
                price, hour, device):
        """
        å‰å‘ä¼ æ’­

        è¿”å›:
            logit: (batch_size,) - é¢„æµ‹çš„ logitï¼ˆæœªç»è¿‡sigmoidï¼‰
        """
        batch_size = user_id.size(0)

        # ============ Deep éƒ¨åˆ† ============

        # 1. Embedding
        user_emb = self.user_embedding(user_id).squeeze(1)      # (batch, emb_dim)
        item_emb = self.item_embedding(item_id).squeeze(1)
        age_emb = self.age_embedding(age).squeeze(1)
        gender_emb = self.gender_embedding(gender).squeeze(1)
        city_emb = self.city_embedding(city).squeeze(1)
        category_emb = self.category_embedding(category).squeeze(1)
        brand_emb = self.brand_embedding(brand).squeeze(1)
        hour_emb = self.hour_embedding(hour).squeeze(1)
        device_emb = self.device_embedding(device).squeeze(1)

        # 2. æ‹¼æ¥æ‰€æœ‰ç‰¹å¾
        deep_input = torch.cat([
            user_emb, item_emb, age_emb, gender_emb, city_emb,
            category_emb, brand_emb, hour_emb, device_emb, price
        ], dim=1)

        # 3. é€šè¿‡ MLP
        deep_hidden = self.deep_mlp(deep_input)
        logit_deep = self.deep_output(deep_hidden).squeeze(1)  # (batch,)

        # ============ Wide éƒ¨åˆ† ============

        # 1. æ„é€ äº¤å‰ç‰¹å¾ID
        # age Ã— gender: å°†(age, gender)æ˜ å°„ä¸ºä¸€ä¸ªID
        cross_id_1 = (age * self.num_genders + gender).squeeze(1)  # (batch,)

        # category Ã— gender
        cross_id_2 = (category * self.num_genders + gender).squeeze(1)

        # hour Ã— device
        cross_id_3 = (hour * self.num_devices + device).squeeze(1)

        # 2. è·å–äº¤å‰ç‰¹å¾çš„æƒé‡
        cross_feat_1 = self.cross_age_gender(cross_id_1).squeeze(1)  # (batch,)
        cross_feat_2 = self.cross_category_gender(cross_id_2).squeeze(1)
        cross_feat_3 = self.cross_hour_device(cross_id_3).squeeze(1)

        # 3. Wide çš„çº¿æ€§ç»„åˆ
        wide_input = torch.stack([cross_feat_1, cross_feat_2, cross_feat_3], dim=1)  # (batch, 3)
        logit_wide = self.wide_output(wide_input).squeeze(1)  # (batch,)

        # ============ ç»„åˆ Wide + Deep ============

        logit = logit_wide + logit_deep

        return logit


# ============ 3. è®­ç»ƒ ============

def train_model(model, train_loader, val_loader, device, num_epochs=20, lr=0.001):
    """è®­ç»ƒ Wide & Deep æ¨¡å‹"""
    # äºŒåˆ†ç±»ä½¿ç”¨ BCEWithLogitsLossï¼ˆå†…ç½®sigmoidï¼Œæ•°å€¼æ›´ç¨³å®šï¼‰
    criterion = nn.BCEWithLogitsLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=lr)

    history = {'train_loss': [], 'train_auc': [], 'val_loss': [], 'val_auc': []}

    print("\nå¼€å§‹è®­ç»ƒ...")
    for epoch in range(num_epochs):
        # è®­ç»ƒé˜¶æ®µ
        model.train()
        train_loss = 0
        train_preds = []
        train_labels = []

        for batch in train_loader:
            # æå–ç‰¹å¾
            user_id = batch['user_id'].to(device)
            item_id = batch['item_id'].to(device)
            age = batch['age'].to(device)
            gender = batch['gender'].to(device)
            city = batch['city'].to(device)
            category = batch['category'].to(device)
            brand = batch['brand'].to(device)
            price = batch['price'].to(device)
            hour = batch['hour'].to(device)
            device_feat = batch['device'].to(device)
            label = batch['label'].to(device).squeeze()

            optimizer.zero_grad()

            # å‰å‘ä¼ æ’­
            logit = model(user_id, item_id, age, gender, city, category,
                         brand, price, hour, device_feat)

            # è®¡ç®—æŸå¤±
            loss = criterion(logit, label)

            # åå‘ä¼ æ’­
            loss.backward()
            optimizer.step()

            # ç»Ÿè®¡
            train_loss += loss.item()
            train_preds.extend(torch.sigmoid(logit).detach().cpu().numpy())
            train_labels.extend(label.cpu().numpy())

        train_loss /= len(train_loader)
        train_auc = roc_auc_score(train_labels, train_preds)

        # éªŒè¯é˜¶æ®µ
        model.eval()
        val_loss = 0
        val_preds = []
        val_labels = []

        with torch.no_grad():
            for batch in val_loader:
                user_id = batch['user_id'].to(device)
                item_id = batch['item_id'].to(device)
                age = batch['age'].to(device)
                gender = batch['gender'].to(device)
                city = batch['city'].to(device)
                category = batch['category'].to(device)
                brand = batch['brand'].to(device)
                price = batch['price'].to(device)
                hour = batch['hour'].to(device)
                device_feat = batch['device'].to(device)
                label = batch['label'].to(device).squeeze()

                logit = model(user_id, item_id, age, gender, city, category,
                            brand, price, hour, device_feat)
                loss = criterion(logit, label)

                val_loss += loss.item()
                val_preds.extend(torch.sigmoid(logit).cpu().numpy())
                val_labels.extend(label.cpu().numpy())

        val_loss /= len(val_loader)
        val_auc = roc_auc_score(val_labels, val_preds)

        history['train_loss'].append(train_loss)
        history['train_auc'].append(train_auc)
        history['val_loss'].append(val_loss)
        history['val_auc'].append(val_auc)

        if (epoch + 1) % 5 == 0:
            print(f'Epoch {epoch+1}/{num_epochs}:')
            print(f'  Train Loss: {train_loss:.4f}, Train AUC: {train_auc:.4f}')
            print(f'  Val Loss: {val_loss:.4f}, Val AUC: {val_auc:.4f}')

    return history


# ============ 4. å¯è§†åŒ– ============

def plot_training_history(history):
    """ç»˜åˆ¶è®­ç»ƒå†å²"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))

    ax1.plot(history['train_loss'], label='Train Loss')
    ax1.plot(history['val_loss'], label='Val Loss')
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Loss')
    ax1.set_title('Training and Validation Loss')
    ax1.legend()
    ax1.grid(True)

    ax2.plot(history['train_auc'], label='Train AUC')
    ax2.plot(history['val_auc'], label='Val AUC')
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('AUC')
    ax2.set_title('Training and Validation AUC')
    ax2.legend()
    ax2.grid(True)

    plt.tight_layout()
    plt.savefig('wide_and_deep_training.png', dpi=150)
    print("\nè®­ç»ƒå†å²å·²ä¿å­˜åˆ° wide_and_deep_training.png")
    plt.close()


# ============ ä¸»å‡½æ•° ============

def main():
    print("\n" + "ğŸš€ " + "=" * 58)
    print("  Wide & Deep æ¨¡å‹ - PyTorchå®ç°")
    print("  æ¨èç³»ç»Ÿç²¾æ’é˜¶æ®µçš„ç»å…¸æ¶æ„")
    print("=" * 60)

    # æ£€æŸ¥è®¾å¤‡
    print(f"\nä½¿ç”¨è®¾å¤‡: {DEVICE}")
    if torch.cuda.is_available():
        print(f"GPUå‹å·: {torch.cuda.get_device_name(0)}")

    # åˆ›å»ºæ•°æ®é›†
    print("\n" + "=" * 60)
    print("åˆ›å»ºç‚¹å‡»ç‡é¢„æµ‹æ•°æ®é›†")
    print("=" * 60)

    train_dataset = CTRDataset(num_samples=20000, num_users=1000, num_items=500)
    val_dataset = CTRDataset(num_samples=5000, num_users=1000, num_items=500)

    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)
    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False)

    print(f"è®­ç»ƒé›†å¤§å°: {len(train_dataset)}")
    print(f"éªŒè¯é›†å¤§å°: {len(val_dataset)}")

    # è®¡ç®—æ­£è´Ÿæ ·æœ¬æ¯”ä¾‹
    train_labels = [s['label'] for s in train_dataset.samples]
    pos_ratio = sum(train_labels) / len(train_labels)
    print(f"æ­£æ ·æœ¬æ¯”ä¾‹: {pos_ratio:.2%}")

    # åˆ›å»ºæ¨¡å‹
    print("\n" + "=" * 60)
    print("åˆ›å»º Wide & Deep æ¨¡å‹")
    print("=" * 60)

    model = WideAndDeepModel(
        num_users=train_dataset.num_users,
        num_items=train_dataset.num_items,
        num_ages=train_dataset.num_ages,
        num_genders=train_dataset.num_genders,
        num_cities=train_dataset.num_cities,
        num_categories=train_dataset.num_categories,
        num_brands=train_dataset.num_brands,
        num_hours=train_dataset.num_hours,
        num_devices=train_dataset.num_devices,
        embedding_dim=16,
        hidden_dims=[256, 128, 64]
    ).to(DEVICE)

    print(f"æ¨¡å‹å‚æ•°é‡: {sum(p.numel() for p in model.parameters()):,}")

    # è®­ç»ƒæ¨¡å‹
    print("\n" + "=" * 60)
    print("è®­ç»ƒæ¨¡å‹")
    print("=" * 60)

    history = train_model(model, train_loader, val_loader, DEVICE, num_epochs=30, lr=0.001)

    # å¯è§†åŒ–
    plot_training_history(history)

    # æµ‹è¯•é¢„æµ‹
    print("\n" + "=" * 60)
    print("æµ‹è¯•é¢„æµ‹")
    print("=" * 60)

    model.eval()
    with torch.no_grad():
        for i in range(3):
            sample = val_dataset[i]

            # å‡†å¤‡è¾“å…¥
            user_id = sample['user_id'].unsqueeze(0).to(DEVICE)
            item_id = sample['item_id'].unsqueeze(0).to(DEVICE)
            age = sample['age'].unsqueeze(0).to(DEVICE)
            gender = sample['gender'].unsqueeze(0).to(DEVICE)
            city = sample['city'].unsqueeze(0).to(DEVICE)
            category = sample['category'].unsqueeze(0).to(DEVICE)
            brand = sample['brand'].unsqueeze(0).to(DEVICE)
            price = sample['price'].unsqueeze(0).to(DEVICE)
            hour = sample['hour'].unsqueeze(0).to(DEVICE)
            device_feat = sample['device'].unsqueeze(0).to(DEVICE)

            logit = model(user_id, item_id, age, gender, city, category,
                         brand, price, hour, device_feat)
            pred_prob = torch.sigmoid(logit).item()
            true_label = sample['label'].item()

            print(f"\næ ·æœ¬ {i+1}:")
            print(f"  ç”¨æˆ·ID: {user_id.item()}, ç‰©å“ID: {item_id.item()}")
            print(f"  ç‰¹å¾: age={age.item()}, gender={gender.item()}, category={category.item()}, price={price.item():.1f}")
            print(f"  é¢„æµ‹æ¦‚ç‡: {pred_prob:.3f}")
            print(f"  çœŸå®æ ‡ç­¾: {int(true_label)}")
            print(f"  é¢„æµ‹ç»“æœ: {'ç‚¹å‡» âœ“' if pred_prob > 0.5 else 'ä¸ç‚¹å‡» âœ—'}")

    # æ€»ç»“
    print("\n" + "=" * 60)
    print("å­¦ä¹ æ€»ç»“")
    print("=" * 60)

    print("""
1. Wide & Deep æ¶æ„
   âœ“ Wide éƒ¨åˆ†: çº¿æ€§æ¨¡å‹ + äº¤å‰ç‰¹å¾ â†’ è®°å¿†èƒ½åŠ›
   âœ“ Deep éƒ¨åˆ†: Embedding + MLP â†’ æ³›åŒ–èƒ½åŠ›
   âœ“ ç»„åˆ: logit = logit_wide + logit_deep

2. Wide éƒ¨åˆ†ï¼ˆè®°å¿†ï¼‰
   âœ“ äº¤å‰ç‰¹å¾: ageÃ—gender, categoryÃ—gender, hourÃ—device
   âœ“ æ•è·ç¡®å®šçš„è§„åˆ™: "å¥³æ€§+ç¾å¦†â†’é«˜ç‚¹å‡»"
   âœ“ å®ç°æ–¹å¼: Embeddingï¼ˆç®€åŒ–ç‰ˆï¼‰æˆ–ç¨€ç–çŸ©é˜µ

3. Deep éƒ¨åˆ†ï¼ˆæ³›åŒ–ï¼‰
   âœ“ Embedding: å°†ID/ç±»åˆ«æ˜ å°„ä¸ºç¨ å¯†å‘é‡
   âœ“ MLP: è‡ªåŠ¨å­¦ä¹ ç‰¹å¾ç»„åˆ
   âœ“ æ³›åŒ–åˆ°æ–°ç»„åˆ: ç±»ä¼¼çš„ç”¨æˆ·/ç‰©å“

4. ä¸åŒå¡”æ¨¡å‹çš„åŒºåˆ«
   åŒå¡”æ¨¡å‹ï¼ˆå¬å›ï¼‰:
   - ç”¨æˆ·å¡” + ç‰©å“å¡”ç‹¬ç«‹
   - åªèƒ½ç”¨ç‚¹ç§¯è®¡ç®—ç›¸ä¼¼åº¦
   - å¿«é€Ÿä½†ä¸ç²¾å‡†

   Wide & Deepï¼ˆç²¾æ’ï¼‰:
   - ç”¨æˆ·å’Œç‰©å“ç‰¹å¾ä¸€èµ·è¾“å…¥
   - å¯ä»¥å»ºæ¨¡ä»»æ„ç‰¹å¾äº¤å‰
   - æ…¢ä½†ç²¾å‡†

5. è¯„ä»·æŒ‡æ ‡
   âœ“ AUC (Area Under Curve): æ’åºèƒ½åŠ›
   âœ“ LogLoss: æ¦‚ç‡æ ¡å‡†ç¨‹åº¦
   âœ“ ç²¾æ’å…³æ³¨é¢„æµ‹çš„å‡†ç¡®æ€§ï¼Œä¸åªæ˜¯æ’åº

6. å·¥ä¸šå®è·µ
   âœ“ Wideç‰¹å¾: éœ€è¦äººå·¥è®¾è®¡ï¼ˆé¢†åŸŸçŸ¥è¯†ï¼‰
   âœ“ ç‰¹å¾å·¥ç¨‹: ç»Ÿè®¡ç‰¹å¾ã€åºåˆ—ç‰¹å¾ã€äº¤å‰ç‰¹å¾
   âœ“ åœ¨çº¿æœåŠ¡: Wideå’ŒDeepéƒ½åœ¨çº¿æ¨ç†ï¼ˆvs åŒå¡”çš„ç¦»çº¿ç´¢å¼•ï¼‰

7. ä¸‹ä¸€æ­¥
   â†’ DeepFM: è‡ªåŠ¨å­¦ä¹ äº¤å‰ç‰¹å¾ï¼ˆæ— éœ€äººå·¥è®¾è®¡ï¼‰
   â†’ DIN: ç”¨æˆ·å…´è¶£å»ºæ¨¡ï¼ˆæ³¨æ„åŠ›æœºåˆ¶ï¼‰
   â†’ å¤šä»»åŠ¡å­¦ä¹ : åŒæ—¶é¢„æµ‹ç‚¹å‡»+è½¬åŒ–
    """)

    print("\nâœ… Wide & Deep å­¦ä¹ å®Œæˆï¼")
    print("\næç¤º: Wide & Deep æ˜¯ç²¾æ’çš„åŸºç¡€ï¼Œæ¥ä¸‹æ¥å­¦ä¹  DeepFM å¯ä»¥è‡ªåŠ¨åŒ–ç‰¹å¾äº¤å‰")


if __name__ == "__main__":
    main()
