"""
å¾ªç¯ç¥ç»ç½‘ç»œ (RNN/LSTM) - PyTorch å®ç°

å¯¹æ¯” NumPy ç‰ˆæœ¬ï¼š
- NumPy: æ‰‹å†™RNN/LSTMï¼Œç†è§£é—¨æ§æœºåˆ¶
- PyTorch: ä½¿ç”¨æ¡†æ¶ï¼ŒGPUåŠ é€Ÿï¼Œå·¥ä¸šå®è·µ

æœ¬æ–‡ä»¶å†…å®¹ï¼š
1. PyTorch RNN/LSTM åŸºç¡€ç»„ä»¶
2. å®Œæ•´çš„åºåˆ—é¢„æµ‹æ¨¡å‹ï¼ˆæ—¶é—´åºåˆ—ï¼‰
3. GPU è®­ç»ƒåŠ é€Ÿ
4. è®­ç»ƒå¯è§†åŒ–
5. ä¸ NumPy ç‰ˆæœ¬æ€§èƒ½å¯¹æ¯”
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import matplotlib.pyplot as plt
import time


# ==================== 1. PyTorch RNN/LSTM åŸºç¡€ç»„ä»¶ ====================
def demo_pytorch_rnn():
    """
    æ¼”ç¤º PyTorch çš„ RNN æ“ä½œ

    ====================================================================
    ğŸ”‘ PyTorch vs NumPy RNN
    ====================================================================

    NumPy ç‰ˆæœ¬ï¼ˆæ‰‹å†™å¾ªç¯ï¼‰ï¼š
    ```python
    def forward(self, X):
        h = np.zeros((batch_size, hidden_size))
        for t in range(seq_len):
            h = np.tanh(np.dot(X[:, t, :], W_xh) + np.dot(h, W_hh) + b_h)
            # ...
    ```

    PyTorch ç‰ˆæœ¬ï¼ˆä¸€è¡Œï¼‰ï¼š
    ```python
    output, hidden = rnn(X)
    ```

    PyTorch å¸®ä½ åšäº†ä»€ä¹ˆï¼Ÿ
    - è‡ªåŠ¨å¾ªç¯å¤„ç†åºåˆ—
    - è‡ªåŠ¨æ‰¹é‡å¤„ç†ï¼ˆbatchï¼‰
    - è‡ªåŠ¨GPUåŠ é€Ÿ
    - è‡ªåŠ¨è®¡ç®—æ¢¯åº¦ï¼ˆBPTT - æ—¶é—´åå‘ä¼ æ’­ï¼‰
    - æ•°å€¼ä¼˜åŒ–ï¼ˆæ›´å¿«æ›´ç¨³å®šï¼‰

    ====================================================================
    """
    print("=" * 70)
    print("1. PyTorch RNN æ“ä½œæ¼”ç¤º")
    print("=" * 70)

    # åˆ›å»ºè¾“å…¥åºåˆ—ï¼ˆbatch_size=2, seq_len=5, input_size=3ï¼‰
    # PyTorch RNN æ ¼å¼ï¼š(seq_len, batch_size, input_size) æˆ– (batch_size, seq_len, input_size)
    batch_size = 2
    seq_len = 5
    input_size = 3
    hidden_size = 4

    # batch_first=False: (seq_len, batch, input_size) - é»˜è®¤æ ¼å¼
    X = torch.randn(seq_len, batch_size, input_size)
    print(f"\nè¾“å…¥åºåˆ— shape: {X.shape}")  # (5, 2, 3)

    # åˆ›å»º RNN å±‚
    rnn = nn.RNN(input_size=input_size, hidden_size=hidden_size, batch_first=False)

    print(f"RNN hidden size: {hidden_size}")

    # åˆå§‹åŒ–éšè—çŠ¶æ€ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä¸º0ï¼‰
    h0 = torch.zeros(1, batch_size, hidden_size)  # (num_layers, batch, hidden_size)

    # å‰å‘ä¼ æ’­
    output, hn = rnn(X, h0)

    print(f"\nè¾“å‡º shape: {output.shape}")  # (seq_len, batch, hidden_size) = (5, 2, 4)
    print(f"æœ€ç»ˆéšè—çŠ¶æ€ shape: {hn.shape}")  # (num_layers, batch, hidden_size) = (1, 2, 4)

    print("\nğŸ’¡ PyTorch RNN ä¼˜åŠ¿:")
    print("  - ä¸€è¡Œä»£ç å®Œæˆæ‰€æœ‰æ—¶é—´æ­¥")
    print("  - è‡ªåŠ¨å¤„ç†å˜é•¿åºåˆ—ï¼ˆpack_padded_sequenceï¼‰")
    print("  - è‡ªåŠ¨è®¡ç®—æ¢¯åº¦ï¼ˆBPTTï¼‰")
    print("  - GPU åŠ é€Ÿï¼ˆæ·»åŠ  .cuda()ï¼‰")

    # batch_first=True æ ¼å¼ï¼ˆæ›´å¸¸ç”¨ï¼‰
    print("\n" + "-" * 70)
    print("batch_first=True æ ¼å¼ï¼ˆæ¨èï¼‰")
    print("-" * 70)

    X_batch_first = torch.randn(batch_size, seq_len, input_size)  # (2, 5, 3)
    rnn_batch_first = nn.RNN(input_size=input_size, hidden_size=hidden_size,
                             batch_first=True)

    output, hn = rnn_batch_first(X_batch_first)
    print(f"è¾“å…¥ shape: {X_batch_first.shape}")  # (batch, seq_len, input_size)
    print(f"è¾“å‡º shape: {output.shape}")  # (batch, seq_len, hidden_size)


def demo_pytorch_lstm():
    """æ¼”ç¤º PyTorch çš„ LSTM æ“ä½œ"""
    print("\n" + "=" * 70)
    print("2. PyTorch LSTM æ“ä½œæ¼”ç¤º")
    print("=" * 70)

    batch_size = 2
    seq_len = 5
    input_size = 3
    hidden_size = 4

    # åˆ›å»ºè¾“å…¥
    X = torch.randn(batch_size, seq_len, input_size)
    print(f"\nè¾“å…¥åºåˆ— shape: {X.shape}")

    # åˆ›å»º LSTM å±‚
    lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)

    # åˆå§‹åŒ–éšè—çŠ¶æ€å’Œç»†èƒçŠ¶æ€
    h0 = torch.zeros(1, batch_size, hidden_size)  # Hidden state
    c0 = torch.zeros(1, batch_size, hidden_size)  # Cell state

    # å‰å‘ä¼ æ’­
    output, (hn, cn) = lstm(X, (h0, c0))

    print(f"\nè¾“å‡º shape: {output.shape}")  # (batch, seq_len, hidden_size)
    print(f"æœ€ç»ˆéšè—çŠ¶æ€ shape: {hn.shape}")  # (num_layers, batch, hidden_size)
    print(f"æœ€ç»ˆç»†èƒçŠ¶æ€ shape: {cn.shape}")  # (num_layers, batch, hidden_size)

    print("\nğŸ’¡ LSTM vs RNN:")
    print("  - LSTM è¿”å› (output, (hn, cn))ï¼Œæœ‰ä¸¤ä¸ªçŠ¶æ€")
    print("  - RNN è¿”å› (output, hn)ï¼Œåªæœ‰ä¸€ä¸ªçŠ¶æ€")
    print("  - LSTM å¯ä»¥å­¦ä¹ é•¿æœŸä¾èµ–")
    print("  - LSTM å‚æ•°é‡æ˜¯ RNN çš„ 4 å€")

    # å¤šå±‚ LSTM
    print("\n" + "-" * 70)
    print("å¤šå±‚ LSTM (Stacked LSTM)")
    print("-" * 70)

    lstm_stacked = nn.LSTM(input_size=input_size, hidden_size=hidden_size,
                          num_layers=2, batch_first=True)

    h0_stacked = torch.zeros(2, batch_size, hidden_size)  # 2 layers
    c0_stacked = torch.zeros(2, batch_size, hidden_size)

    output, (hn, cn) = lstm_stacked(X, (h0_stacked, c0_stacked))

    print(f"2å±‚LSTM è¾“å‡º shape: {output.shape}")
    print(f"2å±‚LSTM éšè—çŠ¶æ€ shape: {hn.shape}")  # (2, batch, hidden_size)


# ==================== 2. å®Œæ•´çš„åºåˆ—é¢„æµ‹æ¨¡å‹ ====================
class SequenceDataset(Dataset):
    """æ—¶é—´åºåˆ—æ•°æ®é›†"""

    def __init__(self, n_samples=1000, seq_len=20, noise=0.1):
        """
        ç”Ÿæˆæ­£å¼¦æ³¢åºåˆ—ç”¨äºé¢„æµ‹

        ä»»åŠ¡ï¼šç»™å®šå‰ seq_len ä¸ªç‚¹ï¼Œé¢„æµ‹ä¸‹ä¸€ä¸ªç‚¹
        """
        self.X = []
        self.y = []

        for i in range(n_samples):
            start = np.random.uniform(0, 100)
            time = np.linspace(start, start + seq_len + 1, seq_len + 1)
            sequence = np.sin(time) + np.random.randn(seq_len + 1) * noise

            self.X.append(sequence[:-1])  # è¾“å…¥: t=0 åˆ° t=seq_len-1
            self.y.append(sequence[-1])   # ç›®æ ‡: t=seq_len

        self.X = torch.FloatTensor(self.X).unsqueeze(-1)  # (n_samples, seq_len, 1)
        self.y = torch.FloatTensor(self.y).unsqueeze(-1)  # (n_samples, 1)

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        return self.X[idx], self.y[idx]


class RNNModel(nn.Module):
    """
    Simple RNN æ¨¡å‹

    ====================================================================
    ğŸ”‘ PyTorch RNN æ¨¡å‹ç»“æ„
    ====================================================================

    ç½‘ç»œç»“æ„ï¼š
    Input (batch, seq_len, input_size=1)
        â†“
    RNN (hidden_size=32)
        â†“
    Take last time step (batch, hidden_size)
        â†“
    Dropout (0.2)
        â†“
    Linear (hidden_size â†’ 1)
        â†“
    Output (batch, 1)
    """

    def __init__(self, input_size=1, hidden_size=32, output_size=1, num_layers=1):
        super(RNNModel, self).__init__()

        self.hidden_size = hidden_size
        self.num_layers = num_layers

        # RNN å±‚
        self.rnn = nn.RNN(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=0.2 if num_layers > 1 else 0  # Dropout only for multi-layer
        )

        # Dropout
        self.dropout = nn.Dropout(0.2)

        # è¾“å‡ºå±‚
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        """
        x: (batch_size, seq_len, input_size)
        è¿”å›: (batch_size, output_size)
        """
        # RNN forward
        # output: (batch, seq_len, hidden_size)
        # hn: (num_layers, batch, hidden_size)
        output, hn = self.rnn(x)

        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        last_output = output[:, -1, :]  # (batch, hidden_size)

        # Dropout + Linear
        out = self.dropout(last_output)
        out = self.fc(out)  # (batch, output_size)

        return out


class LSTMModel(nn.Module):
    """
    LSTM æ¨¡å‹

    ====================================================================
    ğŸ”‘ LSTM vs RNN
    ====================================================================

    ç›¸åŒç‚¹ï¼š
    - éƒ½å¤„ç†åºåˆ—æ•°æ®
    - éƒ½æœ‰éšè—çŠ¶æ€ä¼ é€’

    ä¸åŒç‚¹ï¼š
    - LSTM æœ‰ç»†èƒçŠ¶æ€ (cell state)
    - LSTM æœ‰ä¸‰ä¸ªé—¨æ§æœºåˆ¶
    - LSTM å¯ä»¥å­¦ä¹ é•¿æœŸä¾èµ–

    PyTorch è‡ªåŠ¨å¤„ç†æ‰€æœ‰é—¨æ§é€»è¾‘ï¼
    """

    def __init__(self, input_size=1, hidden_size=32, output_size=1, num_layers=1):
        super(LSTMModel, self).__init__()

        self.hidden_size = hidden_size
        self.num_layers = num_layers

        # LSTM å±‚
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True,
            dropout=0.2 if num_layers > 1 else 0
        )

        self.dropout = nn.Dropout(0.2)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        """
        x: (batch_size, seq_len, input_size)
        è¿”å›: (batch_size, output_size)
        """
        # LSTM forward
        # output: (batch, seq_len, hidden_size)
        # (hn, cn): (num_layers, batch, hidden_size)
        output, (hn, cn) = self.lstm(x)

        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥
        last_output = output[:, -1, :]

        out = self.dropout(last_output)
        out = self.fc(out)

        return out


# ==================== 3. è®­ç»ƒå’Œè¯„ä¼° ====================
def train_one_epoch(model, device, train_loader, optimizer, criterion):
    """è®­ç»ƒä¸€ä¸ª epoch"""
    model.train()

    total_loss = 0

    for batch_idx, (data, target) in enumerate(train_loader):
        data, target = data.to(device), target.to(device)

        optimizer.zero_grad()

        # å‰å‘ä¼ æ’­
        output = model(data)

        # è®¡ç®—æŸå¤±
        loss = criterion(output, target)

        # åå‘ä¼ æ’­
        loss.backward()

        # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

        # æ›´æ–°æƒé‡
        optimizer.step()

        total_loss += loss.item()

    avg_loss = total_loss / len(train_loader)
    return avg_loss


def evaluate(model, device, test_loader, criterion):
    """è¯„ä¼°æ¨¡å‹"""
    model.eval()

    test_loss = 0
    predictions = []
    targets = []

    with torch.no_grad():
        for data, target in test_loader:
            data, target = data.to(device), target.to(device)

            output = model(data)

            test_loss += criterion(output, target).item()

            predictions.append(output.cpu().numpy())
            targets.append(target.cpu().numpy())

    avg_loss = test_loss / len(test_loader)

    predictions = np.concatenate(predictions, axis=0)
    targets = np.concatenate(targets, axis=0)

    return avg_loss, predictions, targets


def train_rnn_lstm():
    """
    å®Œæ•´è®­ç»ƒæµç¨‹

    ====================================================================
    ğŸ”‘ PyTorch åºåˆ—æ¨¡å‹è®­ç»ƒæµç¨‹
    ====================================================================

    1. å‡†å¤‡æ•°æ®
       - åºåˆ—æ•°æ®ï¼š(batch, seq_len, input_size)
       - ä½¿ç”¨ DataLoader

    2. å®šä¹‰æ¨¡å‹
       - ä½¿ç”¨ nn.RNN æˆ– nn.LSTM
       - æå–æœ€åæ—¶é—´æ­¥è¾“å‡º

    3. è®­ç»ƒæŠ€å·§
       - æ¢¯åº¦è£å‰ªï¼šé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
       - Dropoutï¼šé˜²æ­¢è¿‡æ‹Ÿåˆ
       - å¤šå±‚å †å ï¼šæ›´å¼ºè¡¨è¾¾èƒ½åŠ›

    ====================================================================
    """
    print("\n" + "=" * 70)
    print("3. è®­ç»ƒ RNN/LSTM æ¨¡å‹ï¼ˆæ—¶é—´åºåˆ—é¢„æµ‹ï¼‰")
    print("=" * 70)

    # ========== 1. æ£€æŸ¥ GPU ==========
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")

    if torch.cuda.is_available():
        print(f"  GPU å‹å·: {torch.cuda.get_device_name(0)}")
        print(f"  GPU å†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
    else:
        print("  âš ï¸ æ²¡æœ‰æ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ CPU è®­ç»ƒ")

    # ========== 2. å‡†å¤‡æ•°æ® ==========
    print("\nå‡†å¤‡æ•°æ®...")

    train_dataset = SequenceDataset(n_samples=1000, seq_len=20, noise=0.1)
    test_dataset = SequenceDataset(n_samples=200, seq_len=20, noise=0.1)

    batch_size = 32
    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)

    print(f"  è®­ç»ƒé›†: {len(train_dataset)} ä¸ªåºåˆ—")
    print(f"  æµ‹è¯•é›†: {len(test_dataset)} ä¸ªåºåˆ—")
    print(f"  åºåˆ—é•¿åº¦: {train_dataset.X.shape[1]}")
    print(f"  Batch size: {batch_size}")

    # ========== 3. åˆ›å»ºæ¨¡å‹ ==========
    print("\nåˆ›å»ºæ¨¡å‹...")

    # RNN æ¨¡å‹
    rnn_model = RNNModel(input_size=1, hidden_size=32, output_size=1, num_layers=2)
    rnn_model = rnn_model.to(device)

    # LSTM æ¨¡å‹
    lstm_model = LSTMModel(input_size=1, hidden_size=32, output_size=1, num_layers=2)
    lstm_model = lstm_model.to(device)

    print(f"\nRNN æ¨¡å‹:")
    print(rnn_model)
    rnn_params = sum(p.numel() for p in rnn_model.parameters())
    print(f"  å‚æ•°é‡: {rnn_params:,}")

    print(f"\nLSTM æ¨¡å‹:")
    print(lstm_model)
    lstm_params = sum(p.numel() for p in lstm_model.parameters())
    print(f"  å‚æ•°é‡: {lstm_params:,}")

    print(f"\nğŸ’¡ LSTM å‚æ•°é‡çº¦ä¸º RNN çš„ 4 å€ï¼ˆå› ä¸ºæœ‰ 3 ä¸ªé—¨ï¼‰")

    # ========== 4. å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨ ==========
    criterion = nn.MSELoss()

    rnn_optimizer = optim.Adam(rnn_model.parameters(), lr=0.001)
    lstm_optimizer = optim.Adam(lstm_model.parameters(), lr=0.001)

    # ========== 5. è®­ç»ƒ ==========
    print("\nå¼€å§‹è®­ç»ƒ...")
    n_epochs = 50

    rnn_train_losses = []
    rnn_test_losses = []
    lstm_train_losses = []
    lstm_test_losses = []

    # è®­ç»ƒ RNN
    print(f"\n{'='*70}")
    print("è®­ç»ƒ RNN æ¨¡å‹...")
    print(f"{'='*70}")

    rnn_start_time = time.time()

    for epoch in range(1, n_epochs + 1):
        train_loss = train_one_epoch(rnn_model, device, train_loader,
                                     rnn_optimizer, criterion)
        test_loss, _, _ = evaluate(rnn_model, device, test_loader, criterion)

        rnn_train_losses.append(train_loss)
        rnn_test_losses.append(test_loss)

        if epoch % 10 == 0:
            print(f"Epoch {epoch:2d}/{n_epochs} | "
                  f"Train Loss: {train_loss:.6f} | Test Loss: {test_loss:.6f}")

    rnn_time = time.time() - rnn_start_time
    print(f"\nRNN è®­ç»ƒå®Œæˆï¼è€—æ—¶: {rnn_time:.2f} ç§’")

    # è®­ç»ƒ LSTM
    print(f"\n{'='*70}")
    print("è®­ç»ƒ LSTM æ¨¡å‹...")
    print(f"{'='*70}")

    lstm_start_time = time.time()

    for epoch in range(1, n_epochs + 1):
        train_loss = train_one_epoch(lstm_model, device, train_loader,
                                     lstm_optimizer, criterion)
        test_loss, _, _ = evaluate(lstm_model, device, test_loader, criterion)

        lstm_train_losses.append(train_loss)
        lstm_test_losses.append(test_loss)

        if epoch % 10 == 0:
            print(f"Epoch {epoch:2d}/{n_epochs} | "
                  f"Train Loss: {train_loss:.6f} | Test Loss: {test_loss:.6f}")

    lstm_time = time.time() - lstm_start_time
    print(f"\nLSTM è®­ç»ƒå®Œæˆï¼è€—æ—¶: {lstm_time:.2f} ç§’")

    # ========== 6. æœ€ç»ˆè¯„ä¼° ==========
    _, rnn_preds, rnn_targets = evaluate(rnn_model, device, test_loader, criterion)
    _, lstm_preds, lstm_targets = evaluate(lstm_model, device, test_loader, criterion)

    print(f"\n{'='*70}")
    print("æœ€ç»ˆç»“æœå¯¹æ¯”")
    print(f"{'='*70}")
    print(f"RNN  - Test Loss: {rnn_test_losses[-1]:.6f} | è®­ç»ƒæ—¶é—´: {rnn_time:.2f}s")
    print(f"LSTM - Test Loss: {lstm_test_losses[-1]:.6f} | è®­ç»ƒæ—¶é—´: {lstm_time:.2f}s")

    # ========== 7. å¯è§†åŒ– ==========
    visualize_training(n_epochs, rnn_train_losses, rnn_test_losses,
                      lstm_train_losses, lstm_test_losses,
                      rnn_preds, lstm_preds, rnn_targets, test_dataset)

    return rnn_model, lstm_model


def visualize_training(n_epochs, rnn_train_losses, rnn_test_losses,
                      lstm_train_losses, lstm_test_losses,
                      rnn_preds, lstm_preds, targets, test_dataset):
    """å¯è§†åŒ–è®­ç»ƒç»“æœ"""
    print("\nå¯è§†åŒ–è®­ç»ƒç»“æœ...")

    fig = plt.figure(figsize=(16, 10))

    # 1. è®­ç»ƒæŸå¤±æ›²çº¿
    ax1 = plt.subplot(2, 3, 1)
    epochs_range = range(1, n_epochs + 1)
    ax1.plot(epochs_range, rnn_train_losses, 'b-', label='RNN Train', linewidth=2)
    ax1.plot(epochs_range, rnn_test_losses, 'b--', label='RNN Test', linewidth=2)
    ax1.plot(epochs_range, lstm_train_losses, 'r-', label='LSTM Train', linewidth=2)
    ax1.plot(epochs_range, lstm_test_losses, 'r--', label='LSTM Test', linewidth=2)
    ax1.set_xlabel('Epoch', fontsize=11)
    ax1.set_ylabel('Loss (MSE)', fontsize=11)
    ax1.set_title('Training Loss: RNN vs LSTM', fontsize=12, fontweight='bold')
    ax1.legend(fontsize=9)
    ax1.grid(alpha=0.3)

    # 2. æµ‹è¯•æŸå¤±å¯¹æ¯”
    ax2 = plt.subplot(2, 3, 2)
    models = ['RNN', 'LSTM']
    final_losses = [rnn_test_losses[-1], lstm_test_losses[-1]]
    colors = ['#3498db', '#e74c3c']
    bars = ax2.bar(models, final_losses, color=colors, alpha=0.7, edgecolor='black')
    ax2.set_ylabel('Test Loss (MSE)', fontsize=11)
    ax2.set_title('Final Test Loss Comparison', fontsize=12, fontweight='bold')
    ax2.grid(axis='y', alpha=0.3)

    for bar, loss in zip(bars, final_losses):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height,
                f'{loss:.6f}', ha='center', va='bottom', fontsize=10)

    # 3. RNN é¢„æµ‹ vs çœŸå®å€¼ï¼ˆæ•£ç‚¹å›¾ï¼‰
    ax3 = plt.subplot(2, 3, 3)
    ax3.scatter(targets, rnn_preds, alpha=0.5, s=20)
    ax3.plot([targets.min(), targets.max()], [targets.min(), targets.max()],
            'r--', lw=2, label='Perfect Prediction')
    ax3.set_xlabel('True Values', fontsize=11)
    ax3.set_ylabel('RNN Predictions', fontsize=11)
    ax3.set_title('RNN: Predictions vs Truth', fontsize=12, fontweight='bold')
    ax3.legend(fontsize=9)
    ax3.grid(alpha=0.3)

    # 4. LSTM é¢„æµ‹ vs çœŸå®å€¼ï¼ˆæ•£ç‚¹å›¾ï¼‰
    ax4 = plt.subplot(2, 3, 4)
    ax4.scatter(targets, lstm_preds, alpha=0.5, s=20, color='red')
    ax4.plot([targets.min(), targets.max()], [targets.min(), targets.max()],
            'b--', lw=2, label='Perfect Prediction')
    ax4.set_xlabel('True Values', fontsize=11)
    ax4.set_ylabel('LSTM Predictions', fontsize=11)
    ax4.set_title('LSTM: Predictions vs Truth', fontsize=12, fontweight='bold')
    ax4.legend(fontsize=9)
    ax4.grid(alpha=0.3)

    # 5. ç¤ºä¾‹åºåˆ—é¢„æµ‹ï¼ˆRNNï¼‰
    ax5 = plt.subplot(2, 3, 5)
    n_show = 5
    for i in range(n_show):
        seq = test_dataset.X[i, :, 0].numpy()
        ax5.plot(seq, alpha=0.6, linewidth=2)
        # çœŸå®å€¼ï¼ˆçº¢è‰²æ˜Ÿæ˜Ÿï¼‰
        ax5.scatter(len(seq), targets[i], color='red', s=150, marker='*',
                   zorder=5, edgecolors='black', linewidths=1)
        # RNNé¢„æµ‹ï¼ˆè“è‰²åœ†åœˆï¼‰
        ax5.scatter(len(seq), rnn_preds[i], color='blue', s=80, marker='o',
                   zorder=5, edgecolors='black', linewidths=1)

    ax5.set_xlabel('Time Step', fontsize=11)
    ax5.set_ylabel('Value', fontsize=11)
    ax5.set_title('RNN Predictions (Red=True, Blue=Pred)', fontsize=12, fontweight='bold')
    ax5.grid(alpha=0.3)

    # 6. ç¤ºä¾‹åºåˆ—é¢„æµ‹ï¼ˆLSTMï¼‰
    ax6 = plt.subplot(2, 3, 6)
    for i in range(n_show):
        seq = test_dataset.X[i, :, 0].numpy()
        ax6.plot(seq, alpha=0.6, linewidth=2)
        # çœŸå®å€¼ï¼ˆçº¢è‰²æ˜Ÿæ˜Ÿï¼‰
        ax6.scatter(len(seq), targets[i], color='red', s=150, marker='*',
                   zorder=5, edgecolors='black', linewidths=1)
        # LSTMé¢„æµ‹ï¼ˆç»¿è‰²åœ†åœˆï¼‰
        ax6.scatter(len(seq), lstm_preds[i], color='green', s=80, marker='o',
                   zorder=5, edgecolors='black', linewidths=1)

    ax6.set_xlabel('Time Step', fontsize=11)
    ax6.set_ylabel('Value', fontsize=11)
    ax6.set_title('LSTM Predictions (Red=True, Green=Pred)', fontsize=12, fontweight='bold')
    ax6.grid(alpha=0.3)

    plt.tight_layout()
    plt.savefig('rnn_lstm_pytorch_training.png', dpi=100, bbox_inches='tight')
    print("ğŸ“Š è®­ç»ƒç»“æœå·²ä¿å­˜: rnn_lstm_pytorch_training.png")
    plt.close()


# ==================== 4. PyTorch vs NumPy å¯¹æ¯” ====================
def compare_pytorch_vs_numpy():
    """
    å¯¹æ¯” PyTorch å’Œ NumPy ç‰ˆæœ¬

    ====================================================================
    ğŸ”‘ PyTorch vs NumPy
    ====================================================================

    NumPy ç‰ˆæœ¬ï¼š
    âœ… ä¼˜ç‚¹ï¼š
      - ç†è§£RNN/LSTMå†…éƒ¨æœºåˆ¶
      - æ‰‹å†™é—¨æ§é€»è¾‘ï¼ŒæŒæ¡ç»†èŠ‚
      - ä¸ä¾èµ–æ·±åº¦å­¦ä¹ æ¡†æ¶

    âŒ ç¼ºç‚¹ï¼š
      - ä»£ç é‡å¤§ï¼ˆéœ€è¦æ‰‹å†™BPTTï¼‰
      - é€Ÿåº¦æ…¢ï¼ˆæ— GPUåŠ é€Ÿï¼‰
      - éš¾ä»¥å¤„ç†å¤æ‚åºåˆ—ï¼ˆå˜é•¿ã€paddingï¼‰
      - æ•°å€¼ä¸ç¨³å®š

    PyTorch ç‰ˆæœ¬ï¼š
    âœ… ä¼˜ç‚¹ï¼š
      - ä»£ç ç®€æ´ï¼ˆå‡ è¡Œæå®šï¼‰
      - GPU åŠ é€Ÿï¼ˆå¿«10-100å€ï¼‰
      - è‡ªåŠ¨å¾®åˆ†ï¼ˆä¸éœ€è¦æ‰‹å†™BPTTï¼‰
      - å†…ç½®ä¼˜åŒ–ï¼ˆCuDNNåŠ é€Ÿï¼‰
      - å·¥ä¸šç•Œæ ‡å‡†

    âŒ ç¼ºç‚¹ï¼š
      - æ¡†æ¶é»‘ç›’ï¼ˆä¸çŸ¥é“å†…éƒ¨ç»†èŠ‚ï¼‰
      - éœ€è¦å­¦ä¹ æ–°API

    å»ºè®®ï¼š
    - å­¦ä¹ é˜¶æ®µï¼šå…ˆçœ‹ NumPy ç‰ˆæœ¬ï¼ˆç†è§£åŸç†ï¼‰
    - å®è·µé˜¶æ®µï¼šç”¨ PyTorch ç‰ˆæœ¬ï¼ˆå®é™…åº”ç”¨ï¼‰

    ====================================================================
    """
    print("\n" + "=" * 70)
    print("4. PyTorch vs NumPy å¯¹æ¯”")
    print("=" * 70)

    print("""
æ€§èƒ½å¯¹æ¯”ï¼ˆæ—¶é—´åºåˆ—é¢„æµ‹ï¼‰ï¼š

+----------------+------------------+------------------+
|     æŒ‡æ ‡       |   NumPy ç‰ˆæœ¬     |  PyTorch ç‰ˆæœ¬    |
+----------------+------------------+------------------+
| ä»£ç é‡         | ~400 è¡Œ          | ~150 è¡Œ          |
| è®­ç»ƒæ—¶é—´       | ~2 åˆ†é’Ÿ (CPU)    | ~10 ç§’ (GPU)     |
| æµ‹è¯•å‡†ç¡®ç‡     | å¥½               | æ›´å¥½             |
| GPU æ”¯æŒ       | âŒ               | âœ…               |
| è‡ªåŠ¨å¾®åˆ†       | âŒ (æ‰‹å†™BPTT)    | âœ…               |
| å˜é•¿åºåˆ—       | å›°éš¾             | âœ… (pack/pad)    |
| å·¥ä¸šåº”ç”¨       | âŒ               | âœ…               |
+----------------+------------------+------------------+

ä»£ç å¯¹æ¯”ï¼š

NumPy ç‰ˆæœ¬ï¼ˆå¤æ‚ï¼‰ï¼š
```python
# æ‰‹å†™LSTMå‰å‘ä¼ æ’­
def forward(self, X):
    for t in range(seq_len):
        combined = np.concatenate([x_t, h], axis=1)

        # æ‰‹åŠ¨è®¡ç®—æ¯ä¸ªé—¨
        f_t = self.sigmoid(np.dot(combined, self.W_f) + self.b_f)
        i_t = self.sigmoid(np.dot(combined, self.W_i) + self.b_i)
        o_t = self.sigmoid(np.dot(combined, self.W_o) + self.b_o)
        c_tilde = np.tanh(np.dot(combined, self.W_c) + self.b_c)

        # æ‰‹åŠ¨æ›´æ–°çŠ¶æ€
        c = f_t * c + i_t * c_tilde
        h = o_t * np.tanh(c)
        # ...

# æ‰‹å†™BPTTåå‘ä¼ æ’­ï¼ˆæ›´å¤æ‚ï¼ï¼‰
# ... 100+ è¡Œæ¢¯åº¦è®¡ç®—ä»£ç 
```

PyTorch ç‰ˆæœ¬ï¼ˆç®€æ´ï¼‰ï¼š
```python
# å®šä¹‰æ¨¡å‹
class LSTMModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.lstm = nn.LSTM(input_size=1, hidden_size=32)
        self.fc = nn.Linear(32, 1)

    def forward(self, x):
        output, (hn, cn) = self.lstm(x)
        return self.fc(output[:, -1, :])

# è®­ç»ƒï¼ˆè‡ªåŠ¨BPTTï¼ï¼‰
output = model(data)
loss = criterion(output, target)
loss.backward()          # â† è‡ªåŠ¨BPTTï¼
optimizer.step()         # â† è‡ªåŠ¨æ›´æ–°ï¼
```

æ€»ç»“ï¼š
- å­¦ä¹ åŸç† â†’ ç”¨ NumPyï¼ˆç†è§£é—¨æ§æœºåˆ¶ï¼‰
- å®é™…åº”ç”¨ â†’ ç”¨ PyTorchï¼ˆå·¥ä¸šæ ‡å‡†ï¼‰
- ä¸¤è€…ç»“åˆ â†’ æœ€ä½³ç†è§£ï¼
    """)


# ==================== 5. ä¸»ç¨‹åº ====================
def main():
    print("=" * 70)
    print("å¾ªç¯ç¥ç»ç½‘ç»œ (RNN/LSTM) - PyTorch å®ç°")
    print("=" * 70)

    # 1. PyTorch åŸºç¡€ç»„ä»¶
    demo_pytorch_rnn()
    demo_pytorch_lstm()

    # 2. è®­ç»ƒå®Œæ•´æ¨¡å‹
    rnn_model, lstm_model = train_rnn_lstm()

    # 3. å¯¹æ¯” PyTorch vs NumPy
    compare_pytorch_vs_numpy()

    # 4. æ€»ç»“
    print("\n" + "=" * 70)
    print("âœ… æ ¸å¿ƒè¦ç‚¹æ€»ç»“")
    print("=" * 70)
    print("""
1. PyTorch RNN/LSTM åŸºç¡€ç»„ä»¶

   RNNå±‚ï¼š
   nn.RNN(input_size, hidden_size, num_layers, batch_first=True)

   LSTMå±‚ï¼š
   nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)

   GRUå±‚ï¼š
   nn.GRU(input_size, hidden_size, num_layers, batch_first=True)

2. å®šä¹‰åºåˆ—æ¨¡å‹ï¼ˆç»§æ‰¿ nn.Moduleï¼‰

   class MyRNN(nn.Module):
       def __init__(self):
           super().__init__()
           self.rnn = nn.RNN(input_size=1, hidden_size=32)
           self.fc = nn.Linear(32, 1)

       def forward(self, x):
           output, hn = self.rnn(x)
           # å–æœ€åæ—¶é—´æ­¥
           last_output = output[:, -1, :]
           return self.fc(last_output)

3. åºåˆ—æ•°æ®æ ¼å¼

   batch_first=True:  (batch_size, seq_len, input_size)
   batch_first=False: (seq_len, batch_size, input_size)

   æ¨èä½¿ç”¨ batch_first=Trueï¼ˆæ›´ç›´è§‚ï¼‰

4. è®­ç»ƒæŠ€å·§

   # æ¢¯åº¦è£å‰ªï¼ˆé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸ï¼‰
   torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)

   # Dropoutï¼ˆé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
   nn.LSTM(..., dropout=0.2)  # ä»…ç”¨äºå¤šå±‚
   nn.Dropout(0.2)  # åœ¨LSTMåæ·»åŠ 

   # å¤šå±‚å †å 
   nn.LSTM(..., num_layers=2)

5. GPU åŠ é€Ÿ

   device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
   model = model.to(device)
   data = data.to(device)

   é€Ÿåº¦æå‡ï¼šCPU 2åˆ†é’Ÿ â†’ GPU 10ç§’ï¼ˆ10-20å€ï¼‰

6. RNN vs LSTM

   RNN:
   - ç®€å•ï¼Œå‚æ•°å°‘
   - å¿«é€Ÿè®­ç»ƒ
   - çŸ­åºåˆ—è¡¨ç°å¥½
   - é•¿åºåˆ—æœ‰æ¢¯åº¦æ¶ˆå¤±é—®é¢˜

   LSTM:
   - å¤æ‚ï¼Œå‚æ•°å¤šï¼ˆ4å€ï¼‰
   - è®­ç»ƒè¾ƒæ…¢
   - é•¿åºåˆ—è¡¨ç°å¥½
   - æœ‰ç»†èƒçŠ¶æ€å’Œé—¨æ§æœºåˆ¶

7. PyTorch vs NumPy

   NumPy:
   - ç†è§£åŸç†ï¼ˆæ‰‹å†™é—¨æ§ï¼‰
   - ä»£ç é‡å¤§
   - é€Ÿåº¦æ…¢

   PyTorch:
   - å·¥ä¸šå®è·µï¼ˆè‡ªåŠ¨å¾®åˆ†ï¼‰
   - ä»£ç ç®€æ´
   - é€Ÿåº¦å¿«10-100å€

8. å®è·µå»ºè®®

   å­¦ä¹ è·¯å¾„ï¼š
   1. å…ˆçœ‹ NumPy ç‰ˆæœ¬ï¼ˆç†è§£LSTMé—¨æ§æœºåˆ¶ï¼‰
   2. å†çœ‹ PyTorch ç‰ˆæœ¬ï¼ˆå­¦ä¹ æ¡†æ¶ï¼‰
   3. å¯¹æ¯”ä¸¤ä¸ªç‰ˆæœ¬ï¼ˆç†è§£æ¡†æ¶åšäº†ä»€ä¹ˆï¼‰

   å®é™…å·¥ä½œï¼š
   - 100% ç”¨ PyTorchï¼ˆæˆ– TensorFlowï¼‰
   - NumPy åªç”¨äºç†è§£åŸç†

9. åºåˆ—å»ºæ¨¡åº”ç”¨

   - æ—¶é—´åºåˆ—é¢„æµ‹ï¼šè‚¡ä»·ã€å¤©æ°”
   - è‡ªç„¶è¯­è¨€å¤„ç†ï¼šæ–‡æœ¬ç”Ÿæˆã€ç¿»è¯‘
   - æ¨èç³»ç»Ÿï¼šç”¨æˆ·è¡Œä¸ºåºåˆ—å»ºæ¨¡
   - è¯­éŸ³è¯†åˆ«ï¼šéŸ³é¢‘åºåˆ—
   - è§†é¢‘åˆ†æï¼šå¸§åºåˆ—

10. ä¸‹ä¸€æ­¥å­¦ä¹ 

    - Attentionæœºåˆ¶ï¼ˆè§£å†³é•¿åºåˆ—é—®é¢˜ï¼‰
    - Transformerï¼ˆå–ä»£RNNçš„ç°ä»£æ¶æ„ï¼‰
    - GRUï¼ˆLSTMçš„ç®€åŒ–ç‰ˆæœ¬ï¼‰
    - Bidirectional RNNï¼ˆåŒå‘å¤„ç†ï¼‰
    - Seq2Seqï¼ˆç¼–ç å™¨-è§£ç å™¨ï¼‰
    """)


if __name__ == "__main__":
    main()

    print("\nğŸ’¡ ç»ƒä¹ å»ºè®®:")
    print("  1. å°è¯•ä¸åŒçš„ hidden_size å’Œ num_layers")
    print("  2. åœ¨çœŸå®æ—¶é—´åºåˆ—æ•°æ®ä¸Šè®­ç»ƒï¼ˆè‚¡ä»·ã€å¤©æ°”ï¼‰")
    print("  3. å®ç°åŒå‘ LSTMï¼ˆbidirectional=Trueï¼‰")
    print("  4. æ¯”è¾ƒ RNNã€LSTMã€GRU çš„æ€§èƒ½")
    print("  5. ç†è§£ä¸ºä»€ä¹ˆLSTMèƒ½å¤„ç†é•¿åºåˆ—")
    print("  6. æ€è€ƒï¼šå¦‚ä½•ç”¨RNNå»ºæ¨¡ç”¨æˆ·è¡Œä¸ºåºåˆ—ï¼Ÿ")
