# TensorFlow æ ¸å¿ƒæ¦‚å¿µ

> ç†è§£ TensorFlow çš„åŸºç¡€ï¼šå¼ é‡ã€è®¡ç®—å›¾ã€è‡ªåŠ¨å¾®åˆ†

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µæ€»è§ˆ

TensorFlow çš„åå­—æ¥æºäº **Tensorï¼ˆå¼ é‡ï¼‰** + **Flowï¼ˆæµåŠ¨ï¼‰**ï¼Œæè¿°äº†æ•°æ®ï¼ˆå¼ é‡ï¼‰åœ¨è®¡ç®—å›¾ä¸­æµåŠ¨çš„è¿‡ç¨‹ã€‚

```
è¾“å…¥æ•°æ®ï¼ˆå¼ é‡ï¼‰ â†’ è®¡ç®—å›¾ï¼ˆæ“ä½œåºåˆ—ï¼‰ â†’ è¾“å‡ºç»“æœï¼ˆå¼ é‡ï¼‰
                        â†‘
                   è‡ªåŠ¨å¾®åˆ†ï¼ˆåå‘ä¼ æ’­ï¼‰
```

## 1. å¼ é‡ï¼ˆTensorï¼‰

### ä»€ä¹ˆæ˜¯å¼ é‡ï¼Ÿ

å¼ é‡æ˜¯ TensorFlow ä¸­çš„åŸºæœ¬æ•°æ®ç»“æ„ï¼Œå¯ä»¥ç†è§£ä¸º**å¤šç»´æ•°ç»„**ï¼š

```python
import tensorflow as tf

# 0ç»´å¼ é‡ï¼šæ ‡é‡
scalar = tf.constant(42)          # shape: ()

# 1ç»´å¼ é‡ï¼šå‘é‡
vector = tf.constant([1, 2, 3])   # shape: (3,)

# 2ç»´å¼ é‡ï¼šçŸ©é˜µ
matrix = tf.constant([[1, 2],
                      [3, 4]])     # shape: (2, 2)

# 3ç»´å¼ é‡ï¼šå¦‚RGBå›¾åƒ
image = tf.zeros([256, 256, 3])   # shape: (256, 256, 3)

# 4ç»´å¼ é‡ï¼šä¸€æ‰¹å›¾åƒ
batch = tf.zeros([32, 256, 256, 3])  # shape: (batch, height, width, channels)
```

### å¼ é‡çš„ç»´åº¦ç±»æ¯”

| ç»´åº¦ | æ•°å­¦åç§° | ä¾‹å­ | å½¢çŠ¶ |
|------|---------|------|------|
| 0D | æ ‡é‡ï¼ˆScalarï¼‰ | æ¸©åº¦: 36.5Â°C | `()` |
| 1D | å‘é‡ï¼ˆVectorï¼‰ | æ—¶é—´åºåˆ—: [1, 2, 3, 4] | `(4,)` |
| 2D | çŸ©é˜µï¼ˆMatrixï¼‰ | ç°åº¦å›¾åƒ: 28Ã—28 | `(28, 28)` |
| 3D | 3é˜¶å¼ é‡ | RGBå›¾åƒ: 256Ã—256Ã—3 | `(256, 256, 3)` |
| 4D | 4é˜¶å¼ é‡ | å›¾åƒæ‰¹æ¬¡: 32Ã—256Ã—256Ã—3 | `(32, 256, 256, 3)` |

### å¼ é‡çš„å±æ€§

```python
tensor = tf.constant([[1, 2, 3], [4, 5, 6]])

print(tensor.shape)     # TensorShape([2, 3]) - å½¢çŠ¶
print(tensor.dtype)     # tf.int32 - æ•°æ®ç±»å‹
print(tensor.numpy())   # è½¬æ¢ä¸º NumPy æ•°ç»„
```

### å¼ é‡æ“ä½œ

```python
a = tf.constant([1, 2, 3])
b = tf.constant([4, 5, 6])

# åŸºæœ¬è¿ç®—
c = a + b               # [5, 7, 9] - é€å…ƒç´ ç›¸åŠ 
d = a * b               # [4, 10, 18] - é€å…ƒç´ ç›¸ä¹˜
e = tf.matmul(a, b)     # çŸ©é˜µä¹˜æ³•ï¼ˆéœ€è¦å½¢çŠ¶åŒ¹é…ï¼‰

# å½¢çŠ¶æ“ä½œ
x = tf.constant([[1, 2], [3, 4]])
y = tf.reshape(x, [4])              # [1, 2, 3, 4] - é‡å¡‘
z = tf.transpose(x)                 # [[1, 3], [2, 4]] - è½¬ç½®

# èšåˆæ“ä½œ
mean = tf.reduce_mean(a)            # 2.0 - å¹³å‡å€¼
sum_val = tf.reduce_sum(a)          # 6 - æ±‚å’Œ
max_val = tf.reduce_max(a)          # 3 - æœ€å¤§å€¼
```

## 2. è®¡ç®—å›¾ï¼ˆComputation Graphï¼‰

### é™æ€å›¾ vs åŠ¨æ€å›¾

TensorFlow æœ‰ä¸¤ç§æ‰§è¡Œæ¨¡å¼ï¼š

#### TensorFlow 1.xï¼šé™æ€å›¾ï¼ˆGraph Modeï¼‰

```python
# æ—§ç‰ˆæœ¬ï¼šå…ˆå®šä¹‰å›¾ï¼Œå†è¿è¡Œ
import tensorflow.compat.v1 as tf
tf.disable_v2_behavior()

# ç¬¬ä¸€æ­¥ï¼šå®šä¹‰è®¡ç®—å›¾
a = tf.placeholder(tf.float32)
b = tf.placeholder(tf.float32)
c = a + b

# ç¬¬äºŒæ­¥ï¼šåˆ›å»ºä¼šè¯å¹¶æ‰§è¡Œ
with tf.Session() as sess:
    result = sess.run(c, feed_dict={a: 3.0, b: 4.0})
    print(result)  # 7.0
```

**ç‰¹ç‚¹**ï¼š
- âœ… æ€§èƒ½ä¼˜åŒ–å¥½ï¼ˆç¼–è¯‘æ—¶ä¼˜åŒ–ï¼‰
- âœ… é€‚åˆç”Ÿäº§éƒ¨ç½²
- âŒ è°ƒè¯•å›°éš¾
- âŒ ä»£ç ä¸ç›´è§‚

#### TensorFlow 2.xï¼šåŠ¨æ€å›¾ï¼ˆEager Executionï¼‰

```python
# æ–°ç‰ˆæœ¬ï¼šé»˜è®¤å¯ç”¨ Eager Executionï¼ˆå³æ—¶æ‰§è¡Œï¼‰
import tensorflow as tf

a = tf.constant(3.0)
b = tf.constant(4.0)
c = a + b
print(c.numpy())  # 7.0 - ç«‹å³å¾—åˆ°ç»“æœ
```

**ç‰¹ç‚¹**ï¼š
- âœ… ä»£ç ç®€æ´ï¼Œç±»ä¼¼ NumPy
- âœ… è°ƒè¯•æ–¹ä¾¿ï¼ˆå¯ä»¥ç”¨ printã€æ–­ç‚¹ï¼‰
- âœ… æ›´ Pythonic
- âš ï¸ æ€§èƒ½ç•¥ä½äºé™æ€å›¾

### å…¼é¡¾æ€§èƒ½ï¼š@tf.function

ä½¿ç”¨ `@tf.function` å°† Python å‡½æ•°ç¼–è¯‘ä¸ºé™æ€å›¾ï¼Œå…¼é¡¾æ˜“ç”¨æ€§å’Œæ€§èƒ½ï¼š

```python
import tensorflow as tf
import time

# æ™®é€š Python å‡½æ•°ï¼ˆæ…¢ï¼‰
def slow_function(x, y):
    return x ** 2 + y ** 2

# ä½¿ç”¨ @tf.function è£…é¥°ï¼ˆå¿«ï¼‰
@tf.function
def fast_function(x, y):
    return x ** 2 + y ** 2

x = tf.constant(3.0)
y = tf.constant(4.0)

# æ€§èƒ½å¯¹æ¯”
start = time.time()
for _ in range(10000):
    slow_function(x, y)
print(f"æ™®é€šå‡½æ•°è€—æ—¶: {time.time() - start:.4f}s")

start = time.time()
for _ in range(10000):
    fast_function(x, y)
print(f"@tf.function è€—æ—¶: {time.time() - start:.4f}s")
```

**æœ€ä½³å®è·µ**ï¼š
- å¼€å‘è°ƒè¯•æ—¶ï¼šä½¿ç”¨ Eager Execution
- è®­ç»ƒæ¨¡å‹æ—¶ï¼šä½¿ç”¨ `@tf.function` åŠ é€Ÿ
- ç”Ÿäº§éƒ¨ç½²æ—¶ï¼šä½¿ç”¨ SavedModel æ ¼å¼ï¼ˆè‡ªåŠ¨é™æ€å›¾ï¼‰

## 3. è‡ªåŠ¨å¾®åˆ†ï¼ˆAutomatic Differentiationï¼‰

### ä¸ºä»€ä¹ˆéœ€è¦è‡ªåŠ¨å¾®åˆ†ï¼Ÿ

æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒæ˜¯**æ¢¯åº¦ä¸‹é™**ï¼Œéœ€è¦è®¡ç®—æŸå¤±å‡½æ•°å¯¹å‚æ•°çš„æ¢¯åº¦ï¼š

```
Î¸_new = Î¸_old - learning_rate * âˆ‡L(Î¸)
                                  â†‘
                           éœ€è¦è‡ªåŠ¨è®¡ç®—è¿™ä¸ªæ¢¯åº¦
```

### tf.GradientTapeï¼šè‡ªåŠ¨å¾®åˆ†çš„æ ¸å¿ƒ

`tf.GradientTape` æ˜¯ TensorFlow çš„"å½•éŸ³æœº"ï¼Œè®°å½•è®¡ç®—è¿‡ç¨‹ï¼Œç„¶åè‡ªåŠ¨è®¡ç®—æ¢¯åº¦ã€‚

#### åŸºæœ¬ç”¨æ³•

```python
import tensorflow as tf

# å®šä¹‰å˜é‡
x = tf.Variable(3.0)

# ä½¿ç”¨ GradientTape è®°å½•è®¡ç®—è¿‡ç¨‹
with tf.GradientTape() as tape:
    y = x ** 2  # y = xÂ²

# è®¡ç®—æ¢¯åº¦ dy/dx = 2x
dy_dx = tape.gradient(y, x)
print(dy_dx.numpy())  # 6.0 (å› ä¸º 2 * 3 = 6)
```

#### å¤šå˜é‡æ¢¯åº¦

```python
# çº¿æ€§å›å½’ä¾‹å­: y = wx + b
w = tf.Variable(2.0)
b = tf.Variable(1.0)
x = tf.constant(3.0)

with tf.GradientTape() as tape:
    y = w * x + b  # y = 2*3 + 1 = 7
    loss = y ** 2   # loss = 49

# è®¡ç®—æ¢¯åº¦
gradients = tape.gradient(loss, [w, b])
dL_dw, dL_db = gradients

print(f"âˆ‚Loss/âˆ‚w = {dL_dw.numpy()}")  # 42.0
print(f"âˆ‚Loss/âˆ‚b = {dL_db.numpy()}")  # 14.0
```

#### æŒä¹…æ€§ GradientTape

é»˜è®¤æƒ…å†µä¸‹ï¼Œ`GradientTape` åªèƒ½è°ƒç”¨ä¸€æ¬¡ `.gradient()`ã€‚å¦‚éœ€å¤šæ¬¡è®¡ç®—ï¼Œä½¿ç”¨ `persistent=True`ï¼š

```python
x = tf.Variable(3.0)

with tf.GradientTape(persistent=True) as tape:
    y = x ** 2
    z = y ** 2

# å¤šæ¬¡è®¡ç®—æ¢¯åº¦
dy_dx = tape.gradient(y, x)  # dy/dx = 2x = 6
dz_dx = tape.gradient(z, x)  # dz/dx = 4xÂ³ = 108

print(dy_dx.numpy())  # 6.0
print(dz_dx.numpy())  # 108.0

del tape  # æ‰‹åŠ¨åˆ é™¤ä»¥é‡Šæ”¾èµ„æº
```

#### ç›‘è§†å¸¸é‡ï¼ˆwatchï¼‰

`GradientTape` é»˜è®¤åªç›‘è§† `tf.Variable`ã€‚è¦ç›‘è§†å¸¸é‡ï¼Œéœ€è¦æ˜¾å¼è°ƒç”¨ `tape.watch()`ï¼š

```python
x = tf.constant(3.0)  # å¸¸é‡ï¼Œé»˜è®¤ä¸ç›‘è§†

with tf.GradientTape() as tape:
    tape.watch(x)  # æ˜¾å¼ç›‘è§†
    y = x ** 2

dy_dx = tape.gradient(y, x)
print(dy_dx.numpy())  # 6.0
```

### å®æˆ˜ï¼šæ‰‹å†™æ¢¯åº¦ä¸‹é™

```python
import tensorflow as tf

# ç›®æ ‡ï¼šæ‰¾åˆ° y = xÂ² çš„æœ€å°å€¼ç‚¹ï¼ˆç­”æ¡ˆï¼šx = 0ï¼‰

x = tf.Variable(10.0)  # åˆå§‹å€¼
learning_rate = 0.1

for step in range(50):
    with tf.GradientTape() as tape:
        y = x ** 2  # ç›®æ ‡å‡½æ•°

    # è®¡ç®—æ¢¯åº¦
    dy_dx = tape.gradient(y, x)

    # æ¢¯åº¦ä¸‹é™æ›´æ–°
    x.assign(x - learning_rate * dy_dx)

    if step % 10 == 0:
        print(f"Step {step}: x = {x.numpy():.4f}, y = {y.numpy():.4f}")

# è¾“å‡ºï¼š
# Step 0: x = 8.0000, y = 100.0000
# Step 10: x = 2.6843, y = 7.2056
# Step 20: x = 0.9005, y = 0.8109
# Step 30: x = 0.3021, y = 0.0913
# Step 40: x = 0.1013, y = 0.0103
```

## 4. å˜é‡ï¼ˆVariableï¼‰

### Variable vs Tensor

| ç‰¹æ€§ | tf.Tensor | tf.Variable |
|------|----------|-------------|
| å¯å˜æ€§ | ä¸å¯å˜ | å¯å˜ |
| æ¢¯åº¦è¿½è¸ª | éœ€è¦ watch() | è‡ªåŠ¨è¿½è¸ª |
| ç”¨é€” | æ•°æ®ã€ä¸­é—´ç»“æœ | æ¨¡å‹å‚æ•°ï¼ˆæƒé‡ã€åç½®ï¼‰ |

```python
# Tensorï¼šä¸å¯å˜
t = tf.constant([1, 2, 3])
# t[0] = 10  # é”™è¯¯ï¼ä¸èƒ½ä¿®æ”¹

# Variableï¼šå¯å˜
v = tf.Variable([1, 2, 3])
v[0].assign(10)  # æ­£ç¡®ï¼
print(v.numpy())  # [10, 2, 3]
```

### Variable çš„æ“ä½œ

```python
w = tf.Variable([[1.0, 2.0], [3.0, 4.0]])

# èµ‹å€¼æ“ä½œ
w.assign([[0.0, 0.0], [0.0, 0.0]])       # å®Œå…¨æ›¿æ¢
w.assign_add([[1.0, 1.0], [1.0, 1.0]])   # åŠ æ³•èµ‹å€¼
w.assign_sub([[0.5, 0.5], [0.5, 0.5]])   # å‡æ³•èµ‹å€¼

# éƒ¨åˆ†æ›´æ–°
w[0, 0].assign(10.0)                     # æ›´æ–°å•ä¸ªå…ƒç´ 
```

## 5. æ•°æ®ç±»å‹ï¼ˆdtypeï¼‰

TensorFlow æ”¯æŒå¤šç§æ•°æ®ç±»å‹ï¼š

```python
# æµ®ç‚¹æ•°
tf.float16  # åŠç²¾åº¦ï¼ˆçœå†…å­˜ï¼Œä½†ç²¾åº¦ä½ï¼‰
tf.float32  # å•ç²¾åº¦ï¼ˆé»˜è®¤ï¼Œæ€§èƒ½ä¸ç²¾åº¦å¹³è¡¡ï¼‰
tf.float64  # åŒç²¾åº¦ï¼ˆé«˜ç²¾åº¦ç§‘å­¦è®¡ç®—ï¼‰

# æ•´æ•°
tf.int32    # 32ä½æ•´æ•°ï¼ˆé»˜è®¤ï¼‰
tf.int64    # 64ä½æ•´æ•°

# å¸ƒå°”å€¼
tf.bool     # True/False

# å­—ç¬¦ä¸²
tf.string   # æ–‡æœ¬æ•°æ®
```

**ç±»å‹è½¬æ¢**ï¼š

```python
x = tf.constant([1, 2, 3], dtype=tf.int32)
y = tf.cast(x, dtype=tf.float32)  # è½¬æ¢ä¸ºæµ®ç‚¹æ•°
```

**æ··åˆç²¾åº¦è®­ç»ƒ**ï¼ˆæé€Ÿ + çœæ˜¾å­˜ï¼‰ï¼š

```python
from tensorflow.keras import mixed_precision

# å¯ç”¨æ··åˆç²¾åº¦
mixed_precision.set_global_policy('mixed_float16')

# æ¨¡å‹è‡ªåŠ¨ä½¿ç”¨ float16 è®¡ç®—ï¼Œfloat32 å­˜å‚¨
```

## 6. å¸¸è§é”™è¯¯ä¸è°ƒè¯•æŠ€å·§

### é”™è¯¯1ï¼šå½¢çŠ¶ä¸åŒ¹é…

```python
a = tf.constant([[1, 2]])      # shape: (1, 2)
b = tf.constant([[3], [4]])    # shape: (2, 1)

# c = a + b  # é”™è¯¯ï¼å½¢çŠ¶ä¸å…¼å®¹

# è§£å†³æ–¹æ¡ˆ1ï¼šå¹¿æ’­
c = a + tf.transpose(b)  # (1, 2) + (1, 2) âœ“

# è§£å†³æ–¹æ¡ˆ2ï¼šé‡å¡‘
c = tf.reshape(a, [2, 1]) + b  # (2, 1) + (2, 1) âœ“
```

### é”™è¯¯2ï¼šç±»å‹ä¸åŒ¹é…

```python
a = tf.constant([1, 2, 3], dtype=tf.int32)
b = tf.constant([1.0, 2.0, 3.0], dtype=tf.float32)

# c = a + b  # é”™è¯¯ï¼ç±»å‹ä¸åŒ¹é…

# è§£å†³æ–¹æ¡ˆï¼šæ˜¾å¼è½¬æ¢
c = tf.cast(a, tf.float32) + b  # âœ“
```

### è°ƒè¯•æŠ€å·§

```python
# 1. æ‰“å°å¼ é‡å€¼
tensor = tf.constant([1, 2, 3])
print(tensor.numpy())  # è½¬ä¸º NumPy æ‰“å°

# 2. æ‰“å°å½¢çŠ¶å’Œç±»å‹
tf.print("Shape:", tensor.shape, "Dtype:", tensor.dtype)

# 3. åœ¨ @tf.function ä¸­è°ƒè¯•
@tf.function
def debug_function(x):
    tf.print("x =", x)  # ä½¿ç”¨ tf.printï¼Œä¸æ˜¯ print
    return x ** 2

# 4. ç¦ç”¨å³æ—¶æ‰§è¡Œï¼ˆä¸æ¨èï¼Œä»…è°ƒè¯•ï¼‰
# tf.config.run_functions_eagerly(True)
```

## ğŸ”— ä¸‹ä¸€æ­¥

- [02 - Keras API](./02-keras-api.md) - ä½¿ç”¨é«˜çº§ API å¿«é€Ÿæ„å»ºæ¨¡å‹
- [03 - æ•°æ®ç®¡é“](./03-data-pipeline.md) - tf.data é«˜æ•ˆåŠ è½½æ•°æ®
- [04 - æ¨¡å‹è®­ç»ƒ](./04-model-building.md) - å®Œæ•´è®­ç»ƒæµç¨‹

## ğŸ“š å‚è€ƒèµ„æº

- [TensorFlow å®˜æ–¹æ•™ç¨‹](https://www.tensorflow.org/tutorials)
- [tf.GradientTape æ–‡æ¡£](https://www.tensorflow.org/api_docs/python/tf/GradientTape)
- [Eager Execution æŒ‡å—](https://www.tensorflow.org/guide/eager)
